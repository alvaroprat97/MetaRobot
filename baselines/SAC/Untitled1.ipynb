{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading chipmunk for Windows (64bit) [C:\\Users\\Alvaro\\Anaconda3\\lib\\site-packages\\pymunk\\chipmunk.dll]\n",
      "Working on CPU, GPU is too old\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import argparse\n",
    "import datetime\n",
    "import sys\n",
    "sys.path.insert(0,'../../envs/')\n",
    "import os\n",
    "from utils import *\n",
    "from global_vars import BATCH_SIZE, DT, SEED\n",
    "from PegRobot2D import Frontend, WINDOW_X, WINDOW_Y\n",
    "import numpy as np\n",
    "import torch\n",
    "from sac import SAC\n",
    "from tensorboardX import SummaryWriter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "save_dir = \"models/\"\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "actor_path = save_dir# + \"actors/\"\n",
    "if not os.path.exists(actor_path):\n",
    "    os.makedirs(actor_path)\n",
    "critic_path = save_dir# + \"critics/\"\n",
    "if not os.path.exists(critic_path):\n",
    "    os.makedirs(critic_path)\n",
    "\n",
    "parser = argparse.ArgumentParser(description='PyTorch Soft Actor-Critic Args')\n",
    "\n",
    "parser.add_argument('--env-name', default=\"Peg 2D Robot\",\n",
    "                    help='Mujoco Gym environment (default: HalfCheetah-v2)')\n",
    "\n",
    "parser.add_argument('--policy', default=\"Gaussian\",\n",
    "                    help='Policy Type: Gaussian | Deterministic (default: Gaussian)')\n",
    "\n",
    "parser.add_argument('--eval', type=bool, default=False,\n",
    "                    help='Evaluates a policy a policy every 25 episode(s) (default: True)')\n",
    "\n",
    "parser.add_argument('--gamma', type=float, default=0.99, metavar='G',\n",
    "                    help='discount factor for reward (default: 0.99)')\n",
    "\n",
    "parser.add_argument('--tau', type=float, default=0.005, metavar='G',\n",
    "                    help='target smoothing coefficient(τ) (default: 0.005)')\n",
    "\n",
    "parser.add_argument('--lr', type=float, default=0.0003, metavar='G',\n",
    "                    help='learning rate (default: 0.0003)')\n",
    "\n",
    "parser.add_argument('--alpha', type=float, default=0.2, metavar='G',\n",
    "                    help='Temperature parameter α determines the relative importance of the entropy\\\n",
    "                            term against the reward (default: 0.2)')\n",
    "\n",
    "parser.add_argument('--automatic_entropy_tuning', type=bool, default=False, metavar='G',\n",
    "                    help='Automaically adjust α (default: False)')\n",
    "\n",
    "parser.add_argument('--seed', type=int, default=123456, metavar='N',\n",
    "                    help='random seed (default: 123456)')\n",
    "\n",
    "parser.add_argument('--batch_size', type=int, default=256, metavar='N',\n",
    "                    help='batch size (default: 256)')\n",
    "\n",
    "parser.add_argument('--num_steps', type=int, default=1000001, metavar='N',\n",
    "                    help='maximum number of steps (default: 1000000)')\n",
    "\n",
    "parser.add_argument('--hidden_size', type=int, default=64, metavar='N',\n",
    "                    help='hidden size (default: 256)')\n",
    "\n",
    "parser.add_argument('--updates_per_step', type=int, default=1, metavar='N',\n",
    "                    help='model updates per simulator step (default: 1)')\n",
    "\n",
    "parser.add_argument('--start_steps', type=int, default=0, metavar='N',\n",
    "                    help='Steps sampling random actions (default: 10000)')\n",
    "\n",
    "parser.add_argument('--target_update_interval', type=int, default=1, metavar='N',\n",
    "                    help='Value target update per no. of updates per step (default: 1)')\n",
    "\n",
    "parser.add_argument('--replay_size', type=int, default=50000, metavar='N',\n",
    "                    help='size of replay buffer (default: 10000000)')\n",
    "\n",
    "parser.add_argument('--cuda', action=\"store_true\",\n",
    "                    help='run on CUDA (default: False)')\n",
    "\n",
    "# args = parser.parse_args()\n",
    "args, _ = parser.parse_known_args()\n",
    "\n",
    "# Environment\n",
    "env = Frontend(WINDOW_X, WINDOW_Y, args.env_name, vsync = False, resizable = False, visible = False)\n",
    "env.max_episode_steps = 500 # Num episode steps before reset\n",
    "env.denorm_process = False # No need to denorm because in SAC the gaussian policies are already scaled up\n",
    "torch.manual_seed(args.seed)\n",
    "np.random.seed(args.seed)\n",
    "\n",
    "# Agent\n",
    "num_actions = env.num_actions\n",
    "num_inputs = env.num_states\n",
    "action_range = env.action_range\n",
    "\n",
    "agent = SAC(num_inputs, num_actions, action_range, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "ORIGIN = (400, 360)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Vec2d(991.2838766526819, 280.7372867097782)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peg_tip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
