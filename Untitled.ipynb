{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading chipmunk for Windows (64bit) [C:\\Users\\Alvaro\\Anaconda3\\lib\\site-packages\\pymunk\\chipmunk.dll]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Launcher for experiments with PEARL\n",
    "\"\"\"\n",
    "import sys\n",
    "sys.path.append(\"\")\n",
    "\n",
    "import os\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import click\n",
    "import json\n",
    "import torch\n",
    "\n",
    "from envs.metaENV import ENV\n",
    "# from backend.envs.wrappers import NormalizedBoxEnv\n",
    "from backend.torch.PEARL.policies import TanhGaussianPolicy\n",
    "from backend.torch.networks import FlattenMlp, MlpEncoder, RecurrentEncoder\n",
    "from backend.torch.PEARL.sac import PEARLSoftActorCritic\n",
    "from backend.torch.PEARL.agent import PEARLAgent\n",
    "from backend.launchers.launcher_util import setup_logger\n",
    "import backend.torch.pytorch_util as ptu\n",
    "from configs.default import default_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 3\n",
      "2020-06-11 14:10:07.537957 Hora de verano romance | Variant:\n",
      "2020-06-11 14:10:07.538944 Hora de verano romance | {\n",
      "  \"env_name\": \"Peg2D\",\n",
      "  \"n_train_tasks\": 8,\n",
      "  \"n_eval_tasks\": 2,\n",
      "  \"latent_size\": 5,\n",
      "  \"net_size\": 128,\n",
      "  \"path_to_weights\": null,\n",
      "  \"env_params\": {\n",
      "    \"n_tasks\": 10,\n",
      "    \"randomize_tasks\": true\n",
      "  },\n",
      "  \"algo_params\": {\n",
      "    \"meta_batch\": 4,\n",
      "    \"num_iterations\": 500,\n",
      "    \"num_initial_steps\": 2000,\n",
      "    \"num_tasks_sample\": 5,\n",
      "    \"num_steps_prior\": 200,\n",
      "    \"num_steps_posterior\": 0,\n",
      "    \"num_extra_rl_steps_posterior\": 200,\n",
      "    \"num_train_steps_per_itr\": 500,\n",
      "    \"num_evals\": 4,\n",
      "    \"num_steps_per_eval\": 200,\n",
      "    \"batch_size\": 256,\n",
      "    \"embedding_batch_size\": 64,\n",
      "    \"embedding_mini_batch_size\": 64,\n",
      "    \"max_path_length\": 100,\n",
      "    \"discount\": 0.99,\n",
      "    \"soft_target_tau\": 0.005,\n",
      "    \"policy_lr\": 0.0003,\n",
      "    \"qf_lr\": 0.0003,\n",
      "    \"vf_lr\": 0.0003,\n",
      "    \"context_lr\": 0.0003,\n",
      "    \"reward_scale\": 5.0,\n",
      "    \"sparse_rewards\": false,\n",
      "    \"kl_lambda\": 0.1,\n",
      "    \"use_information_bottleneck\": true,\n",
      "    \"use_next_obs_in_context\": false,\n",
      "    \"update_post_train\": 1,\n",
      "    \"num_exp_traj_eval\": 1,\n",
      "    \"recurrent\": false,\n",
      "    \"dump_eval_paths\": false\n",
      "  },\n",
      "  \"util_params\": {\n",
      "    \"base_log_dir\": \"output\",\n",
      "    \"use_gpu\": false,\n",
      "    \"gpu_id\": 0,\n",
      "    \"debug\": false,\n",
      "    \"docker\": false\n",
      "  }\n",
      "}\n",
      "----------------------------------  ---------------\n",
      "Z mean train                            0.00207008\n",
      "Z variance train                        0.010824\n",
      "KL Divergence                          35.3685\n",
      "KL Loss                                 3.53685\n",
      "QF Loss                                 0.00205785\n",
      "VF Loss                                 4.1404\n",
      "Policy Loss                            -1.99453\n",
      "Q Predictions Mean                     -0.00200501\n",
      "Q Predictions Std                       0.000499041\n",
      "Q Predictions Max                      -0.00084346\n",
      "Q Predictions Min                      -0.00315092\n",
      "V Predictions Mean                     -0.00549411\n",
      "V Predictions Std                       0.000263243\n",
      "V Predictions Max                      -0.00466507\n",
      "V Predictions Min                      -0.00589109\n",
      "Log Pis Mean                           -2.0019\n",
      "Log Pis Std                             0.374567\n",
      "Log Pis Max                            -0.962463\n",
      "Log Pis Min                            -3.4686\n",
      "Policy mu Mean                          0.000653017\n",
      "Policy mu Std                           0.000152522\n",
      "Policy mu Max                           0.000872447\n",
      "Policy mu Min                           0.000192335\n",
      "Policy log std Mean                    -0.000382189\n",
      "Policy log std Std                      0.0011566\n",
      "Policy log std Max                      0.00134174\n",
      "Policy log std Min                     -0.00168006\n",
      "Z mean eval                             0.0342704\n",
      "Z variance eval                         0.325829\n",
      "AverageTrainReturn_all_train_tasks      2.17589\n",
      "AverageReturn_all_train_tasks          -0.0534298\n",
      "AverageReturn_all_test_tasks           -0.0531423\n",
      "Number of train steps total           500\n",
      "Number of env steps total           18000\n",
      "Number of rollouts total                0\n",
      "Train Time (s)                         35.421\n",
      "(Previous) Eval Time (s)                0\n",
      "Sample Time (s)                        36.1402\n",
      "Epoch Time (s)                         71.5612\n",
      "Total Train Time (s)                   77.1957\n",
      "Epoch                                   0\n",
      "----------------------------------  ---------------\n",
      "2020-06-11 14:11:24.790946 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #0 | Epoch Duration: 77.24001121520996\n",
      "2020-06-11 14:11:24.792936 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #0 | Started Training: True\n",
      "----------------------------------  --------------\n",
      "Z mean train                            0.0342875\n",
      "Z variance train                        1.01125\n",
      "KL Divergence                           0.020587\n",
      "KL Loss                                 0.0020587\n",
      "QF Loss                                 0.00203949\n",
      "VF Loss                                 0.0496079\n",
      "Policy Loss                            -4.81985\n",
      "Q Predictions Mean                      2.78624\n",
      "Q Predictions Std                       0.10295\n",
      "Q Predictions Max                       2.97395\n",
      "Q Predictions Min                       2.4905\n",
      "V Predictions Mean                      4.94121\n",
      "V Predictions Std                       0.156095\n",
      "V Predictions Max                       5.20192\n",
      "V Predictions Min                       4.43739\n",
      "Log Pis Mean                           -2.05008\n",
      "Log Pis Std                             0.187849\n",
      "Log Pis Max                            -1.53672\n",
      "Log Pis Min                            -3.09539\n",
      "Policy mu Mean                          0.00665777\n",
      "Policy mu Std                           0.00831489\n",
      "Policy mu Max                           0.0145338\n",
      "Policy mu Min                          -0.00557245\n",
      "Policy log std Mean                    -0.128912\n",
      "Policy log std Std                      0.00489421\n",
      "Policy log std Max                     -0.119931\n",
      "Policy log std Min                     -0.141874\n",
      "Z mean eval                             0.0774952\n",
      "Z variance eval                         0.322458\n",
      "AverageTrainReturn_all_train_tasks     -0.0480409\n",
      "AverageReturn_all_train_tasks          -0.0425434\n",
      "AverageReturn_all_test_tasks           -0.0473541\n",
      "Number of train steps total          1000\n",
      "Number of env steps total           20000\n",
      "Number of rollouts total                0\n",
      "Train Time (s)                         30.1222\n",
      "(Previous) Eval Time (s)                5.67878\n",
      "Sample Time (s)                         3.54145\n",
      "Epoch Time (s)                         39.3424\n",
      "Total Train Time (s)                  116.594\n",
      "Epoch                                   1\n",
      "----------------------------------  --------------\n",
      "2020-06-11 14:12:04.176802 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #1 | Epoch Duration: 39.38286733627319\n",
      "2020-06-11 14:12:04.176802 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #1 | Started Training: True\n",
      "----------------------------------  --------------\n",
      "Z mean train                            0.0735622\n",
      "Z variance train                        0.956505\n",
      "KL Divergence                           0.0811548\n",
      "KL Loss                                 0.00811548\n",
      "QF Loss                                 0.0172002\n",
      "VF Loss                                 0.0513205\n",
      "Policy Loss                            -8.99445\n",
      "Q Predictions Mean                      6.87566\n",
      "Q Predictions Std                       0.121992\n",
      "Q Predictions Max                       7.11462\n",
      "Q Predictions Min                       6.2782\n",
      "V Predictions Mean                      8.94594\n",
      "V Predictions Std                       0.158543\n",
      "V Predictions Max                       9.26844\n",
      "V Predictions Min                       8.33776\n",
      "Log Pis Mean                           -2.05545\n",
      "Log Pis Std                             0.201504\n",
      "Log Pis Max                            -1.57757\n",
      "Log Pis Min                            -3.97678\n",
      "Policy mu Mean                         -0.00399617\n",
      "Policy mu Std                           0.00172012\n",
      "Policy mu Max                          -0.00107967\n",
      "Policy mu Min                          -0.00665064\n",
      "Policy log std Mean                    -0.12778\n",
      "Policy log std Std                      0.00300707\n",
      "Policy log std Max                     -0.123069\n",
      "Policy log std Min                     -0.132906\n",
      "Z mean eval                             0.0529178\n",
      "Z variance eval                         0.312966\n",
      "AverageTrainReturn_all_train_tasks     -0.0466899\n",
      "AverageReturn_all_train_tasks          -0.0393226\n",
      "AverageReturn_all_test_tasks           -0.0429598\n",
      "Number of train steps total          1500\n",
      "Number of env steps total           22000\n",
      "Number of rollouts total                0\n",
      "Train Time (s)                         32.9348\n",
      "(Previous) Eval Time (s)                5.71833\n",
      "Sample Time (s)                         3.85082\n",
      "Epoch Time (s)                         42.504\n",
      "Total Train Time (s)                  159.133\n",
      "Epoch                                   2\n",
      "----------------------------------  --------------\n",
      "2020-06-11 14:12:46.727018 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #2 | Epoch Duration: 42.549216747283936\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-06-11 14:12:46.730015 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #2 | Started Training: True\n",
      "----------------------------------  ---------------\n",
      "Z mean train                            0.0527748\n",
      "Z variance train                        0.974753\n",
      "KL Divergence                           0.0420004\n",
      "KL Loss                                 0.00420004\n",
      "QF Loss                                 0.0509449\n",
      "VF Loss                                 0.0470282\n",
      "Policy Loss                           -13.4304\n",
      "Q Predictions Mean                     11.3631\n",
      "Q Predictions Std                       0.161569\n",
      "Q Predictions Max                      11.6867\n",
      "Q Predictions Min                      10.4884\n",
      "V Predictions Mean                     13.5146\n",
      "V Predictions Std                       0.155216\n",
      "V Predictions Max                      13.75\n",
      "V Predictions Min                      12.6766\n",
      "Log Pis Mean                           -2.04858\n",
      "Log Pis Std                             0.196829\n",
      "Log Pis Max                            -1.58486\n",
      "Log Pis Min                            -4.19878\n",
      "Policy mu Mean                          0.00594828\n",
      "Policy mu Std                           0.00310752\n",
      "Policy mu Max                           0.0107114\n",
      "Policy mu Min                          -0.000364319\n",
      "Policy log std Mean                    -0.130624\n",
      "Policy log std Std                      0.0026122\n",
      "Policy log std Max                     -0.126179\n",
      "Policy log std Min                     -0.134064\n",
      "Z mean eval                             0.0898063\n",
      "Z variance eval                         0.311946\n",
      "AverageTrainReturn_all_train_tasks     -0.0453189\n",
      "AverageReturn_all_train_tasks          -0.0439503\n",
      "AverageReturn_all_test_tasks           -0.0444257\n",
      "Number of train steps total          2000\n",
      "Number of env steps total           24000\n",
      "Number of rollouts total                0\n",
      "Train Time (s)                         35.8624\n",
      "(Previous) Eval Time (s)                5.7637\n",
      "Sample Time (s)                         3.9635\n",
      "Epoch Time (s)                         45.5896\n",
      "Total Train Time (s)                  205.672\n",
      "Epoch                                   3\n",
      "----------------------------------  ---------------\n",
      "2020-06-11 14:13:33.274235 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #3 | Epoch Duration: 46.54321789741516\n",
      "2020-06-11 14:13:33.275234 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #3 | Started Training: True\n",
      "----------------------------------  --------------\n",
      "Z mean train                            0.0866374\n",
      "Z variance train                        0.94249\n",
      "KL Divergence                           0.143316\n",
      "KL Loss                                 0.0143316\n",
      "QF Loss                                 0.00594978\n",
      "VF Loss                                 0.0536942\n",
      "Policy Loss                           -17.9032\n",
      "Q Predictions Mean                     15.841\n",
      "Q Predictions Std                       0.252024\n",
      "Q Predictions Max                      16.3402\n",
      "Q Predictions Min                      14.6872\n",
      "V Predictions Mean                     17.8143\n",
      "V Predictions Std                       0.234048\n",
      "V Predictions Max                      18.2137\n",
      "V Predictions Min                      16.6424\n",
      "Log Pis Mean                           -2.05099\n",
      "Log Pis Std                             0.205955\n",
      "Log Pis Max                            -1.54027\n",
      "Log Pis Min                            -4.53595\n",
      "Policy mu Mean                          0.00442392\n",
      "Policy mu Std                           0.00786276\n",
      "Policy mu Max                           0.0180708\n",
      "Policy mu Min                          -0.0124428\n",
      "Policy log std Mean                    -0.126478\n",
      "Policy log std Std                      0.00595146\n",
      "Policy log std Max                     -0.118015\n",
      "Policy log std Min                     -0.136301\n",
      "Z mean eval                             0.0602705\n",
      "Z variance eval                         0.299984\n",
      "AverageTrainReturn_all_train_tasks     -0.0414854\n",
      "AverageReturn_all_train_tasks          -0.0415398\n",
      "AverageReturn_all_test_tasks           -0.0479158\n",
      "Number of train steps total          2500\n",
      "Number of env steps total           26000\n",
      "Number of rollouts total                0\n",
      "Train Time (s)                         31.5422\n",
      "(Previous) Eval Time (s)                6.71765\n",
      "Sample Time (s)                         3.43894\n",
      "Epoch Time (s)                         41.6988\n",
      "Total Train Time (s)                  246.38\n",
      "Epoch                                   4\n",
      "----------------------------------  --------------\n",
      "2020-06-11 14:14:13.972623 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #4 | Epoch Duration: 40.69638919830322\n",
      "2020-06-11 14:14:13.973623 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #4 | Started Training: True\n",
      "----------------------------------  --------------\n",
      "Z mean train                            0.0618738\n",
      "Z variance train                        0.96287\n",
      "KL Divergence                           0.0670574\n",
      "KL Loss                                 0.00670574\n",
      "QF Loss                                 0.0262919\n",
      "VF Loss                                 0.0907851\n",
      "Policy Loss                           -22.3019\n",
      "Q Predictions Mean                     20.2377\n",
      "Q Predictions Std                       0.290138\n",
      "Q Predictions Max                      20.8135\n",
      "Q Predictions Min                      18.9855\n",
      "V Predictions Mean                     22.1091\n",
      "V Predictions Std                       0.321076\n",
      "V Predictions Max                      22.6882\n",
      "V Predictions Min                      20.5462\n",
      "Log Pis Mean                           -2.05309\n",
      "Log Pis Std                             0.211746\n",
      "Log Pis Max                            -1.55827\n",
      "Log Pis Min                            -4.15872\n",
      "Policy mu Mean                          0.00971199\n",
      "Policy mu Std                           0.0122067\n",
      "Policy mu Max                           0.0325432\n",
      "Policy mu Min                          -0.0106088\n",
      "Policy log std Mean                    -0.133424\n",
      "Policy log std Std                      0.00518193\n",
      "Policy log std Max                     -0.126387\n",
      "Policy log std Min                     -0.144253\n",
      "Z mean eval                             0.0846268\n",
      "Z variance eval                         0.311816\n",
      "AverageTrainReturn_all_train_tasks     -0.0423406\n",
      "AverageReturn_all_train_tasks          -0.0435716\n",
      "AverageReturn_all_test_tasks           -0.0442045\n",
      "Number of train steps total          3000\n",
      "Number of env steps total           28000\n",
      "Number of rollouts total                0\n",
      "Train Time (s)                         34.5941\n",
      "(Previous) Eval Time (s)                5.71431\n",
      "Sample Time (s)                         3.74502\n",
      "Epoch Time (s)                         44.0534\n",
      "Total Train Time (s)                  290.624\n",
      "Epoch                                   5\n",
      "----------------------------------  --------------\n",
      "2020-06-11 14:14:58.220310 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #5 | Epoch Duration: 44.24568843841553\n",
      "2020-06-11 14:14:58.222309 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #5 | Started Training: True\n",
      "----------------------------------  --------------\n",
      "Z mean train                            0.0847756\n",
      "Z variance train                        0.976187\n",
      "KL Divergence                           0.111342\n",
      "KL Loss                                 0.0111342\n",
      "QF Loss                                 0.0350695\n",
      "VF Loss                                 0.0726366\n",
      "Policy Loss                           -26.6272\n",
      "Q Predictions Mean                     24.6728\n",
      "Q Predictions Std                       0.320393\n",
      "Q Predictions Max                      25.4051\n",
      "Q Predictions Min                      23.1721\n",
      "V Predictions Mean                     26.6411\n",
      "V Predictions Std                       0.447457\n",
      "V Predictions Max                      27.6398\n",
      "V Predictions Min                      24.7824\n",
      "Log Pis Mean                           -2.04966\n",
      "Log Pis Std                             0.215266\n",
      "Log Pis Max                            -1.54113\n",
      "Log Pis Min                            -3.91434\n",
      "Policy mu Mean                          0.00785489\n",
      "Policy mu Std                           0.0199694\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy mu Max                           0.0470977\n",
      "Policy mu Min                          -0.0263434\n",
      "Policy log std Mean                    -0.134036\n",
      "Policy log std Std                      0.00343655\n",
      "Policy log std Max                     -0.123216\n",
      "Policy log std Min                     -0.141425\n",
      "Z mean eval                             0.045817\n",
      "Z variance eval                         0.3208\n",
      "AverageTrainReturn_all_train_tasks     -0.0477546\n",
      "AverageReturn_all_train_tasks          -0.0469942\n",
      "AverageReturn_all_test_tasks           -0.0455768\n",
      "Number of train steps total          3500\n",
      "Number of env steps total           30000\n",
      "Number of rollouts total                0\n",
      "Train Time (s)                         34.0405\n",
      "(Previous) Eval Time (s)                5.90706\n",
      "Sample Time (s)                         3.32708\n",
      "Epoch Time (s)                         43.2747\n",
      "Total Train Time (s)                  334.839\n",
      "Epoch                                   6\n",
      "----------------------------------  --------------\n",
      "2020-06-11 14:15:42.432834 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #6 | Epoch Duration: 44.20852494239807\n",
      "2020-06-11 14:15:42.435835 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #6 | Started Training: True\n",
      "----------------------------------  --------------\n",
      "Z mean train                            0.0451612\n",
      "Z variance train                        0.989036\n",
      "KL Divergence                           0.0427325\n",
      "KL Loss                                 0.00427325\n",
      "QF Loss                                 0.0246112\n",
      "VF Loss                                 0.0527162\n",
      "Policy Loss                           -30.8042\n",
      "Q Predictions Mean                     28.7704\n",
      "Q Predictions Std                       0.329033\n",
      "Q Predictions Max                      29.407\n",
      "Q Predictions Min                      26.4732\n",
      "V Predictions Mean                     30.8202\n",
      "V Predictions Std                       0.335313\n",
      "V Predictions Max                      31.4344\n",
      "V Predictions Min                      28.7015\n",
      "Log Pis Mean                           -2.03892\n",
      "Log Pis Std                             0.216735\n",
      "Log Pis Max                            -1.56235\n",
      "Log Pis Min                            -4.93894\n",
      "Policy mu Mean                          0.0113551\n",
      "Policy mu Std                           0.026996\n",
      "Policy mu Max                           0.0726385\n",
      "Policy mu Min                          -0.0262889\n",
      "Policy log std Mean                    -0.137186\n",
      "Policy log std Std                      0.00246606\n",
      "Policy log std Max                     -0.127742\n",
      "Policy log std Min                     -0.143289\n",
      "Z mean eval                             0.176154\n",
      "Z variance eval                         0.255927\n",
      "AverageTrainReturn_all_train_tasks     -0.044776\n",
      "AverageReturn_all_train_tasks          -0.0440855\n",
      "AverageReturn_all_test_tasks           -0.0456071\n",
      "Number of train steps total          4000\n",
      "Number of env steps total           32000\n",
      "Number of rollouts total                0\n",
      "Train Time (s)                         38.5064\n",
      "(Previous) Eval Time (s)                6.84031\n",
      "Sample Time (s)                         5.27674\n",
      "Epoch Time (s)                         50.6234\n",
      "Total Train Time (s)                  384.57\n",
      "Epoch                                   7\n",
      "----------------------------------  --------------\n",
      "2020-06-11 14:16:32.163454 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #7 | Epoch Duration: 49.72562217712402\n",
      "2020-06-11 14:16:32.164454 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #7 | Started Training: True\n",
      "----------------------------------  --------------\n",
      "Z mean train                            0.176551\n",
      "Z variance train                        0.801698\n",
      "KL Divergence                           0.62719\n",
      "KL Loss                                 0.062719\n",
      "QF Loss                                 0.0749332\n",
      "VF Loss                                 0.0600268\n",
      "Policy Loss                           -34.6122\n",
      "Q Predictions Mean                     32.5022\n",
      "Q Predictions Std                       0.414467\n",
      "Q Predictions Max                      33.3294\n",
      "Q Predictions Min                      30.2108\n",
      "V Predictions Mean                     34.6241\n",
      "V Predictions Std                       0.418536\n",
      "V Predictions Max                      35.3934\n",
      "V Predictions Min                      32.6175\n",
      "Log Pis Mean                           -2.04716\n",
      "Log Pis Std                             0.199482\n",
      "Log Pis Max                            -1.45578\n",
      "Log Pis Min                            -3.40158\n",
      "Policy mu Mean                          0.0191902\n",
      "Policy mu Std                           0.0218998\n",
      "Policy mu Max                           0.0870365\n",
      "Policy mu Min                          -0.0215684\n",
      "Policy log std Mean                    -0.128724\n",
      "Policy log std Std                      0.00593014\n",
      "Policy log std Max                     -0.1157\n",
      "Policy log std Min                     -0.149508\n",
      "Z mean eval                             0.0579435\n",
      "Z variance eval                         0.316157\n",
      "AverageTrainReturn_all_train_tasks      2.45013\n",
      "AverageReturn_all_train_tasks           0.0342004\n",
      "AverageReturn_all_test_tasks            0.0353661\n",
      "Number of train steps total          4500\n",
      "Number of env steps total           34000\n",
      "Number of rollouts total                0\n",
      "Train Time (s)                         33.9968\n",
      "(Previous) Eval Time (s)                5.94237\n",
      "Sample Time (s)                         3.78129\n",
      "Epoch Time (s)                         43.7204\n",
      "Total Train Time (s)                  428.765\n",
      "Epoch                                   8\n",
      "----------------------------------  --------------\n",
      "2020-06-11 14:17:16.360703 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #8 | Epoch Duration: 44.188252449035645\n",
      "2020-06-11 14:17:16.361702 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #8 | Started Training: True\n",
      "----------------------------------  --------------\n",
      "Z mean train                            0.0583238\n",
      "Z variance train                        0.995647\n",
      "KL Divergence                           0.0400706\n",
      "KL Loss                                 0.00400706\n",
      "QF Loss                                 0.0577075\n",
      "VF Loss                                 0.140322\n",
      "Policy Loss                           -39.0243\n",
      "Q Predictions Mean                     37.1766\n",
      "Q Predictions Std                       0.526946\n",
      "Q Predictions Max                      38.2419\n",
      "Q Predictions Min                      35.0626\n",
      "V Predictions Mean                     39.2835\n",
      "V Predictions Std                       0.457134\n",
      "V Predictions Max                      40.0621\n",
      "V Predictions Min                      37.2108\n",
      "Log Pis Mean                           -2.0569\n",
      "Log Pis Std                             0.206417\n",
      "Log Pis Max                            -1.35888\n",
      "Log Pis Min                            -3.45427\n",
      "Policy mu Mean                          0.00881444\n",
      "Policy mu Std                           0.024328\n",
      "Policy mu Max                           0.0845613\n",
      "Policy mu Min                          -0.0484901\n",
      "Policy log std Mean                    -0.130702\n",
      "Policy log std Std                      0.00403939\n",
      "Policy log std Max                     -0.121264\n",
      "Policy log std Min                     -0.149193\n",
      "Z mean eval                             0.0863172\n",
      "Z variance eval                         0.307369\n",
      "AverageTrainReturn_all_train_tasks      1.92153\n",
      "AverageReturn_all_train_tasks          -0.0548922\n",
      "AverageReturn_all_test_tasks           -0.052676\n",
      "Number of train steps total          5000\n",
      "Number of env steps total           36000\n",
      "Number of rollouts total                0\n",
      "Train Time (s)                         34.4309\n",
      "(Previous) Eval Time (s)                6.41023\n",
      "Sample Time (s)                         3.6925\n",
      "Epoch Time (s)                         44.5336\n",
      "Total Train Time (s)                  472.926\n",
      "Epoch                                   9\n",
      "----------------------------------  --------------\n",
      "2020-06-11 14:18:00.528307 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #9 | Epoch Duration: 44.1656060218811\n",
      "2020-06-11 14:18:00.528307 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #9 | Started Training: True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------  --------------\n",
      "Z mean train                            0.0849024\n",
      "Z variance train                        0.944597\n",
      "KL Divergence                           0.169286\n",
      "KL Loss                                 0.0169286\n",
      "QF Loss                                 0.0675816\n",
      "VF Loss                                 0.106158\n",
      "Policy Loss                           -43.2034\n",
      "Q Predictions Mean                     41.1149\n",
      "Q Predictions Std                       0.596294\n",
      "Q Predictions Max                      42.5067\n",
      "Q Predictions Min                      38.2354\n",
      "V Predictions Mean                     43.3131\n",
      "V Predictions Std                       0.604892\n",
      "V Predictions Max                      44.4183\n",
      "V Predictions Min                      40.1702\n",
      "Log Pis Mean                           -2.0401\n",
      "Log Pis Std                             0.216268\n",
      "Log Pis Max                            -1.41126\n",
      "Log Pis Min                            -3.69819\n",
      "Policy mu Mean                          0.0135928\n",
      "Policy mu Std                           0.0315599\n",
      "Policy mu Max                           0.116649\n",
      "Policy mu Min                          -0.0371106\n",
      "Policy log std Mean                    -0.126567\n",
      "Policy log std Std                      0.00570451\n",
      "Policy log std Max                     -0.104885\n",
      "Policy log std Min                     -0.143488\n",
      "Z mean eval                             0.0713106\n",
      "Z variance eval                         0.315056\n",
      "AverageTrainReturn_all_train_tasks     -0.0605181\n",
      "AverageReturn_all_train_tasks          -0.0537547\n",
      "AverageReturn_all_test_tasks            1.06026\n",
      "Number of train steps total          5500\n",
      "Number of env steps total           38000\n",
      "Number of rollouts total                0\n",
      "Train Time (s)                         35.756\n",
      "(Previous) Eval Time (s)                6.04186\n",
      "Sample Time (s)                         3.69486\n",
      "Epoch Time (s)                         45.4927\n",
      "Total Train Time (s)                  518.554\n",
      "Epoch                                  10\n",
      "----------------------------------  --------------\n",
      "2020-06-11 14:18:46.151714 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #10 | Epoch Duration: 45.62240791320801\n",
      "2020-06-11 14:18:46.152713 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #10 | Started Training: True\n",
      "----------------------------------  --------------\n",
      "Z mean train                            0.0688852\n",
      "Z variance train                        0.95166\n",
      "KL Divergence                           0.0753739\n",
      "KL Loss                                 0.00753739\n",
      "QF Loss                                 0.0313665\n",
      "VF Loss                                 0.0525986\n",
      "Policy Loss                           -46.8937\n",
      "Q Predictions Mean                     44.7735\n",
      "Q Predictions Std                       0.68952\n",
      "Q Predictions Max                      46.1354\n",
      "Q Predictions Min                      41.2651\n",
      "V Predictions Mean                     46.9267\n",
      "V Predictions Std                       0.700031\n",
      "V Predictions Max                      48.2753\n",
      "V Predictions Min                      43.1108\n",
      "Log Pis Mean                           -2.05403\n",
      "Log Pis Std                             0.218825\n",
      "Log Pis Max                            -1.50965\n",
      "Log Pis Min                            -4.41871\n",
      "Policy mu Mean                          0.0242935\n",
      "Policy mu Std                           0.0281955\n",
      "Policy mu Max                           0.118814\n",
      "Policy mu Min                          -0.0321213\n",
      "Policy log std Mean                    -0.138043\n",
      "Policy log std Std                      0.00647343\n",
      "Policy log std Max                     -0.121532\n",
      "Policy log std Min                     -0.148351\n",
      "Z mean eval                             0.0704275\n",
      "Z variance eval                         0.312823\n",
      "AverageTrainReturn_all_train_tasks     -0.053578\n",
      "AverageReturn_all_train_tasks           0.247326\n",
      "AverageReturn_all_test_tasks           -0.0544342\n",
      "Number of train steps total          6000\n",
      "Number of env steps total           40000\n",
      "Number of rollouts total                0\n",
      "Train Time (s)                         36.7059\n",
      "(Previous) Eval Time (s)                6.17134\n",
      "Sample Time (s)                         3.71958\n",
      "Epoch Time (s)                         46.5968\n",
      "Total Train Time (s)                  566.621\n",
      "Epoch                                  11\n",
      "----------------------------------  --------------\n",
      "2020-06-11 14:19:34.240123 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #11 | Epoch Duration: 48.08641076087952\n",
      "2020-06-11 14:19:34.241123 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #11 | Started Training: True\n",
      "----------------------------------  --------------\n",
      "Z mean train                            0.06961\n",
      "Z variance train                        0.966835\n",
      "KL Divergence                           0.0686179\n",
      "KL Loss                                 0.00686179\n",
      "QF Loss                                 0.035435\n",
      "VF Loss                                 0.0863546\n",
      "Policy Loss                           -50.3799\n",
      "Q Predictions Mean                     48.2398\n",
      "Q Predictions Std                       0.606192\n",
      "Q Predictions Max                      49.1788\n",
      "Q Predictions Min                      45.4555\n",
      "V Predictions Mean                     50.2056\n",
      "V Predictions Std                       0.643053\n",
      "V Predictions Max                      51.2362\n",
      "V Predictions Min                      47.207\n",
      "Log Pis Mean                           -2.04743\n",
      "Log Pis Std                             0.245557\n",
      "Log Pis Max                            -1.42563\n",
      "Log Pis Min                            -5.67263\n",
      "Policy mu Mean                          0.0268667\n",
      "Policy mu Std                           0.0327842\n",
      "Policy mu Max                           0.148744\n",
      "Policy mu Min                          -0.0507081\n",
      "Policy log std Mean                    -0.133163\n",
      "Policy log std Std                      0.00904605\n",
      "Policy log std Max                     -0.112223\n",
      "Policy log std Min                     -0.149517\n",
      "Z mean eval                             0.0835225\n",
      "Z variance eval                         0.305552\n",
      "AverageTrainReturn_all_train_tasks     -0.0483963\n",
      "AverageReturn_all_train_tasks          -0.047508\n",
      "AverageReturn_all_test_tasks            0.216032\n",
      "Number of train steps total          6500\n",
      "Number of env steps total           42000\n",
      "Number of rollouts total                0\n",
      "Train Time (s)                         40.1285\n",
      "(Previous) Eval Time (s)                7.66039\n",
      "Sample Time (s)                         3.67373\n",
      "Epoch Time (s)                         51.4626\n",
      "Total Train Time (s)                  622.052\n",
      "Epoch                                  12\n",
      "----------------------------------  --------------\n",
      "2020-06-11 14:20:29.685165 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #12 | Epoch Duration: 55.44304323196411\n",
      "2020-06-11 14:20:29.687168 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #12 | Started Training: True\n",
      "----------------------------------  --------------\n",
      "Z mean train                            0.0855358\n",
      "Z variance train                        0.977907\n",
      "KL Divergence                           0.0966113\n",
      "KL Loss                                 0.00966113\n",
      "QF Loss                                 0.0625549\n",
      "VF Loss                                 0.152726\n",
      "Policy Loss                           -53.9986\n",
      "Q Predictions Mean                     51.9922\n",
      "Q Predictions Std                       0.683288\n",
      "Q Predictions Max                      53.2702\n",
      "Q Predictions Min                      48.1659\n",
      "V Predictions Mean                     54.2966\n",
      "V Predictions Std                       0.74174\n",
      "V Predictions Max                      55.6795\n",
      "V Predictions Min                      50.5123\n",
      "Log Pis Mean                           -2.04197\n",
      "Log Pis Std                             0.221856\n",
      "Log Pis Max                            -1.34071\n",
      "Log Pis Min                            -3.48083\n",
      "Policy mu Mean                          0.0249228\n",
      "Policy mu Std                           0.0427981\n",
      "Policy mu Max                           0.161626\n",
      "Policy mu Min                          -0.0652207\n",
      "Policy log std Mean                    -0.134327\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy log std Std                      0.00586487\n",
      "Policy log std Max                     -0.122691\n",
      "Policy log std Min                     -0.14794\n",
      "Z mean eval                             0.0824039\n",
      "Z variance eval                         0.296086\n",
      "AverageTrainReturn_all_train_tasks     -0.0493907\n",
      "AverageReturn_all_train_tasks          -0.0493038\n",
      "AverageReturn_all_test_tasks           -0.0471251\n",
      "Number of train steps total          7000\n",
      "Number of env steps total           44000\n",
      "Number of rollouts total                0\n",
      "Train Time (s)                         41.6549\n",
      "(Previous) Eval Time (s)               11.6403\n",
      "Sample Time (s)                         5.07511\n",
      "Epoch Time (s)                         58.3703\n",
      "Total Train Time (s)                  675.28\n",
      "Epoch                                  13\n",
      "----------------------------------  --------------\n",
      "2020-06-11 14:21:22.877450 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #13 | Epoch Duration: 53.18928384780884\n",
      "2020-06-11 14:21:22.878450 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #13 | Started Training: True\n",
      "----------------------------------  --------------\n",
      "Z mean train                            0.0818151\n",
      "Z variance train                        0.918999\n",
      "KL Divergence                           0.130688\n",
      "KL Loss                                 0.0130688\n",
      "QF Loss                                 0.106668\n",
      "VF Loss                                 0.112719\n",
      "Policy Loss                           -57.2835\n",
      "Q Predictions Mean                     55.2926\n",
      "Q Predictions Std                       0.674317\n",
      "Q Predictions Max                      56.623\n",
      "Q Predictions Min                      52.0482\n",
      "V Predictions Mean                     57.2621\n",
      "V Predictions Std                       0.716747\n",
      "V Predictions Max                      58.7086\n",
      "V Predictions Min                      53.9363\n",
      "Log Pis Mean                           -2.05132\n",
      "Log Pis Std                             0.219206\n",
      "Log Pis Max                            -1.39281\n",
      "Log Pis Min                            -4.17088\n",
      "Policy mu Mean                          0.0206822\n",
      "Policy mu Std                           0.043193\n",
      "Policy mu Max                           0.187707\n",
      "Policy mu Min                          -0.0544881\n",
      "Policy log std Mean                    -0.126709\n",
      "Policy log std Std                      0.00460243\n",
      "Policy log std Max                     -0.109479\n",
      "Policy log std Min                     -0.13515\n",
      "Z mean eval                             0.0716759\n",
      "Z variance eval                         0.292451\n",
      "AverageTrainReturn_all_train_tasks     -0.0568766\n",
      "AverageReturn_all_train_tasks          -0.0540448\n",
      "AverageReturn_all_test_tasks           -0.0548504\n",
      "Number of train steps total          7500\n",
      "Number of env steps total           46000\n",
      "Number of rollouts total                0\n",
      "Train Time (s)                         32.1545\n",
      "(Previous) Eval Time (s)                6.45914\n",
      "Sample Time (s)                         3.47841\n",
      "Epoch Time (s)                         42.092\n",
      "Total Train Time (s)                  716.749\n",
      "Epoch                                  14\n",
      "----------------------------------  --------------\n",
      "2020-06-11 14:22:04.348862 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #14 | Epoch Duration: 41.46941256523132\n",
      "2020-06-11 14:22:04.349861 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #14 | Started Training: True\n",
      "----------------------------------  --------------\n",
      "Z mean train                            0.0763537\n",
      "Z variance train                        0.973553\n",
      "KL Divergence                           0.0882112\n",
      "KL Loss                                 0.00882112\n",
      "QF Loss                                 0.0523625\n",
      "VF Loss                                 0.108423\n",
      "Policy Loss                           -60.8359\n",
      "Q Predictions Mean                     58.9923\n",
      "Q Predictions Std                       0.710334\n",
      "Q Predictions Max                      60.267\n",
      "Q Predictions Min                      55.5461\n",
      "V Predictions Mean                     61.0482\n",
      "V Predictions Std                       0.756296\n",
      "V Predictions Max                      62.3686\n",
      "V Predictions Min                      57.4514\n",
      "Log Pis Mean                           -2.049\n",
      "Log Pis Std                             0.226504\n",
      "Log Pis Max                            -1.14086\n",
      "Log Pis Min                            -3.49194\n",
      "Policy mu Mean                          0.0265799\n",
      "Policy mu Std                           0.039711\n",
      "Policy mu Max                           0.191925\n",
      "Policy mu Min                          -0.0647918\n",
      "Policy log std Mean                    -0.126779\n",
      "Policy log std Std                      0.0043736\n",
      "Policy log std Max                     -0.113796\n",
      "Policy log std Min                     -0.14216\n",
      "Z mean eval                             0.0504399\n",
      "Z variance eval                         0.287736\n",
      "AverageTrainReturn_all_train_tasks     -0.046096\n",
      "AverageReturn_all_train_tasks          -0.0450824\n",
      "AverageReturn_all_test_tasks           -0.044844\n",
      "Number of train steps total          8000\n",
      "Number of env steps total           48000\n",
      "Number of rollouts total                0\n",
      "Train Time (s)                         33.1623\n",
      "(Previous) Eval Time (s)                5.83674\n",
      "Sample Time (s)                         4.12517\n",
      "Epoch Time (s)                         43.1242\n",
      "Total Train Time (s)                  759.835\n",
      "Epoch                                  15\n",
      "----------------------------------  --------------\n",
      "2020-06-11 14:22:47.442363 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #15 | Epoch Duration: 43.09050369262695\n",
      "2020-06-11 14:22:47.443362 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #15 | Started Training: True\n",
      "----------------------------------  --------------\n",
      "Z mean train                            0.0504604\n",
      "Z variance train                        0.899559\n",
      "KL Divergence                           0.0925348\n",
      "KL Loss                                 0.00925348\n",
      "QF Loss                                 0.137343\n",
      "VF Loss                                 0.243244\n",
      "Policy Loss                           -64.242\n",
      "Q Predictions Mean                     62.1749\n",
      "Q Predictions Std                       0.842453\n",
      "Q Predictions Max                      63.6849\n",
      "Q Predictions Min                      57.5845\n",
      "V Predictions Mean                     64.2813\n",
      "V Predictions Std                       0.924894\n",
      "V Predictions Max                      66.2982\n",
      "V Predictions Min                      59.9502\n",
      "Log Pis Mean                           -2.04588\n",
      "Log Pis Std                             0.232445\n",
      "Log Pis Max                            -1.21638\n",
      "Log Pis Min                            -4.26907\n",
      "Policy mu Mean                          0.0195574\n",
      "Policy mu Std                           0.0469362\n",
      "Policy mu Max                           0.181871\n",
      "Policy mu Min                          -0.0709056\n",
      "Policy log std Mean                    -0.132536\n",
      "Policy log std Std                      0.00454325\n",
      "Policy log std Max                     -0.122338\n",
      "Policy log std Min                     -0.145669\n",
      "Z mean eval                             0.0886273\n",
      "Z variance eval                         0.263443\n",
      "AverageTrainReturn_all_train_tasks     -0.057246\n",
      "AverageReturn_all_train_tasks          -0.0563747\n",
      "AverageReturn_all_test_tasks           -0.0535385\n",
      "Number of train steps total          8500\n",
      "Number of env steps total           50000\n",
      "Number of rollouts total                0\n",
      "Train Time (s)                         39.2641\n",
      "(Previous) Eval Time (s)                5.80322\n",
      "Sample Time (s)                         3.35954\n",
      "Epoch Time (s)                         48.4269\n",
      "Total Train Time (s)                  808.443\n",
      "Epoch                                  16\n",
      "----------------------------------  --------------\n",
      "2020-06-11 14:23:36.047871 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #16 | Epoch Duration: 48.60350847244263\n",
      "2020-06-11 14:23:36.048870 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #16 | Started Training: True\n",
      "----------------------------------  --------------\n",
      "Z mean train                            0.0880722\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z variance train                        0.818382\n",
      "KL Divergence                           0.365098\n",
      "KL Loss                                 0.0365098\n",
      "QF Loss                                 0.467044\n",
      "VF Loss                                 1.10067\n",
      "Policy Loss                           -67.2947\n",
      "Q Predictions Mean                     65.5643\n",
      "Q Predictions Std                       0.920301\n",
      "Q Predictions Max                      67.4604\n",
      "Q Predictions Min                      60.9724\n",
      "V Predictions Mean                     68.18\n",
      "V Predictions Std                       1.16259\n",
      "V Predictions Max                      70.6686\n",
      "V Predictions Min                      63.1801\n",
      "Log Pis Mean                           -2.05228\n",
      "Log Pis Std                             0.245137\n",
      "Log Pis Max                            -1.28277\n",
      "Log Pis Min                            -3.89132\n",
      "Policy mu Mean                          0.0198976\n",
      "Policy mu Std                           0.046032\n",
      "Policy mu Max                           0.20707\n",
      "Policy mu Min                          -0.0671789\n",
      "Policy log std Mean                    -0.127233\n",
      "Policy log std Std                      0.00584205\n",
      "Policy log std Max                     -0.113348\n",
      "Policy log std Min                     -0.142978\n",
      "Z mean eval                             0.0399496\n",
      "Z variance eval                         0.308209\n",
      "AverageTrainReturn_all_train_tasks     -0.0494187\n",
      "AverageReturn_all_train_tasks          -0.0435379\n",
      "AverageReturn_all_test_tasks           -0.044953\n",
      "Number of train steps total          9000\n",
      "Number of env steps total           52000\n",
      "Number of rollouts total                0\n",
      "Train Time (s)                         31.4194\n",
      "(Previous) Eval Time (s)                5.97937\n",
      "Sample Time (s)                         3.58551\n",
      "Epoch Time (s)                         40.9843\n",
      "Total Train Time (s)                  850.414\n",
      "Epoch                                  17\n",
      "----------------------------------  --------------\n",
      "2020-06-11 14:24:18.031032 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #17 | Epoch Duration: 41.98216152191162\n",
      "2020-06-11 14:24:18.033027 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #17 | Started Training: True\n",
      "----------------------------------  --------------\n",
      "Z mean train                            0.0409213\n",
      "Z variance train                        0.986462\n",
      "KL Divergence                           0.0237131\n",
      "KL Loss                                 0.00237131\n",
      "QF Loss                                 0.0573809\n",
      "VF Loss                                 0.0740834\n",
      "Policy Loss                           -71.2257\n",
      "Q Predictions Mean                     69.2038\n",
      "Q Predictions Std                       0.913563\n",
      "Q Predictions Max                      70.9693\n",
      "Q Predictions Min                      64.6697\n",
      "V Predictions Mean                     71.3684\n",
      "V Predictions Std                       0.972873\n",
      "V Predictions Max                      73.1604\n",
      "V Predictions Min                      66.7237\n",
      "Log Pis Mean                           -2.03805\n",
      "Log Pis Std                             0.220373\n",
      "Log Pis Max                            -1.21267\n",
      "Log Pis Min                            -3.29824\n",
      "Policy mu Mean                          0.0197945\n",
      "Policy mu Std                           0.0494479\n",
      "Policy mu Max                           0.20584\n",
      "Policy mu Min                          -0.0971861\n",
      "Policy log std Mean                    -0.127654\n",
      "Policy log std Std                      0.00389487\n",
      "Policy log std Max                     -0.114766\n",
      "Policy log std Min                     -0.134392\n",
      "Z mean eval                             0.0212689\n",
      "Z variance eval                         0.287215\n",
      "AverageTrainReturn_all_train_tasks     -0.0478119\n",
      "AverageReturn_all_train_tasks          -0.0500148\n",
      "AverageReturn_all_test_tasks            0.2165\n",
      "Number of train steps total          9500\n",
      "Number of env steps total           54000\n",
      "Number of rollouts total                0\n",
      "Train Time (s)                         40.6052\n",
      "(Previous) Eval Time (s)                6.9767\n",
      "Sample Time (s)                         5.90586\n",
      "Epoch Time (s)                         53.4878\n",
      "Total Train Time (s)                  905.151\n",
      "Epoch                                  18\n",
      "----------------------------------  --------------\n",
      "2020-06-11 14:25:12.773355 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #18 | Epoch Duration: 54.73732900619507\n",
      "2020-06-11 14:25:12.775354 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #18 | Started Training: True\n",
      "----------------------------------  --------------\n",
      "Z mean train                            0.0231774\n",
      "Z variance train                        0.977456\n",
      "KL Divergence                           0.0273588\n",
      "KL Loss                                 0.00273588\n",
      "QF Loss                                 0.0777431\n",
      "VF Loss                                 0.0909716\n",
      "Policy Loss                           -73.4612\n",
      "Q Predictions Mean                     71.6647\n",
      "Q Predictions Std                       1.01892\n",
      "Q Predictions Max                      73.3602\n",
      "Q Predictions Min                      66.7834\n",
      "V Predictions Mean                     73.4407\n",
      "V Predictions Std                       1.01946\n",
      "V Predictions Max                      74.9565\n",
      "V Predictions Min                      68.213\n",
      "Log Pis Mean                           -2.03927\n",
      "Log Pis Std                             0.237447\n",
      "Log Pis Max                            -1.34053\n",
      "Log Pis Min                            -3.43169\n",
      "Policy mu Mean                          0.029292\n",
      "Policy mu Std                           0.0629754\n",
      "Policy mu Max                           0.244878\n",
      "Policy mu Min                          -0.0822714\n",
      "Policy log std Mean                    -0.122855\n",
      "Policy log std Std                      0.00371679\n",
      "Policy log std Max                     -0.110656\n",
      "Policy log std Min                     -0.137363\n",
      "Z mean eval                             0.0323268\n",
      "Z variance eval                         0.302739\n",
      "AverageTrainReturn_all_train_tasks     -0.0455287\n",
      "AverageReturn_all_train_tasks          -0.0447368\n",
      "AverageReturn_all_test_tasks           -0.0470167\n",
      "Number of train steps total         10000\n",
      "Number of env steps total           56000\n",
      "Number of rollouts total                0\n",
      "Train Time (s)                         37.9943\n",
      "(Previous) Eval Time (s)                8.22595\n",
      "Sample Time (s)                         3.82685\n",
      "Epoch Time (s)                         50.0471\n",
      "Total Train Time (s)                  955.354\n",
      "Epoch                                  19\n",
      "----------------------------------  --------------\n",
      "2020-06-11 14:26:02.972496 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #19 | Epoch Duration: 50.19614315032959\n",
      "2020-06-11 14:26:02.975511 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #19 | Started Training: True\n",
      "----------------------------------  --------------\n",
      "Z mean train                            0.0328794\n",
      "Z variance train                        0.962863\n",
      "KL Divergence                           0.0225615\n",
      "KL Loss                                 0.00225615\n",
      "QF Loss                                 0.282983\n",
      "VF Loss                                 0.16624\n",
      "Policy Loss                           -77.3253\n",
      "Q Predictions Mean                     74.9748\n",
      "Q Predictions Std                       1.04246\n",
      "Q Predictions Max                      76.9633\n",
      "Q Predictions Min                      69.4181\n",
      "V Predictions Mean                     77.6001\n",
      "V Predictions Std                       1.1905\n",
      "V Predictions Max                      79.9738\n",
      "V Predictions Min                      72.1225\n",
      "Log Pis Mean                           -2.04944\n",
      "Log Pis Std                             0.276221\n",
      "Log Pis Max                            -1.26808\n",
      "Log Pis Min                            -5.72354\n",
      "Policy mu Mean                          0.0306207\n",
      "Policy mu Std                           0.0530846\n",
      "Policy mu Max                           0.226078\n",
      "Policy mu Min                          -0.067319\n",
      "Policy log std Mean                    -0.132374\n",
      "Policy log std Std                      0.00419389\n",
      "Policy log std Max                     -0.123756\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy log std Min                     -0.153153\n",
      "Z mean eval                             0.0492399\n",
      "Z variance eval                         0.3134\n",
      "AverageTrainReturn_all_train_tasks     -0.0475221\n",
      "AverageReturn_all_train_tasks          -0.0459763\n",
      "AverageReturn_all_test_tasks           -0.0447107\n",
      "Number of train steps total         10500\n",
      "Number of env steps total           58000\n",
      "Number of rollouts total                0\n",
      "Train Time (s)                         39.6099\n",
      "(Previous) Eval Time (s)                8.37547\n",
      "Sample Time (s)                         3.66357\n",
      "Epoch Time (s)                         51.6489\n",
      "Total Train Time (s)                 1004.86\n",
      "Epoch                                  20\n",
      "----------------------------------  --------------\n",
      "2020-06-11 14:26:52.477662 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #20 | Epoch Duration: 49.50016975402832\n",
      "2020-06-11 14:26:52.478662 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #20 | Started Training: True\n",
      "----------------------------------  --------------\n",
      "Z mean train                            0.0500174\n",
      "Z variance train                        0.995564\n",
      "KL Divergence                           0.0321373\n",
      "KL Loss                                 0.00321373\n",
      "QF Loss                                 0.064188\n",
      "VF Loss                                 0.0761427\n",
      "Policy Loss                           -80.0688\n",
      "Q Predictions Mean                     78.1357\n",
      "Q Predictions Std                       0.992921\n",
      "Q Predictions Max                      79.8562\n",
      "Q Predictions Min                      72.4709\n",
      "V Predictions Mean                     80.21\n",
      "V Predictions Std                       0.975487\n",
      "V Predictions Max                      81.8862\n",
      "V Predictions Min                      74.8692\n",
      "Log Pis Mean                           -2.0498\n",
      "Log Pis Std                             0.247854\n",
      "Log Pis Max                            -1.00649\n",
      "Log Pis Min                            -4.56201\n",
      "Policy mu Mean                          0.0324838\n",
      "Policy mu Std                           0.0612174\n",
      "Policy mu Max                           0.265414\n",
      "Policy mu Min                          -0.120244\n",
      "Policy log std Mean                    -0.13753\n",
      "Policy log std Std                      0.00622467\n",
      "Policy log std Max                     -0.125378\n",
      "Policy log std Min                     -0.15147\n",
      "Z mean eval                             0.0233288\n",
      "Z variance eval                         0.267524\n",
      "AverageTrainReturn_all_train_tasks     -0.0460328\n",
      "AverageReturn_all_train_tasks          -0.0474828\n",
      "AverageReturn_all_test_tasks            0.878222\n",
      "Number of train steps total         11000\n",
      "Number of env steps total           60000\n",
      "Number of rollouts total                0\n",
      "Train Time (s)                         37.0396\n",
      "(Previous) Eval Time (s)                6.22675\n",
      "Sample Time (s)                         3.67813\n",
      "Epoch Time (s)                         46.9444\n",
      "Total Train Time (s)                 1051.64\n",
      "Epoch                                  21\n",
      "----------------------------------  --------------\n",
      "2020-06-11 14:27:39.247995 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #21 | Epoch Duration: 46.768332719802856\n",
      "2020-06-11 14:27:39.248994 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #21 | Started Training: True\n",
      "----------------------------------  --------------\n",
      "Z mean train                            0.0241738\n",
      "Z variance train                        0.867373\n",
      "KL Divergence                           0.139092\n",
      "KL Loss                                 0.0139092\n",
      "QF Loss                                 0.0412132\n",
      "VF Loss                                 0.339552\n",
      "Policy Loss                           -82.445\n",
      "Q Predictions Mean                     80.3848\n",
      "Q Predictions Std                       1.15158\n",
      "Q Predictions Max                      82.6902\n",
      "Q Predictions Min                      74.2279\n",
      "V Predictions Mean                     81.8998\n",
      "V Predictions Std                       1.08652\n",
      "V Predictions Max                      84.3141\n",
      "V Predictions Min                      75.8388\n",
      "Log Pis Mean                           -2.04754\n",
      "Log Pis Std                             0.234895\n",
      "Log Pis Max                            -1.24494\n",
      "Log Pis Min                            -3.3264\n",
      "Policy mu Mean                          0.0269488\n",
      "Policy mu Std                           0.0631023\n",
      "Policy mu Max                           0.283404\n",
      "Policy mu Min                          -0.105946\n",
      "Policy log std Mean                    -0.134095\n",
      "Policy log std Std                      0.00328172\n",
      "Policy log std Max                     -0.123383\n",
      "Policy log std Min                     -0.14681\n",
      "Z mean eval                             0.0424205\n",
      "Z variance eval                         0.287544\n",
      "AverageTrainReturn_all_train_tasks     -0.0565371\n",
      "AverageReturn_all_train_tasks          -0.0552025\n",
      "AverageReturn_all_test_tasks           -0.0523428\n",
      "Number of train steps total         11500\n",
      "Number of env steps total           62000\n",
      "Number of rollouts total                0\n",
      "Train Time (s)                         34.5631\n",
      "(Previous) Eval Time (s)                6.05114\n",
      "Sample Time (s)                         3.89657\n",
      "Epoch Time (s)                         44.5108\n",
      "Total Train Time (s)                 1097.65\n",
      "Epoch                                  22\n",
      "----------------------------------  --------------\n",
      "2020-06-11 14:28:25.269872 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #22 | Epoch Duration: 46.01987838745117\n",
      "2020-06-11 14:28:25.270870 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #22 | Started Training: True\n",
      "----------------------------------  --------------\n",
      "Z mean train                            0.0417647\n",
      "Z variance train                        0.88419\n",
      "KL Divergence                           0.0806581\n",
      "KL Loss                                 0.00806582\n",
      "QF Loss                                 0.223149\n",
      "VF Loss                                 0.3521\n",
      "Policy Loss                           -85.3227\n",
      "Q Predictions Mean                     83.2705\n",
      "Q Predictions Std                       1.21367\n",
      "Q Predictions Max                      85.5543\n",
      "Q Predictions Min                      75.9091\n",
      "V Predictions Mean                     85.1537\n",
      "V Predictions Std                       1.10793\n",
      "V Predictions Max                      87.0913\n",
      "V Predictions Min                      78.4201\n",
      "Log Pis Mean                           -2.0355\n",
      "Log Pis Std                             0.243694\n",
      "Log Pis Max                            -1.28547\n",
      "Log Pis Min                            -3.87598\n",
      "Policy mu Mean                          0.0263824\n",
      "Policy mu Std                           0.0644701\n",
      "Policy mu Max                           0.27185\n",
      "Policy mu Min                          -0.0935809\n",
      "Policy log std Mean                    -0.125518\n",
      "Policy log std Std                      0.00548403\n",
      "Policy log std Max                     -0.11039\n",
      "Policy log std Min                     -0.151461\n",
      "Z mean eval                             0.027732\n",
      "Z variance eval                         0.31354\n",
      "AverageTrainReturn_all_train_tasks     -0.0589138\n",
      "AverageReturn_all_train_tasks           0.959317\n",
      "AverageReturn_all_test_tasks            0.221181\n",
      "Number of train steps total         12000\n",
      "Number of env steps total           64000\n",
      "Number of rollouts total                0\n",
      "Train Time (s)                         32.5377\n",
      "(Previous) Eval Time (s)                7.56006\n",
      "Sample Time (s)                         3.55215\n",
      "Epoch Time (s)                         43.6499\n",
      "Total Train Time (s)                 1139.55\n",
      "Epoch                                  23\n",
      "----------------------------------  --------------\n",
      "2020-06-11 14:29:07.160942 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #23 | Epoch Duration: 41.88907170295715\n",
      "2020-06-11 14:29:07.161941 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #23 | Started Training: True\n",
      "----------------------------------  --------------\n",
      "Z mean train                            0.0275526\n",
      "Z variance train                        0.976283\n",
      "KL Divergence                           0.0159346\n",
      "KL Loss                                 0.00159346\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QF Loss                                 0.124141\n",
      "VF Loss                                 0.341874\n",
      "Policy Loss                           -88.9727\n",
      "Q Predictions Mean                     87.2044\n",
      "Q Predictions Std                       1.20828\n",
      "Q Predictions Max                      89.3226\n",
      "Q Predictions Min                      81.2748\n",
      "V Predictions Mean                     89.4286\n",
      "V Predictions Std                       1.20914\n",
      "V Predictions Max                      91.5082\n",
      "V Predictions Min                      83.8293\n",
      "Log Pis Mean                           -2.04164\n",
      "Log Pis Std                             0.236006\n",
      "Log Pis Max                            -1.24606\n",
      "Log Pis Min                            -3.66204\n",
      "Policy mu Mean                          0.033699\n",
      "Policy mu Std                           0.0624777\n",
      "Policy mu Max                           0.299389\n",
      "Policy mu Min                          -0.0952353\n",
      "Policy log std Mean                    -0.129403\n",
      "Policy log std Std                      0.00500276\n",
      "Policy log std Max                     -0.114211\n",
      "Policy log std Min                     -0.140973\n",
      "Z mean eval                             0.0612627\n",
      "Z variance eval                         0.288228\n",
      "AverageTrainReturn_all_train_tasks      3.52073\n",
      "AverageReturn_all_train_tasks          -0.0509794\n",
      "AverageReturn_all_test_tasks            0.335582\n",
      "Number of train steps total         12500\n",
      "Number of env steps total           66000\n",
      "Number of rollouts total                0\n",
      "Train Time (s)                         32.5806\n",
      "(Previous) Eval Time (s)                5.79876\n",
      "Sample Time (s)                         3.5301\n",
      "Epoch Time (s)                         41.9094\n",
      "Total Train Time (s)                 1181.71\n",
      "Epoch                                  24\n",
      "----------------------------------  --------------\n",
      "2020-06-11 14:29:49.327051 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #24 | Epoch Duration: 42.16510987281799\n",
      "2020-06-11 14:29:49.327051 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #24 | Started Training: True\n",
      "----------------------------------  --------------\n",
      "Z mean train                            0.0636602\n",
      "Z variance train                        0.93568\n",
      "KL Divergence                           0.101647\n",
      "KL Loss                                 0.0101647\n",
      "QF Loss                                 0.750227\n",
      "VF Loss                                 0.514549\n",
      "Policy Loss                           -90.8557\n",
      "Q Predictions Mean                     89.7099\n",
      "Q Predictions Std                       1.40736\n",
      "Q Predictions Max                      92.5504\n",
      "Q Predictions Min                      84.1649\n",
      "V Predictions Mean                     91.2745\n",
      "V Predictions Std                       1.09776\n",
      "V Predictions Max                      93.374\n",
      "V Predictions Min                      85.3536\n",
      "Log Pis Mean                           -2.02759\n",
      "Log Pis Std                             0.250987\n",
      "Log Pis Max                            -1.08162\n",
      "Log Pis Min                            -4.72798\n",
      "Policy mu Mean                          0.0399926\n",
      "Policy mu Std                           0.0664747\n",
      "Policy mu Max                           0.297502\n",
      "Policy mu Min                          -0.0958467\n",
      "Policy log std Mean                    -0.126092\n",
      "Policy log std Std                      0.00546434\n",
      "Policy log std Max                     -0.115895\n",
      "Policy log std Min                     -0.143182\n",
      "Z mean eval                             0.0361453\n",
      "Z variance eval                         0.336673\n",
      "AverageTrainReturn_all_train_tasks     -0.0535555\n",
      "AverageReturn_all_train_tasks          -0.0552124\n",
      "AverageReturn_all_test_tasks           -0.056135\n",
      "Number of train steps total         13000\n",
      "Number of env steps total           68000\n",
      "Number of rollouts total                0\n",
      "Train Time (s)                         44.1342\n",
      "(Previous) Eval Time (s)                6.05347\n",
      "Sample Time (s)                         3.53683\n",
      "Epoch Time (s)                         53.7245\n",
      "Total Train Time (s)                 1236.09\n",
      "Epoch                                  25\n",
      "----------------------------------  --------------\n",
      "2020-06-11 14:30:43.702497 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #25 | Epoch Duration: 54.374446868896484\n",
      "2020-06-11 14:30:43.703497 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #25 | Started Training: True\n",
      "----------------------------------  --------------\n",
      "Z mean train                            0.0356144\n",
      "Z variance train                        1.03401\n",
      "KL Divergence                           0.0163865\n",
      "KL Loss                                 0.00163865\n",
      "QF Loss                                 0.209361\n",
      "VF Loss                                 0.112601\n",
      "Policy Loss                           -94.5956\n",
      "Q Predictions Mean                     92.6509\n",
      "Q Predictions Std                       1.60127\n",
      "Q Predictions Max                      96.0445\n",
      "Q Predictions Min                      86.4229\n",
      "V Predictions Mean                     94.4182\n",
      "V Predictions Std                       1.53615\n",
      "V Predictions Max                      97.1897\n",
      "V Predictions Min                      88.3001\n",
      "Log Pis Mean                           -2.034\n",
      "Log Pis Std                             0.246816\n",
      "Log Pis Max                            -1.07005\n",
      "Log Pis Min                            -3.84556\n",
      "Policy mu Mean                          0.0390507\n",
      "Policy mu Std                           0.064787\n",
      "Policy mu Max                           0.288496\n",
      "Policy mu Min                          -0.110707\n",
      "Policy log std Mean                    -0.12736\n",
      "Policy log std Std                      0.00464801\n",
      "Policy log std Max                     -0.115415\n",
      "Policy log std Min                     -0.141307\n",
      "Z mean eval                             0.0190303\n",
      "Z variance eval                         0.317749\n",
      "AverageTrainReturn_all_train_tasks     -0.0510311\n",
      "AverageReturn_all_train_tasks          -0.0529047\n",
      "AverageReturn_all_test_tasks           -0.0528721\n",
      "Number of train steps total         13500\n",
      "Number of env steps total           70000\n",
      "Number of rollouts total                0\n",
      "Train Time (s)                         37.1022\n",
      "(Previous) Eval Time (s)                6.70291\n",
      "Sample Time (s)                         3.60158\n",
      "Epoch Time (s)                         47.4067\n",
      "Total Train Time (s)                 1285.05\n",
      "Epoch                                  26\n",
      "----------------------------------  --------------\n",
      "2020-06-11 14:31:32.665376 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #26 | Epoch Duration: 48.9608793258667\n",
      "2020-06-11 14:31:32.666376 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #26 | Started Training: True\n",
      "----------------------------------  ---------------\n",
      "Z mean train                            0.019204\n",
      "Z variance train                        1.00159\n",
      "KL Divergence                           0.00756738\n",
      "KL Loss                                 0.000756739\n",
      "QF Loss                                 0.0585159\n",
      "VF Loss                                 0.0611801\n",
      "Policy Loss                           -95.4939\n",
      "Q Predictions Mean                     93.5778\n",
      "Q Predictions Std                       1.18675\n",
      "Q Predictions Max                      95.7787\n",
      "Q Predictions Min                      84.8109\n",
      "V Predictions Mean                     95.5213\n",
      "V Predictions Std                       1.19308\n",
      "V Predictions Max                      97.623\n",
      "V Predictions Min                      86.7946\n",
      "Log Pis Mean                           -2.04528\n",
      "Log Pis Std                             0.274401\n",
      "Log Pis Max                            -0.992088\n",
      "Log Pis Min                            -4.51337\n",
      "Policy mu Mean                          0.0406964\n",
      "Policy mu Std                           0.0683244\n",
      "Policy mu Max                           0.30062\n",
      "Policy mu Min                          -0.107319\n",
      "Policy log std Mean                    -0.131199\n",
      "Policy log std Std                      0.00496804\n",
      "Policy log std Max                     -0.121536\n",
      "Policy log std Min                     -0.158765\n",
      "Z mean eval                             0.0195679\n",
      "Z variance eval                         0.273324\n",
      "AverageTrainReturn_all_train_tasks     -0.0544844\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AverageReturn_all_train_tasks          -0.0527025\n",
      "AverageReturn_all_test_tasks           -0.0552516\n",
      "Number of train steps total         14000\n",
      "Number of env steps total           72000\n",
      "Number of rollouts total                0\n",
      "Train Time (s)                         37.6399\n",
      "(Previous) Eval Time (s)                8.25707\n",
      "Sample Time (s)                         6.13546\n",
      "Epoch Time (s)                         52.0325\n",
      "Total Train Time (s)                 1335.55\n",
      "Epoch                                  27\n",
      "----------------------------------  ---------------\n",
      "2020-06-11 14:32:23.165883 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #27 | Epoch Duration: 50.498507261276245\n",
      "2020-06-11 14:32:23.165883 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #27 | Started Training: True\n",
      "----------------------------------  --------------\n",
      "Z mean train                            0.0197218\n",
      "Z variance train                        0.859758\n",
      "KL Divergence                           0.102477\n",
      "KL Loss                                 0.0102477\n",
      "QF Loss                                 0.0793727\n",
      "VF Loss                                 0.213943\n",
      "Policy Loss                           -98.3684\n",
      "Q Predictions Mean                     96.4152\n",
      "Q Predictions Std                       1.21491\n",
      "Q Predictions Max                      98.735\n",
      "Q Predictions Min                      87.4325\n",
      "V Predictions Mean                     98.633\n",
      "V Predictions Std                       1.26798\n",
      "V Predictions Max                     100.854\n",
      "V Predictions Min                      90.0677\n",
      "Log Pis Mean                           -2.03409\n",
      "Log Pis Std                             0.279859\n",
      "Log Pis Max                            -0.946517\n",
      "Log Pis Min                            -4.50167\n",
      "Policy mu Mean                          0.0365661\n",
      "Policy mu Std                           0.0732194\n",
      "Policy mu Max                           0.327669\n",
      "Policy mu Min                          -0.0980686\n",
      "Policy log std Mean                    -0.133555\n",
      "Policy log std Std                      0.00762258\n",
      "Policy log std Max                     -0.11726\n",
      "Policy log std Min                     -0.150775\n",
      "Z mean eval                             0.0138625\n",
      "Z variance eval                         0.333464\n",
      "AverageTrainReturn_all_train_tasks     -0.0504019\n",
      "AverageReturn_all_train_tasks          -0.0489489\n",
      "AverageReturn_all_test_tasks           -0.0475686\n",
      "Number of train steps total         14500\n",
      "Number of env steps total           74000\n",
      "Number of rollouts total                0\n",
      "Train Time (s)                         33.5504\n",
      "(Previous) Eval Time (s)                6.72242\n",
      "Sample Time (s)                         3.85833\n",
      "Epoch Time (s)                         44.1311\n",
      "Total Train Time (s)                 1379.2\n",
      "Epoch                                  28\n",
      "----------------------------------  --------------\n",
      "2020-06-11 14:33:06.815299 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #28 | Epoch Duration: 43.6484169960022\n",
      "2020-06-11 14:33:06.817300 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #28 | Started Training: True\n",
      "----------------------------------  ---------------\n",
      "Z mean train                            0.0135823\n",
      "Z variance train                        1.0202\n",
      "KL Divergence                           0.00525363\n",
      "KL Loss                                 0.000525363\n",
      "QF Loss                                 0.129654\n",
      "VF Loss                                 0.0880809\n",
      "Policy Loss                          -100.462\n",
      "Q Predictions Mean                     98.454\n",
      "Q Predictions Std                       1.27639\n",
      "Q Predictions Max                     100.443\n",
      "Q Predictions Min                      88.5298\n",
      "V Predictions Mean                    100.505\n",
      "V Predictions Std                       1.36521\n",
      "V Predictions Max                     102.793\n",
      "V Predictions Min                      89.6904\n",
      "Log Pis Mean                           -2.03843\n",
      "Log Pis Std                             0.244544\n",
      "Log Pis Max                            -1.04692\n",
      "Log Pis Min                            -3.74837\n",
      "Policy mu Mean                          0.0247173\n",
      "Policy mu Std                           0.0791791\n",
      "Policy mu Max                           0.32364\n",
      "Policy mu Min                          -0.126376\n",
      "Policy log std Mean                    -0.135268\n",
      "Policy log std Std                      0.00655722\n",
      "Policy log std Max                     -0.119736\n",
      "Policy log std Min                     -0.165212\n",
      "Z mean eval                             0.0191588\n",
      "Z variance eval                         0.309218\n",
      "AverageTrainReturn_all_train_tasks     -0.0476526\n",
      "AverageReturn_all_train_tasks          -0.0491044\n",
      "AverageReturn_all_test_tasks           -0.0462651\n",
      "Number of train steps total         15000\n",
      "Number of env steps total           76000\n",
      "Number of rollouts total                0\n",
      "Train Time (s)                         35.7197\n",
      "(Previous) Eval Time (s)                6.23926\n",
      "Sample Time (s)                         3.81834\n",
      "Epoch Time (s)                         45.7773\n",
      "Total Train Time (s)                 1426.37\n",
      "Epoch                                  29\n",
      "----------------------------------  ---------------\n",
      "2020-06-11 14:33:53.989976 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #29 | Epoch Duration: 47.17167901992798\n",
      "2020-06-11 14:33:53.990976 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #29 | Started Training: True\n",
      "----------------------------------  --------------\n",
      "Z mean train                            0.0196369\n",
      "Z variance train                        0.98889\n",
      "KL Divergence                           0.0118544\n",
      "KL Loss                                 0.00118544\n",
      "QF Loss                                 0.100704\n",
      "VF Loss                                 0.123745\n",
      "Policy Loss                          -102.994\n",
      "Q Predictions Mean                    100.966\n",
      "Q Predictions Std                       1.32314\n",
      "Q Predictions Max                     103.912\n",
      "Q Predictions Min                      93.8918\n",
      "V Predictions Mean                    102.732\n",
      "V Predictions Std                       1.34558\n",
      "V Predictions Max                     105.75\n",
      "V Predictions Min                      94.978\n",
      "Log Pis Mean                           -2.02697\n",
      "Log Pis Std                             0.255846\n",
      "Log Pis Max                            -1.05937\n",
      "Log Pis Min                            -4.31207\n",
      "Policy mu Mean                          0.0449747\n",
      "Policy mu Std                           0.0737177\n",
      "Policy mu Max                           0.332144\n",
      "Policy mu Min                          -0.108733\n",
      "Policy log std Mean                    -0.136612\n",
      "Policy log std Std                      0.00513276\n",
      "Policy log std Max                     -0.120084\n",
      "Policy log std Min                     -0.169354\n",
      "Z mean eval                             0.0513993\n",
      "Z variance eval                         0.275589\n",
      "AverageTrainReturn_all_train_tasks     -0.0454588\n",
      "AverageReturn_all_train_tasks          -0.0465111\n",
      "AverageReturn_all_test_tasks           -0.0490662\n",
      "Number of train steps total         15500\n",
      "Number of env steps total           78000\n",
      "Number of rollouts total                0\n",
      "Train Time (s)                         36.9679\n",
      "(Previous) Eval Time (s)                7.63271\n",
      "Sample Time (s)                         4.85488\n",
      "Epoch Time (s)                         49.4555\n",
      "Total Train Time (s)                 1474.79\n",
      "Epoch                                  30\n",
      "----------------------------------  --------------\n",
      "2020-06-11 14:34:42.416176 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #30 | Epoch Duration: 48.424200773239136\n",
      "2020-06-11 14:34:42.417177 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #30 | Started Training: True\n",
      "----------------------------------  --------------\n",
      "Z mean train                            0.0513272\n",
      "Z variance train                        0.861655\n",
      "KL Divergence                           0.123269\n",
      "KL Loss                                 0.0123269\n",
      "QF Loss                                 0.107842\n",
      "VF Loss                                 0.222249\n",
      "Policy Loss                          -104.893\n",
      "Q Predictions Mean                    102.863\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q Predictions Std                       1.26707\n",
      "Q Predictions Max                     105.234\n",
      "Q Predictions Min                      94.694\n",
      "V Predictions Mean                    105.222\n",
      "V Predictions Std                       1.28929\n",
      "V Predictions Max                     107.264\n",
      "V Predictions Min                      97.2129\n",
      "Log Pis Mean                           -2.02372\n",
      "Log Pis Std                             0.250479\n",
      "Log Pis Max                            -1.00496\n",
      "Log Pis Min                            -3.90086\n",
      "Policy mu Mean                          0.0389025\n",
      "Policy mu Std                           0.0768279\n",
      "Policy mu Max                           0.339414\n",
      "Policy mu Min                          -0.115444\n",
      "Policy log std Mean                    -0.128067\n",
      "Policy log std Std                      0.00503247\n",
      "Policy log std Max                     -0.112209\n",
      "Policy log std Min                     -0.137481\n",
      "Z mean eval                             0.0224944\n",
      "Z variance eval                         0.258778\n",
      "AverageTrainReturn_all_train_tasks     -0.0516064\n",
      "AverageReturn_all_train_tasks          -0.0486497\n",
      "AverageReturn_all_test_tasks           -0.0499682\n",
      "Number of train steps total         16000\n",
      "Number of env steps total           80000\n",
      "Number of rollouts total                0\n",
      "Train Time (s)                         32.9542\n",
      "(Previous) Eval Time (s)                6.60124\n",
      "Sample Time (s)                         3.82799\n",
      "Epoch Time (s)                         43.3834\n",
      "Total Train Time (s)                 1518.35\n",
      "Epoch                                  31\n",
      "----------------------------------  --------------\n",
      "2020-06-11 14:35:25.971421 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #31 | Epoch Duration: 43.553245544433594\n",
      "2020-06-11 14:35:25.972421 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #31 | Started Training: True\n",
      "----------------------------------  --------------\n",
      "Z mean train                            0.0231811\n",
      "Z variance train                        0.834551\n",
      "KL Divergence                           0.168491\n",
      "KL Loss                                 0.0168491\n",
      "QF Loss                                 3.19092\n",
      "VF Loss                                 0.442607\n",
      "Policy Loss                          -107.077\n",
      "Q Predictions Mean                    105.134\n",
      "Q Predictions Std                       1.40359\n",
      "Q Predictions Max                     108.044\n",
      "Q Predictions Min                      96.0177\n",
      "V Predictions Mean                    107.229\n",
      "V Predictions Std                       1.5458\n",
      "V Predictions Max                     110.164\n",
      "V Predictions Min                      98.8727\n",
      "Log Pis Mean                           -2.03881\n",
      "Log Pis Std                             0.273014\n",
      "Log Pis Max                            -1.02734\n",
      "Log Pis Min                            -4.40799\n",
      "Policy mu Mean                          0.0314412\n",
      "Policy mu Std                           0.0915031\n",
      "Policy mu Max                           0.366512\n",
      "Policy mu Min                          -0.125423\n",
      "Policy log std Mean                    -0.137379\n",
      "Policy log std Std                      0.00816764\n",
      "Policy log std Max                     -0.115956\n",
      "Policy log std Min                     -0.159735\n",
      "Z mean eval                             0.058788\n",
      "Z variance eval                         0.258058\n",
      "AverageTrainReturn_all_train_tasks     -0.0466942\n",
      "AverageReturn_all_train_tasks           0.178715\n",
      "AverageReturn_all_test_tasks            0.801811\n",
      "Number of train steps total         16500\n",
      "Number of env steps total           82000\n",
      "Number of rollouts total                0\n",
      "Train Time (s)                         38.9853\n",
      "(Previous) Eval Time (s)                6.77049\n",
      "Sample Time (s)                         4.45683\n",
      "Epoch Time (s)                         50.2127\n",
      "Total Train Time (s)                 1568.88\n",
      "Epoch                                  32\n",
      "----------------------------------  --------------\n",
      "2020-06-11 14:36:16.508733 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #32 | Epoch Duration: 50.536312103271484\n",
      "2020-06-11 14:36:16.509732 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #32 | Started Training: True\n",
      "----------------------------------  --------------\n",
      "Z mean train                            0.060194\n",
      "Z variance train                        0.825658\n",
      "KL Divergence                           0.240998\n",
      "KL Loss                                 0.0240998\n",
      "QF Loss                                 0.0886226\n",
      "VF Loss                                 0.0852306\n",
      "Policy Loss                          -109.239\n",
      "Q Predictions Mean                    107.166\n",
      "Q Predictions Std                       1.37651\n",
      "Q Predictions Max                     109.991\n",
      "Q Predictions Min                      97.0476\n",
      "V Predictions Mean                    109.123\n",
      "V Predictions Std                       1.33784\n",
      "V Predictions Max                     111.761\n",
      "V Predictions Min                      99.1399\n",
      "Log Pis Mean                           -2.02869\n",
      "Log Pis Std                             0.251391\n",
      "Log Pis Max                            -1.03194\n",
      "Log Pis Min                            -3.47346\n",
      "Policy mu Mean                          0.0468879\n",
      "Policy mu Std                           0.0762327\n",
      "Policy mu Max                           0.354496\n",
      "Policy mu Min                          -0.108562\n",
      "Policy log std Mean                    -0.137178\n",
      "Policy log std Std                      0.00493301\n",
      "Policy log std Max                     -0.114314\n",
      "Policy log std Min                     -0.156615\n",
      "Z mean eval                             0.0153981\n",
      "Z variance eval                         0.287675\n",
      "AverageTrainReturn_all_train_tasks     -0.0459239\n",
      "AverageReturn_all_train_tasks          -0.0487087\n",
      "AverageReturn_all_test_tasks            0.289852\n",
      "Number of train steps total         17000\n",
      "Number of env steps total           84000\n",
      "Number of rollouts total                0\n",
      "Train Time (s)                         35.2925\n",
      "(Previous) Eval Time (s)                7.09332\n",
      "Sample Time (s)                         4.24995\n",
      "Epoch Time (s)                         46.6358\n",
      "Total Train Time (s)                 1615.53\n",
      "Epoch                                  33\n",
      "----------------------------------  --------------\n",
      "2020-06-11 14:37:03.145103 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #33 | Epoch Duration: 46.63437223434448\n",
      "2020-06-11 14:37:03.146104 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #33 | Started Training: True\n",
      "----------------------------------  --------------\n",
      "Z mean train                            0.0165712\n",
      "Z variance train                        0.964357\n",
      "KL Divergence                           0.0249619\n",
      "KL Loss                                 0.00249619\n",
      "QF Loss                                 0.0840445\n",
      "VF Loss                                 0.0435554\n",
      "Policy Loss                          -111.769\n",
      "Q Predictions Mean                    109.702\n",
      "Q Predictions Std                       1.24808\n",
      "Q Predictions Max                     111.866\n",
      "Q Predictions Min                     100.12\n",
      "V Predictions Mean                    111.815\n",
      "V Predictions Std                       1.26279\n",
      "V Predictions Max                     114.041\n",
      "V Predictions Min                     102.807\n",
      "Log Pis Mean                           -2.04493\n",
      "Log Pis Std                             0.268844\n",
      "Log Pis Max                            -1.06934\n",
      "Log Pis Min                            -3.53248\n",
      "Policy mu Mean                          0.0465544\n",
      "Policy mu Std                           0.0800697\n",
      "Policy mu Max                           0.355266\n",
      "Policy mu Min                          -0.117029\n",
      "Policy log std Mean                    -0.131707\n",
      "Policy log std Std                      0.00569659\n",
      "Policy log std Max                     -0.120297\n",
      "Policy log std Min                     -0.169693\n",
      "Z mean eval                             0.0131958\n",
      "Z variance eval                         0.28309\n",
      "AverageTrainReturn_all_train_tasks     -0.0471129\n",
      "AverageReturn_all_train_tasks          -0.0481499\n",
      "AverageReturn_all_test_tasks           -0.0476898\n",
      "Number of train steps total         17500\n",
      "Number of env steps total           86000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rollouts total                0\n",
      "Train Time (s)                        171.872\n",
      "(Previous) Eval Time (s)                7.09211\n",
      "Sample Time (s)                         4.47891\n",
      "Epoch Time (s)                        183.443\n",
      "Total Train Time (s)                 1797.7\n",
      "Epoch                                  34\n",
      "----------------------------------  --------------\n",
      "2020-06-11 14:39:53.781809 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #34 | Epoch Duration: 170.63470554351807\n",
      "2020-06-11 14:39:53.786806 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #34 | Started Training: True\n",
      "----------------------------------  --------------\n",
      "Z mean train                            0.0132421\n",
      "Z variance train                        0.924443\n",
      "KL Divergence                           0.0284844\n",
      "KL Loss                                 0.00284844\n",
      "QF Loss                                 0.0950257\n",
      "VF Loss                                 0.236062\n",
      "Policy Loss                          -113.172\n",
      "Q Predictions Mean                    111.298\n",
      "Q Predictions Std                       1.45763\n",
      "Q Predictions Max                     114.014\n",
      "Q Predictions Min                     102.111\n",
      "V Predictions Mean                    113.475\n",
      "V Predictions Std                       1.49452\n",
      "V Predictions Max                     116.16\n",
      "V Predictions Min                     105.7\n",
      "Log Pis Mean                           -2.0431\n",
      "Log Pis Std                             0.268521\n",
      "Log Pis Max                            -0.968393\n",
      "Log Pis Min                            -3.87979\n",
      "Policy mu Mean                          0.0315583\n",
      "Policy mu Std                           0.086658\n",
      "Policy mu Max                           0.348878\n",
      "Policy mu Min                          -0.125945\n",
      "Policy log std Mean                    -0.13648\n",
      "Policy log std Std                      0.00438515\n",
      "Policy log std Max                     -0.120782\n",
      "Policy log std Min                     -0.156763\n",
      "Z mean eval                             0.0201709\n",
      "Z variance eval                         0.289348\n",
      "AverageTrainReturn_all_train_tasks     -0.0480152\n",
      "AverageReturn_all_train_tasks          -0.048205\n",
      "AverageReturn_all_test_tasks           -0.0457183\n",
      "Number of train steps total         18000\n",
      "Number of env steps total           88000\n",
      "Number of rollouts total                0\n",
      "Train Time (s)                         32.1493\n",
      "(Previous) Eval Time (s)                5.83329\n",
      "Sample Time (s)                         3.28422\n",
      "Epoch Time (s)                         41.2668\n",
      "Total Train Time (s)                 1839.76\n",
      "Epoch                                  35\n",
      "----------------------------------  --------------\n",
      "2020-06-11 14:40:35.836508 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #35 | Epoch Duration: 42.04870367050171\n",
      "2020-06-11 14:40:35.838507 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #35 | Started Training: True\n",
      "----------------------------------  ---------------\n",
      "Z mean train                            0.0209677\n",
      "Z variance train                        0.950307\n",
      "KL Divergence                           0.021265\n",
      "KL Loss                                 0.0021265\n",
      "QF Loss                                 0.145149\n",
      "VF Loss                                 0.196648\n",
      "Policy Loss                          -115.195\n",
      "Q Predictions Mean                    113.125\n",
      "Q Predictions Std                       1.32203\n",
      "Q Predictions Max                     115.457\n",
      "Q Predictions Min                     106.48\n",
      "V Predictions Mean                    115.433\n",
      "V Predictions Std                       1.33861\n",
      "V Predictions Max                     117.791\n",
      "V Predictions Min                     109.103\n",
      "Log Pis Mean                           -2.04357\n",
      "Log Pis Std                             0.282482\n",
      "Log Pis Max                            -1.09372\n",
      "Log Pis Min                            -4.8407\n",
      "Policy mu Mean                          0.0408622\n",
      "Policy mu Std                           0.0771295\n",
      "Policy mu Max                           0.316385\n",
      "Policy mu Min                          -0.120025\n",
      "Policy log std Mean                    -0.134244\n",
      "Policy log std Std                      0.00504152\n",
      "Policy log std Max                     -0.121448\n",
      "Policy log std Min                     -0.161903\n",
      "Z mean eval                             0.0189237\n",
      "Z variance eval                         0.283004\n",
      "AverageTrainReturn_all_train_tasks     -0.0472069\n",
      "AverageReturn_all_train_tasks           0.000402487\n",
      "AverageReturn_all_test_tasks            0.815172\n",
      "Number of train steps total         18500\n",
      "Number of env steps total           90000\n",
      "Number of rollouts total                0\n",
      "Train Time (s)                         30.8697\n",
      "(Previous) Eval Time (s)                6.61499\n",
      "Sample Time (s)                         3.95305\n",
      "Epoch Time (s)                         41.4378\n",
      "Total Train Time (s)                 1880.19\n",
      "Epoch                                  36\n",
      "----------------------------------  ---------------\n",
      "2020-06-11 14:41:16.273552 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #36 | Epoch Duration: 40.4340455532074\n",
      "2020-06-11 14:41:16.275552 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #36 | Started Training: True\n",
      "----------------------------------  --------------\n",
      "Z mean train                            0.0197404\n",
      "Z variance train                        0.915931\n",
      "KL Divergence                           0.0489272\n",
      "KL Loss                                 0.00489272\n",
      "QF Loss                                 0.176188\n",
      "VF Loss                                 0.078541\n",
      "Policy Loss                          -117.343\n",
      "Q Predictions Mean                    115.293\n",
      "Q Predictions Std                       1.57711\n",
      "Q Predictions Max                     118.734\n",
      "Q Predictions Min                     107.918\n",
      "V Predictions Mean                    117.336\n",
      "V Predictions Std                       1.48425\n",
      "V Predictions Max                     120.567\n",
      "V Predictions Min                     110.294\n",
      "Log Pis Mean                           -2.02601\n",
      "Log Pis Std                             0.287769\n",
      "Log Pis Max                            -0.968739\n",
      "Log Pis Min                            -3.42839\n",
      "Policy mu Mean                          0.0553915\n",
      "Policy mu Std                           0.0904033\n",
      "Policy mu Max                           0.374264\n",
      "Policy mu Min                          -0.128059\n",
      "Policy log std Mean                    -0.128959\n",
      "Policy log std Std                      0.00760343\n",
      "Policy log std Max                     -0.108065\n",
      "Policy log std Min                     -0.168199\n",
      "Z mean eval                             0.0400422\n",
      "Z variance eval                         0.282976\n",
      "AverageTrainReturn_all_train_tasks     -0.053331\n",
      "AverageReturn_all_train_tasks          -0.0505526\n",
      "AverageReturn_all_test_tasks            1.60068\n",
      "Number of train steps total         19000\n",
      "Number of env steps total           92000\n",
      "Number of rollouts total                0\n",
      "Train Time (s)                         30.6653\n",
      "(Previous) Eval Time (s)                5.61091\n",
      "Sample Time (s)                         3.25796\n",
      "Epoch Time (s)                         39.5341\n",
      "Total Train Time (s)                 1919.8\n",
      "Epoch                                  37\n",
      "----------------------------------  --------------\n",
      "2020-06-11 14:41:55.884330 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #37 | Epoch Duration: 39.60677933692932\n",
      "2020-06-11 14:41:55.886328 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #37 | Started Training: True\n",
      "----------------------------------  --------------\n",
      "Z mean train                            0.0414805\n",
      "Z variance train                        0.922111\n",
      "KL Divergence                           0.0541788\n",
      "KL Loss                                 0.00541788\n",
      "QF Loss                                 0.479436\n",
      "VF Loss                                 0.127858\n",
      "Policy Loss                          -119.318\n",
      "Q Predictions Mean                    117.414\n",
      "Q Predictions Std                       1.80532\n",
      "Q Predictions Max                     121.085\n",
      "Q Predictions Min                     108.446\n",
      "V Predictions Mean                    119.076\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V Predictions Std                       1.80334\n",
      "V Predictions Max                     122.549\n",
      "V Predictions Min                     110.313\n",
      "Log Pis Mean                           -2.02337\n",
      "Log Pis Std                             0.271238\n",
      "Log Pis Max                            -1.05301\n",
      "Log Pis Min                            -3.28658\n",
      "Policy mu Mean                          0.0458501\n",
      "Policy mu Std                           0.0826144\n",
      "Policy mu Max                           0.346956\n",
      "Policy mu Min                          -0.123517\n",
      "Policy log std Mean                    -0.128211\n",
      "Policy log std Std                      0.00533769\n",
      "Policy log std Max                     -0.115781\n",
      "Policy log std Min                     -0.147654\n",
      "Z mean eval                             0.0325499\n",
      "Z variance eval                         0.203126\n",
      "AverageTrainReturn_all_train_tasks     -0.0476429\n",
      "AverageReturn_all_train_tasks          -0.044982\n",
      "AverageReturn_all_test_tasks           -0.0467084\n",
      "Number of train steps total         19500\n",
      "Number of env steps total           94000\n",
      "Number of rollouts total                0\n",
      "Train Time (s)                         30.7661\n",
      "(Previous) Eval Time (s)                5.68383\n",
      "Sample Time (s)                         3.28826\n",
      "Epoch Time (s)                         39.7382\n",
      "Total Train Time (s)                 1959.48\n",
      "Epoch                                  38\n",
      "----------------------------------  --------------\n",
      "2020-06-11 14:42:35.568421 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #38 | Epoch Duration: 39.68009376525879\n",
      "2020-06-11 14:42:35.569392 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #38 | Started Training: True\n",
      "----------------------------------  --------------\n",
      "Z mean train                            0.0339046\n",
      "Z variance train                        0.659123\n",
      "KL Divergence                           0.80863\n",
      "KL Loss                                 0.080863\n",
      "QF Loss                                 0.805616\n",
      "VF Loss                                 0.258907\n",
      "Policy Loss                          -121.511\n",
      "Q Predictions Mean                    120.213\n",
      "Q Predictions Std                       1.51276\n",
      "Q Predictions Max                     123.383\n",
      "Q Predictions Min                     113.675\n",
      "V Predictions Mean                    121.142\n",
      "V Predictions Std                       1.44071\n",
      "V Predictions Max                     124.294\n",
      "V Predictions Min                     114.671\n",
      "Log Pis Mean                           -2.02043\n",
      "Log Pis Std                             0.273592\n",
      "Log Pis Max                            -1.14005\n",
      "Log Pis Min                            -4.02398\n",
      "Policy mu Mean                          0.0341546\n",
      "Policy mu Std                           0.0916926\n",
      "Policy mu Max                           0.348063\n",
      "Policy mu Min                          -0.134544\n",
      "Policy log std Mean                    -0.13253\n",
      "Policy log std Std                      0.00391047\n",
      "Policy log std Max                     -0.119266\n",
      "Policy log std Min                     -0.165511\n",
      "Z mean eval                             0.0127249\n",
      "Z variance eval                         0.302386\n",
      "AverageTrainReturn_all_train_tasks     -0.0461699\n",
      "AverageReturn_all_train_tasks          -0.0474027\n",
      "AverageReturn_all_test_tasks           -0.0505567\n",
      "Number of train steps total         20000\n",
      "Number of env steps total           96000\n",
      "Number of rollouts total                0\n",
      "Train Time (s)                         29.634\n",
      "(Previous) Eval Time (s)                5.62481\n",
      "Sample Time (s)                         3.23747\n",
      "Epoch Time (s)                         38.4962\n",
      "Total Train Time (s)                 1997.8\n",
      "Epoch                                  39\n",
      "----------------------------------  --------------\n",
      "2020-06-11 14:43:13.884162 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #39 | Epoch Duration: 38.314770460128784\n",
      "2020-06-11 14:43:13.885161 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #39 | Started Training: True\n",
      "----------------------------------  ---------------\n",
      "Z mean train                            0.013619\n",
      "Z variance train                        1.01395\n",
      "KL Divergence                           0.00732562\n",
      "KL Loss                                 0.000732562\n",
      "QF Loss                                 0.0998368\n",
      "VF Loss                                 0.0497677\n",
      "Policy Loss                          -122.55\n",
      "Q Predictions Mean                    120.676\n",
      "Q Predictions Std                       1.46421\n",
      "Q Predictions Max                     123.095\n",
      "Q Predictions Min                     111.716\n",
      "V Predictions Mean                    122.565\n",
      "V Predictions Std                       1.46518\n",
      "V Predictions Max                     124.943\n",
      "V Predictions Min                     113.785\n",
      "Log Pis Mean                           -2.03536\n",
      "Log Pis Std                             0.286608\n",
      "Log Pis Max                            -0.925423\n",
      "Log Pis Min                            -3.5658\n",
      "Policy mu Mean                          0.0370288\n",
      "Policy mu Std                           0.0921056\n",
      "Policy mu Max                           0.352815\n",
      "Policy mu Min                          -0.136331\n",
      "Policy log std Mean                    -0.135697\n",
      "Policy log std Std                      0.00444479\n",
      "Policy log std Max                     -0.111094\n",
      "Policy log std Min                     -0.154295\n",
      "Z mean eval                             0.0141397\n",
      "Z variance eval                         0.29139\n",
      "AverageTrainReturn_all_train_tasks     -0.058004\n",
      "AverageReturn_all_train_tasks           0.469969\n",
      "AverageReturn_all_test_tasks            0.491775\n",
      "Number of train steps total         20500\n",
      "Number of env steps total           98000\n",
      "Number of rollouts total                0\n",
      "Train Time (s)                         28.5463\n",
      "(Previous) Eval Time (s)                5.44276\n",
      "Sample Time (s)                         3.03799\n",
      "Epoch Time (s)                         37.0271\n",
      "Total Train Time (s)                 2034.56\n",
      "Epoch                                  40\n",
      "----------------------------------  ---------------\n",
      "2020-06-11 14:43:50.643693 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #40 | Epoch Duration: 36.75753164291382\n",
      "2020-06-11 14:43:50.645701 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #40 | Started Training: True\n",
      "----------------------------------  ---------------\n",
      "Z mean train                             0.0153806\n",
      "Z variance train                         0.972254\n",
      "KL Divergence                            0.0116475\n",
      "KL Loss                                  0.00116475\n",
      "QF Loss                                  0.0807353\n",
      "VF Loss                                  0.222234\n",
      "Policy Loss                           -124.304\n",
      "Q Predictions Mean                     122.26\n",
      "Q Predictions Std                        1.48815\n",
      "Q Predictions Max                      124.978\n",
      "Q Predictions Min                      114.412\n",
      "V Predictions Mean                     124.349\n",
      "V Predictions Std                        1.49399\n",
      "V Predictions Max                      127.264\n",
      "V Predictions Min                      116.157\n",
      "Log Pis Mean                            -2.03188\n",
      "Log Pis Std                              0.300149\n",
      "Log Pis Max                             -0.990968\n",
      "Log Pis Min                             -4.76175\n",
      "Policy mu Mean                           0.0453968\n",
      "Policy mu Std                            0.0908433\n",
      "Policy mu Max                            0.392634\n",
      "Policy mu Min                           -0.109611\n",
      "Policy log std Mean                     -0.127899\n",
      "Policy log std Std                       0.00522528\n",
      "Policy log std Max                      -0.102844\n",
      "Policy log std Min                      -0.16744\n",
      "Z mean eval                              0.024146\n",
      "Z variance eval                          0.274798\n",
      "AverageTrainReturn_all_train_tasks      -0.0517826\n",
      "AverageReturn_all_train_tasks           -0.0486679\n",
      "AverageReturn_all_test_tasks            -0.0503169\n",
      "Number of train steps total          21000\n",
      "Number of env steps total           100000\n",
      "Number of rollouts total                 0\n",
      "Train Time (s)                          29.3699\n",
      "(Previous) Eval Time (s)                 5.17338\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Time (s)                          3.04051\n",
      "Epoch Time (s)                          37.5838\n",
      "Total Train Time (s)                  2072.33\n",
      "Epoch                                   41\n",
      "----------------------------------  ---------------\n",
      "2020-06-11 14:44:28.414834 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #41 | Epoch Duration: 37.76814413070679\n",
      "2020-06-11 14:44:28.415834 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #41 | Started Training: True\n",
      "----------------------------------  ---------------\n",
      "Z mean train                             0.0255777\n",
      "Z variance train                         0.902918\n",
      "KL Divergence                            0.0693241\n",
      "KL Loss                                  0.00693241\n",
      "QF Loss                                  0.604926\n",
      "VF Loss                                  0.573468\n",
      "Policy Loss                           -126.539\n",
      "Q Predictions Mean                     124.755\n",
      "Q Predictions Std                        1.42208\n",
      "Q Predictions Max                      127.436\n",
      "Q Predictions Min                      117.305\n",
      "V Predictions Mean                     125.945\n",
      "V Predictions Std                        1.64444\n",
      "V Predictions Max                      129.377\n",
      "V Predictions Min                      117.102\n",
      "Log Pis Mean                            -2.01868\n",
      "Log Pis Std                              0.300703\n",
      "Log Pis Max                             -1.13285\n",
      "Log Pis Min                             -5.23563\n",
      "Policy mu Mean                           0.044369\n",
      "Policy mu Std                            0.0903644\n",
      "Policy mu Max                            0.35405\n",
      "Policy mu Min                           -0.12526\n",
      "Policy log std Mean                     -0.131609\n",
      "Policy log std Std                       0.00581997\n",
      "Policy log std Max                      -0.118028\n",
      "Policy log std Min                      -0.160032\n",
      "Z mean eval                              0.0157017\n",
      "Z variance eval                          0.261826\n",
      "AverageTrainReturn_all_train_tasks      -0.0480786\n",
      "AverageReturn_all_train_tasks           -0.0497816\n",
      "AverageReturn_all_test_tasks            -0.0479714\n",
      "Number of train steps total          21500\n",
      "Number of env steps total           102000\n",
      "Number of rollouts total                 0\n",
      "Train Time (s)                          29.3146\n",
      "(Previous) Eval Time (s)                 5.35756\n",
      "Sample Time (s)                          3.03249\n",
      "Epoch Time (s)                          37.7047\n",
      "Total Train Time (s)                  2109.9\n",
      "Epoch                                   42\n",
      "----------------------------------  ---------------\n",
      "2020-06-11 14:45:05.988284 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #42 | Epoch Duration: 37.57145166397095\n",
      "2020-06-11 14:45:05.991280 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #42 | Started Training: True\n",
      "----------------------------------  ---------------\n",
      "Z mean train                             0.0166495\n",
      "Z variance train                         0.861825\n",
      "KL Divergence                            0.109564\n",
      "KL Loss                                  0.0109564\n",
      "QF Loss                                  0.44147\n",
      "VF Loss                                  0.389147\n",
      "Policy Loss                           -127.84\n",
      "Q Predictions Mean                     126.006\n",
      "Q Predictions Std                        1.49184\n",
      "Q Predictions Max                      129.529\n",
      "Q Predictions Min                      116.122\n",
      "V Predictions Mean                     127.956\n",
      "V Predictions Std                        1.40575\n",
      "V Predictions Max                      131.206\n",
      "V Predictions Min                      119.208\n",
      "Log Pis Mean                            -2.03521\n",
      "Log Pis Std                              0.287359\n",
      "Log Pis Max                             -1.02773\n",
      "Log Pis Min                             -3.32382\n",
      "Policy mu Mean                           0.0524572\n",
      "Policy mu Std                            0.0941282\n",
      "Policy mu Max                            0.36879\n",
      "Policy mu Min                           -0.130545\n",
      "Policy log std Mean                     -0.130289\n",
      "Policy log std Std                       0.00510224\n",
      "Policy log std Max                      -0.103687\n",
      "Policy log std Min                      -0.147361\n",
      "Z mean eval                              0.0224866\n",
      "Z variance eval                          0.284521\n",
      "AverageTrainReturn_all_train_tasks      -0.0539732\n",
      "AverageReturn_all_train_tasks           -0.0552944\n",
      "AverageReturn_all_test_tasks            -0.055438\n",
      "Number of train steps total          22000\n",
      "Number of env steps total           104000\n",
      "Number of rollouts total                 0\n",
      "Train Time (s)                          29.0077\n",
      "(Previous) Eval Time (s)                 5.22412\n",
      "Sample Time (s)                          3.09483\n",
      "Epoch Time (s)                          37.3266\n",
      "Total Train Time (s)                  2147.34\n",
      "Epoch                                   43\n",
      "----------------------------------  ---------------\n",
      "2020-06-11 14:45:43.428460 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #43 | Epoch Duration: 37.43618059158325\n",
      "2020-06-11 14:45:43.429469 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #43 | Started Training: True\n",
      "----------------------------------  ---------------\n",
      "Z mean train                             0.0225752\n",
      "Z variance train                         0.879608\n",
      "KL Divergence                            0.0788438\n",
      "KL Loss                                  0.00788438\n",
      "QF Loss                                  0.295469\n",
      "VF Loss                                  0.655605\n",
      "Policy Loss                           -130.129\n",
      "Q Predictions Mean                     127.992\n",
      "Q Predictions Std                        1.73855\n",
      "Q Predictions Max                      130.599\n",
      "Q Predictions Min                      115.142\n",
      "V Predictions Mean                     129.446\n",
      "V Predictions Std                        1.72858\n",
      "V Predictions Max                      132.044\n",
      "V Predictions Min                      117.03\n",
      "Log Pis Mean                            -2.01981\n",
      "Log Pis Std                              0.336446\n",
      "Log Pis Max                             -0.633974\n",
      "Log Pis Min                             -4.27089\n",
      "Policy mu Mean                           0.0348761\n",
      "Policy mu Std                            0.10757\n",
      "Policy mu Max                            0.394076\n",
      "Policy mu Min                           -0.123604\n",
      "Policy log std Mean                     -0.128444\n",
      "Policy log std Std                       0.00425508\n",
      "Policy log std Max                      -0.11604\n",
      "Policy log std Min                      -0.145969\n",
      "Z mean eval                              0.00933799\n",
      "Z variance eval                          0.297231\n",
      "AverageTrainReturn_all_train_tasks      -0.0495827\n",
      "AverageReturn_all_train_tasks           -0.049185\n",
      "AverageReturn_all_test_tasks            -0.0495165\n",
      "Number of train steps total          22500\n",
      "Number of env steps total           106000\n",
      "Number of rollouts total                 0\n",
      "Train Time (s)                          29.1125\n",
      "(Previous) Eval Time (s)                 5.33307\n",
      "Sample Time (s)                          3.02682\n",
      "Epoch Time (s)                          37.4724\n",
      "Total Train Time (s)                  2184.74\n",
      "Epoch                                   44\n",
      "----------------------------------  ---------------\n",
      "2020-06-11 14:46:20.826572 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #44 | Epoch Duration: 37.39611196517944\n",
      "2020-06-11 14:46:20.827572 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #44 | Started Training: True\n",
      "----------------------------------  ----------------\n",
      "Z mean train                             0.00953618\n",
      "Z variance train                         0.952725\n",
      "KL Divergence                            0.00897679\n",
      "KL Loss                                  0.000897679\n",
      "QF Loss                                  0.14004\n",
      "VF Loss                                  0.161189\n",
      "Policy Loss                           -131.573\n",
      "Q Predictions Mean                     129.68\n",
      "Q Predictions Std                        1.7527\n",
      "Q Predictions Max                      133.381\n",
      "Q Predictions Min                      119.454\n",
      "V Predictions Mean                     131.814\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V Predictions Std                        1.69331\n",
      "V Predictions Max                      135.304\n",
      "V Predictions Min                      121.571\n",
      "Log Pis Mean                            -2.03525\n",
      "Log Pis Std                              0.290906\n",
      "Log Pis Max                             -1.04751\n",
      "Log Pis Min                             -3.35848\n",
      "Policy mu Mean                           0.0450201\n",
      "Policy mu Std                            0.105422\n",
      "Policy mu Max                            0.39312\n",
      "Policy mu Min                           -0.137911\n",
      "Policy log std Mean                     -0.133283\n",
      "Policy log std Std                       0.00693065\n",
      "Policy log std Max                      -0.121556\n",
      "Policy log std Min                      -0.167822\n",
      "Z mean eval                              0.0236572\n",
      "Z variance eval                          0.296432\n",
      "AverageTrainReturn_all_train_tasks      -0.0548585\n",
      "AverageReturn_all_train_tasks           -0.0553339\n",
      "AverageReturn_all_test_tasks            -0.05253\n",
      "Number of train steps total          23000\n",
      "Number of env steps total           108000\n",
      "Number of rollouts total                 0\n",
      "Train Time (s)                          29.87\n",
      "(Previous) Eval Time (s)                 5.25714\n",
      "Sample Time (s)                          3.01722\n",
      "Epoch Time (s)                          38.1443\n",
      "Total Train Time (s)                  2222.82\n",
      "Epoch                                   45\n",
      "----------------------------------  ----------------\n",
      "2020-06-11 14:46:58.904677 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #45 | Epoch Duration: 38.076107025146484\n",
      "2020-06-11 14:46:58.905677 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #45 | Started Training: True\n",
      "----------------------------------  ---------------\n",
      "Z mean train                             0.0234376\n",
      "Z variance train                         0.907479\n",
      "KL Divergence                            0.0337149\n",
      "KL Loss                                  0.00337149\n",
      "QF Loss                                  0.116714\n",
      "VF Loss                                  0.118482\n",
      "Policy Loss                           -132.859\n",
      "Q Predictions Mean                     131.037\n",
      "Q Predictions Std                        1.58963\n",
      "Q Predictions Max                      134.059\n",
      "Q Predictions Min                      122.691\n",
      "V Predictions Mean                     133.112\n",
      "V Predictions Std                        1.60876\n",
      "V Predictions Max                      136.04\n",
      "V Predictions Min                      125.069\n",
      "Log Pis Mean                            -2.017\n",
      "Log Pis Std                              0.294001\n",
      "Log Pis Max                             -0.81913\n",
      "Log Pis Min                             -3.58722\n",
      "Policy mu Mean                           0.0541238\n",
      "Policy mu Std                            0.0991311\n",
      "Policy mu Max                            0.423354\n",
      "Policy mu Min                           -0.155045\n",
      "Policy log std Mean                     -0.13159\n",
      "Policy log std Std                       0.00789717\n",
      "Policy log std Max                      -0.118015\n",
      "Policy log std Min                      -0.176246\n",
      "Z mean eval                              0.0234231\n",
      "Z variance eval                          0.311002\n",
      "AverageTrainReturn_all_train_tasks      -0.0532506\n",
      "AverageReturn_all_train_tasks           -0.0528838\n",
      "AverageReturn_all_test_tasks             0.0242749\n",
      "Number of train steps total          23500\n",
      "Number of env steps total           110000\n",
      "Number of rollouts total                 0\n",
      "Train Time (s)                          28.9117\n",
      "(Previous) Eval Time (s)                 5.18833\n",
      "Sample Time (s)                          3.00717\n",
      "Epoch Time (s)                          37.1072\n",
      "Total Train Time (s)                  2259.94\n",
      "Epoch                                   46\n",
      "----------------------------------  ---------------\n",
      "2020-06-11 14:47:36.020890 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #46 | Epoch Duration: 37.11421298980713\n",
      "2020-06-11 14:47:36.021889 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #46 | Started Training: True\n",
      "----------------------------------  ---------------\n",
      "Z mean train                             0.0239732\n",
      "Z variance train                         0.98297\n",
      "KL Divergence                            0.0123793\n",
      "KL Loss                                  0.00123793\n",
      "QF Loss                                  0.0783652\n",
      "VF Loss                                  0.0702196\n",
      "Policy Loss                           -134.74\n",
      "Q Predictions Mean                     132.7\n",
      "Q Predictions Std                        1.61965\n",
      "Q Predictions Max                      135.197\n",
      "Q Predictions Min                      122.46\n",
      "V Predictions Mean                     134.818\n",
      "V Predictions Std                        1.60913\n",
      "V Predictions Max                      137.301\n",
      "V Predictions Min                      124.424\n",
      "Log Pis Mean                            -2.03637\n",
      "Log Pis Std                              0.351887\n",
      "Log Pis Max                             -0.898568\n",
      "Log Pis Min                             -4.77604\n",
      "Policy mu Mean                           0.0421974\n",
      "Policy mu Std                            0.107064\n",
      "Policy mu Max                            0.375222\n",
      "Policy mu Min                           -0.117596\n",
      "Policy log std Mean                     -0.130014\n",
      "Policy log std Std                       0.00629603\n",
      "Policy log std Max                      -0.117194\n",
      "Policy log std Min                      -0.164006\n",
      "Z mean eval                              0.01609\n",
      "Z variance eval                          0.299948\n",
      "AverageTrainReturn_all_train_tasks      -0.0491915\n",
      "AverageReturn_all_train_tasks           -0.0471655\n",
      "AverageReturn_all_test_tasks            -0.0467174\n",
      "Number of train steps total          24000\n",
      "Number of env steps total           112000\n",
      "Number of rollouts total                 0\n",
      "Train Time (s)                          28.9492\n",
      "(Previous) Eval Time (s)                 5.19518\n",
      "Sample Time (s)                          3.11947\n",
      "Epoch Time (s)                          37.2639\n",
      "Total Train Time (s)                  2297.28\n",
      "Epoch                                   47\n",
      "----------------------------------  ---------------\n",
      "2020-06-11 14:48:13.366258 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #47 | Epoch Duration: 37.343369007110596\n",
      "2020-06-11 14:48:13.367257 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #47 | Started Training: True\n",
      "----------------------------------  ----------------\n",
      "Z mean train                             0.0170211\n",
      "Z variance train                         1.0058\n",
      "KL Divergence                            0.00597449\n",
      "KL Loss                                  0.000597449\n",
      "QF Loss                                  0.155663\n",
      "VF Loss                                  0.0651545\n",
      "Policy Loss                           -136.727\n",
      "Q Predictions Mean                     134.569\n",
      "Q Predictions Std                        1.61779\n",
      "Q Predictions Max                      138.301\n",
      "Q Predictions Min                      125.47\n",
      "V Predictions Mean                     136.664\n",
      "V Predictions Std                        1.58011\n",
      "V Predictions Max                      140.191\n",
      "V Predictions Min                      128.296\n",
      "Log Pis Mean                            -2.0304\n",
      "Log Pis Std                              0.307091\n",
      "Log Pis Max                             -0.910955\n",
      "Log Pis Min                             -3.34941\n",
      "Policy mu Mean                           0.0535\n",
      "Policy mu Std                            0.107525\n",
      "Policy mu Max                            0.392625\n",
      "Policy mu Min                           -0.138157\n",
      "Policy log std Mean                     -0.134037\n",
      "Policy log std Std                       0.00690022\n",
      "Policy log std Max                      -0.115279\n",
      "Policy log std Min                      -0.170973\n",
      "Z mean eval                              0.00596711\n",
      "Z variance eval                          0.309811\n",
      "AverageTrainReturn_all_train_tasks      -0.0483068\n",
      "AverageReturn_all_train_tasks           -0.0499179\n",
      "AverageReturn_all_test_tasks            -0.0487258\n",
      "Number of train steps total          24500\n",
      "Number of env steps total           114000\n",
      "Number of rollouts total                 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Time (s)                          31.7473\n",
      "(Previous) Eval Time (s)                 5.27517\n",
      "Sample Time (s)                          3.05037\n",
      "Epoch Time (s)                          40.0728\n",
      "Total Train Time (s)                  2337.36\n",
      "Epoch                                   48\n",
      "----------------------------------  ----------------\n",
      "2020-06-11 14:48:53.447999 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #48 | Epoch Duration: 40.079742670059204\n",
      "2020-06-11 14:48:53.448999 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #48 | Started Training: True\n",
      "----------------------------------  ---------------\n",
      "Z mean train                             0.00717087\n",
      "Z variance train                         0.992531\n",
      "KL Divergence                            0.0143341\n",
      "KL Loss                                  0.00143341\n",
      "QF Loss                                  0.139806\n",
      "VF Loss                                  0.097611\n",
      "Policy Loss                           -136.806\n",
      "Q Predictions Mean                     134.544\n",
      "Q Predictions Std                        1.58716\n",
      "Q Predictions Max                      137.494\n",
      "Q Predictions Min                      123.403\n",
      "V Predictions Mean                     136.613\n",
      "V Predictions Std                        1.64233\n",
      "V Predictions Max                      139.838\n",
      "V Predictions Min                      126.027\n",
      "Log Pis Mean                            -2.01274\n",
      "Log Pis Std                              0.276964\n",
      "Log Pis Max                             -1.01658\n",
      "Log Pis Min                             -3.08334\n",
      "Policy mu Mean                           0.0543256\n",
      "Policy mu Std                            0.0924353\n",
      "Policy mu Max                            0.397043\n",
      "Policy mu Min                           -0.133996\n",
      "Policy log std Mean                     -0.131036\n",
      "Policy log std Std                       0.00458075\n",
      "Policy log std Max                      -0.116369\n",
      "Policy log std Min                      -0.15671\n",
      "Z mean eval                              0.0260836\n",
      "Z variance eval                          0.287974\n",
      "AverageTrainReturn_all_train_tasks      -0.0503068\n",
      "AverageReturn_all_train_tasks           -0.0480036\n",
      "AverageReturn_all_test_tasks             0.216878\n",
      "Number of train steps total          25000\n",
      "Number of env steps total           116000\n",
      "Number of rollouts total                 0\n",
      "Train Time (s)                          28.9356\n",
      "(Previous) Eval Time (s)                 5.28244\n",
      "Sample Time (s)                          3.19314\n",
      "Epoch Time (s)                          37.4111\n",
      "Total Train Time (s)                  2374.53\n",
      "Epoch                                   49\n",
      "----------------------------------  ---------------\n",
      "2020-06-11 14:49:30.625652 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #49 | Epoch Duration: 37.175652503967285\n",
      "2020-06-11 14:49:30.626631 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #49 | Started Training: True\n",
      "----------------------------------  ---------------\n",
      "Z mean train                             0.0278795\n",
      "Z variance train                         0.933134\n",
      "KL Divergence                            0.0382371\n",
      "KL Loss                                  0.00382371\n",
      "QF Loss                                  0.176809\n",
      "VF Loss                                  0.582268\n",
      "Policy Loss                           -138.765\n",
      "Q Predictions Mean                     136.619\n",
      "Q Predictions Std                        1.60849\n",
      "Q Predictions Max                      140.031\n",
      "Q Predictions Min                      126.358\n",
      "V Predictions Mean                     138.131\n",
      "V Predictions Std                        1.61368\n",
      "V Predictions Max                      141.396\n",
      "V Predictions Min                      127.658\n",
      "Log Pis Mean                            -2.02432\n",
      "Log Pis Std                              0.287755\n",
      "Log Pis Max                             -1.00695\n",
      "Log Pis Min                             -3.81924\n",
      "Policy mu Mean                           0.046871\n",
      "Policy mu Std                            0.0979197\n",
      "Policy mu Max                            0.391906\n",
      "Policy mu Min                           -0.130872\n",
      "Policy log std Mean                     -0.133031\n",
      "Policy log std Std                       0.00644621\n",
      "Policy log std Max                      -0.120457\n",
      "Policy log std Min                      -0.171395\n",
      "Z mean eval                              0.0105346\n",
      "Z variance eval                          0.274165\n",
      "AverageTrainReturn_all_train_tasks      -0.0535164\n",
      "AverageReturn_all_train_tasks            0.119188\n",
      "AverageReturn_all_test_tasks            -0.0537757\n",
      "Number of train steps total          25500\n",
      "Number of env steps total           118000\n",
      "Number of rollouts total                 0\n",
      "Train Time (s)                          29.459\n",
      "(Previous) Eval Time (s)                 5.04647\n",
      "Sample Time (s)                          3.00158\n",
      "Epoch Time (s)                          37.5071\n",
      "Total Train Time (s)                  2412.18\n",
      "Epoch                                   50\n",
      "----------------------------------  ---------------\n",
      "2020-06-11 14:50:08.272953 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #50 | Epoch Duration: 37.64532423019409\n",
      "2020-06-11 14:50:08.276951 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #50 | Started Training: True\n",
      "----------------------------------  ---------------\n",
      "Z mean train                             0.0110916\n",
      "Z variance train                         0.932792\n",
      "KL Divergence                            0.0376253\n",
      "KL Loss                                  0.00376253\n",
      "QF Loss                                  0.20887\n",
      "VF Loss                                  0.123998\n",
      "Policy Loss                           -140.529\n",
      "Q Predictions Mean                     138.562\n",
      "Q Predictions Std                        1.60957\n",
      "Q Predictions Max                      141.78\n",
      "Q Predictions Min                      130.232\n",
      "V Predictions Mean                     140.496\n",
      "V Predictions Std                        1.62841\n",
      "V Predictions Max                      143.56\n",
      "V Predictions Min                      131.563\n",
      "Log Pis Mean                            -2.03199\n",
      "Log Pis Std                              0.30296\n",
      "Log Pis Max                             -0.866448\n",
      "Log Pis Min                             -4.83843\n",
      "Policy mu Mean                           0.0454788\n",
      "Policy mu Std                            0.10712\n",
      "Policy mu Max                            0.412608\n",
      "Policy mu Min                           -0.148479\n",
      "Policy log std Mean                     -0.130526\n",
      "Policy log std Std                       0.00647325\n",
      "Policy log std Max                      -0.118848\n",
      "Policy log std Min                      -0.172725\n",
      "Z mean eval                              0.0342012\n",
      "Z variance eval                          0.229414\n",
      "AverageTrainReturn_all_train_tasks       0.226989\n",
      "AverageReturn_all_train_tasks           -0.0491176\n",
      "AverageReturn_all_test_tasks            -0.0504003\n",
      "Number of train steps total          26000\n",
      "Number of env steps total           120000\n",
      "Number of rollouts total                 0\n",
      "Train Time (s)                          31.1729\n",
      "(Previous) Eval Time (s)                 5.1843\n",
      "Sample Time (s)                          3.11066\n",
      "Epoch Time (s)                          39.4679\n",
      "Total Train Time (s)                  2451.61\n",
      "Epoch                                   51\n",
      "----------------------------------  ---------------\n",
      "2020-06-11 14:50:47.696344 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #51 | Epoch Duration: 39.41739559173584\n",
      "2020-06-11 14:50:47.697341 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #51 | Started Training: True\n",
      "----------------------------------  ---------------\n",
      "Z mean train                             0.0386755\n",
      "Z variance train                         0.757713\n",
      "KL Divergence                            0.361115\n",
      "KL Loss                                  0.0361115\n",
      "QF Loss                                  1.44505\n",
      "VF Loss                                  0.773929\n",
      "Policy Loss                           -141.019\n",
      "Q Predictions Mean                     139.924\n",
      "Q Predictions Std                        2.0741\n",
      "Q Predictions Max                      144.307\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q Predictions Min                      130.648\n",
      "V Predictions Mean                     141.469\n",
      "V Predictions Std                        1.61724\n",
      "V Predictions Max                      144.805\n",
      "V Predictions Min                      133.412\n",
      "Log Pis Mean                            -2.03162\n",
      "Log Pis Std                              0.297763\n",
      "Log Pis Max                             -0.810216\n",
      "Log Pis Min                             -3.93015\n",
      "Policy mu Mean                           0.0404426\n",
      "Policy mu Std                            0.103593\n",
      "Policy mu Max                            0.391658\n",
      "Policy mu Min                           -0.139548\n",
      "Policy log std Mean                     -0.137762\n",
      "Policy log std Std                       0.00448504\n",
      "Policy log std Max                      -0.125576\n",
      "Policy log std Min                      -0.172264\n",
      "Z mean eval                              0.018993\n",
      "Z variance eval                          0.274961\n",
      "AverageTrainReturn_all_train_tasks      -0.0464585\n",
      "AverageReturn_all_train_tasks           -0.047788\n",
      "AverageReturn_all_test_tasks            -0.0472129\n",
      "Number of train steps total          26500\n",
      "Number of env steps total           122000\n",
      "Number of rollouts total                 0\n",
      "Train Time (s)                          32.7044\n",
      "(Previous) Eval Time (s)                 5.13382\n",
      "Sample Time (s)                          3.02771\n",
      "Epoch Time (s)                          40.8659\n",
      "Total Train Time (s)                  2492.52\n",
      "Epoch                                   52\n",
      "----------------------------------  ---------------\n",
      "2020-06-11 14:51:28.614570 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #52 | Epoch Duration: 40.91623044013977\n",
      "2020-06-11 14:51:28.615571 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #52 | Started Training: True\n",
      "----------------------------------  ---------------\n",
      "Z mean train                             0.0183829\n",
      "Z variance train                         0.901901\n",
      "KL Divergence                            0.062088\n",
      "KL Loss                                  0.0062088\n",
      "QF Loss                                  0.108813\n",
      "VF Loss                                  0.100122\n",
      "Policy Loss                           -142.774\n",
      "Q Predictions Mean                     140.741\n",
      "Q Predictions Std                        1.86393\n",
      "Q Predictions Max                      144.717\n",
      "Q Predictions Min                      129.121\n",
      "V Predictions Mean                     142.626\n",
      "V Predictions Std                        1.82197\n",
      "V Predictions Max                      146.143\n",
      "V Predictions Min                      130.944\n",
      "Log Pis Mean                            -2.01869\n",
      "Log Pis Std                              0.340169\n",
      "Log Pis Max                             -0.881893\n",
      "Log Pis Min                             -4.36399\n",
      "Policy mu Mean                           0.0502645\n",
      "Policy mu Std                            0.114609\n",
      "Policy mu Max                            0.416939\n",
      "Policy mu Min                           -0.137616\n",
      "Policy log std Mean                     -0.136738\n",
      "Policy log std Std                       0.00571729\n",
      "Policy log std Max                      -0.125394\n",
      "Policy log std Min                      -0.161752\n",
      "Z mean eval                              0.00517602\n",
      "Z variance eval                          0.252361\n",
      "AverageTrainReturn_all_train_tasks      -0.0528792\n",
      "AverageReturn_all_train_tasks           -0.0496076\n",
      "AverageReturn_all_test_tasks            -0.0496306\n",
      "Number of train steps total          27000\n",
      "Number of env steps total           124000\n",
      "Number of rollouts total                 0\n",
      "Train Time (s)                          29.4548\n",
      "(Previous) Eval Time (s)                 5.18333\n",
      "Sample Time (s)                          3.05832\n",
      "Epoch Time (s)                          37.6964\n",
      "Total Train Time (s)                  2530.94\n",
      "Epoch                                   53\n",
      "----------------------------------  ---------------\n",
      "2020-06-11 14:52:07.078607 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #53 | Epoch Duration: 38.462037801742554\n",
      "2020-06-11 14:52:07.079605 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #53 | Started Training: True\n",
      "----------------------------------  --------------\n",
      "Z mean train                             0.0047292\n",
      "Z variance train                         0.808532\n",
      "KL Divergence                            0.181617\n",
      "KL Loss                                  0.0181617\n",
      "QF Loss                                  0.354533\n",
      "VF Loss                                  0.346117\n",
      "Policy Loss                           -144.069\n",
      "Q Predictions Mean                     142.195\n",
      "Q Predictions Std                        1.88369\n",
      "Q Predictions Max                      146.441\n",
      "Q Predictions Min                      130.972\n",
      "V Predictions Mean                     144.59\n",
      "V Predictions Std                        1.93515\n",
      "V Predictions Max                      148.913\n",
      "V Predictions Min                      132.699\n",
      "Log Pis Mean                            -2.01819\n",
      "Log Pis Std                              0.316492\n",
      "Log Pis Max                             -1.05604\n",
      "Log Pis Min                             -3.84576\n",
      "Policy mu Mean                           0.061005\n",
      "Policy mu Std                            0.107058\n",
      "Policy mu Max                            0.416203\n",
      "Policy mu Min                           -0.139081\n",
      "Policy log std Mean                     -0.131282\n",
      "Policy log std Std                       0.0038935\n",
      "Policy log std Max                      -0.118442\n",
      "Policy log std Min                      -0.157034\n",
      "Z mean eval                              0.0208514\n",
      "Z variance eval                          0.259911\n",
      "AverageTrainReturn_all_train_tasks      -0.0479991\n",
      "AverageReturn_all_train_tasks           -0.0473271\n",
      "AverageReturn_all_test_tasks            -0.0474625\n",
      "Number of train steps total          27500\n",
      "Number of env steps total           126000\n",
      "Number of rollouts total                 0\n",
      "Train Time (s)                          32.5138\n",
      "(Previous) Eval Time (s)                 5.9489\n",
      "Sample Time (s)                          3.60425\n",
      "Epoch Time (s)                          42.0669\n",
      "Total Train Time (s)                  2573.03\n",
      "Epoch                                   54\n",
      "----------------------------------  --------------\n",
      "2020-06-11 14:52:49.125920 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #54 | Epoch Duration: 42.04531502723694\n",
      "2020-06-11 14:52:49.126920 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #54 | Started Training: True\n",
      "----------------------------------  ---------------\n",
      "Z mean train                             0.0205644\n",
      "Z variance train                         0.864451\n",
      "KL Divergence                            0.120566\n",
      "KL Loss                                  0.0120566\n",
      "QF Loss                                  0.328516\n",
      "VF Loss                                  1.92897\n",
      "Policy Loss                           -144.607\n",
      "Q Predictions Mean                     143.212\n",
      "Q Predictions Std                        1.728\n",
      "Q Predictions Max                      146.991\n",
      "Q Predictions Min                      129.961\n",
      "V Predictions Mean                     145.955\n",
      "V Predictions Std                        1.79225\n",
      "V Predictions Max                      150.232\n",
      "V Predictions Min                      133.142\n",
      "Log Pis Mean                            -2.0268\n",
      "Log Pis Std                              0.313965\n",
      "Log Pis Max                             -0.91286\n",
      "Log Pis Min                             -3.72437\n",
      "Policy mu Mean                           0.0555933\n",
      "Policy mu Std                            0.107861\n",
      "Policy mu Max                            0.419209\n",
      "Policy mu Min                           -0.146291\n",
      "Policy log std Mean                     -0.133695\n",
      "Policy log std Std                       0.00567062\n",
      "Policy log std Max                      -0.118857\n",
      "Policy log std Min                      -0.171328\n",
      "Z mean eval                              0.00707558\n",
      "Z variance eval                          0.280243\n",
      "AverageTrainReturn_all_train_tasks      -0.0447586\n",
      "AverageReturn_all_train_tasks           -0.0450827\n",
      "AverageReturn_all_test_tasks            -0.0497387\n",
      "Number of train steps total          28000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of env steps total           128000\n",
      "Number of rollouts total                 0\n",
      "Train Time (s)                          32.8925\n",
      "(Previous) Eval Time (s)                 5.92722\n",
      "Sample Time (s)                          3.36557\n",
      "Epoch Time (s)                          42.1853\n",
      "Total Train Time (s)                  2614.99\n",
      "Epoch                                   55\n",
      "----------------------------------  ---------------\n",
      "2020-06-11 14:53:31.081737 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #55 | Epoch Duration: 41.95381712913513\n",
      "2020-06-11 14:53:31.082736 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #55 | Started Training: True\n",
      "----------------------------------  ---------------\n",
      "Z mean train                             0.00765858\n",
      "Z variance train                         0.916852\n",
      "KL Divergence                            0.0235585\n",
      "KL Loss                                  0.00235585\n",
      "QF Loss                                  0.492304\n",
      "VF Loss                                  0.0969781\n",
      "Policy Loss                           -146.308\n",
      "Q Predictions Mean                     144.421\n",
      "Q Predictions Std                        1.96788\n",
      "Q Predictions Max                      147.959\n",
      "Q Predictions Min                      133.176\n",
      "V Predictions Mean                     146.132\n",
      "V Predictions Std                        2.00414\n",
      "V Predictions Max                      150.014\n",
      "V Predictions Min                      134.245\n",
      "Log Pis Mean                            -2.02156\n",
      "Log Pis Std                              0.300776\n",
      "Log Pis Max                             -0.627045\n",
      "Log Pis Min                             -3.66724\n",
      "Policy mu Mean                           0.0442084\n",
      "Policy mu Std                            0.120117\n",
      "Policy mu Max                            0.426829\n",
      "Policy mu Min                           -0.167357\n",
      "Policy log std Mean                     -0.133485\n",
      "Policy log std Std                       0.00628355\n",
      "Policy log std Max                      -0.120708\n",
      "Policy log std Min                      -0.170044\n",
      "Z mean eval                              0.00621758\n",
      "Z variance eval                          0.292978\n",
      "AverageTrainReturn_all_train_tasks      -0.0473452\n",
      "AverageReturn_all_train_tasks           -0.0494891\n",
      "AverageReturn_all_test_tasks            -0.0482438\n",
      "Number of train steps total          28500\n",
      "Number of env steps total           130000\n",
      "Number of rollouts total                 0\n",
      "Train Time (s)                          31.3235\n",
      "(Previous) Eval Time (s)                 5.69569\n",
      "Sample Time (s)                          3.38209\n",
      "Epoch Time (s)                          40.4012\n",
      "Total Train Time (s)                  2655\n",
      "Epoch                                   56\n",
      "----------------------------------  ---------------\n",
      "2020-06-11 14:54:11.105297 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #56 | Epoch Duration: 40.022560596466064\n",
      "2020-06-11 14:54:11.106297 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #56 | Started Training: True\n",
      "----------------------------------  ---------------\n",
      "Z mean train                             0.00701194\n",
      "Z variance train                         0.986745\n",
      "KL Divergence                            0.0105251\n",
      "KL Loss                                  0.00105251\n",
      "QF Loss                                  0.12447\n",
      "VF Loss                                  0.191286\n",
      "Policy Loss                           -147.485\n",
      "Q Predictions Mean                     145.593\n",
      "Q Predictions Std                        1.79944\n",
      "Q Predictions Max                      149.288\n",
      "Q Predictions Min                      133.838\n",
      "V Predictions Mean                     147.143\n",
      "V Predictions Std                        1.80693\n",
      "V Predictions Max                      150.908\n",
      "V Predictions Min                      136.014\n",
      "Log Pis Mean                            -2.02133\n",
      "Log Pis Std                              0.354363\n",
      "Log Pis Max                             -0.665435\n",
      "Log Pis Min                             -4.36599\n",
      "Policy mu Mean                           0.0439562\n",
      "Policy mu Std                            0.115515\n",
      "Policy mu Max                            0.427433\n",
      "Policy mu Min                           -0.133287\n",
      "Policy log std Mean                     -0.13052\n",
      "Policy log std Std                       0.00834041\n",
      "Policy log std Max                      -0.116274\n",
      "Policy log std Min                      -0.195884\n",
      "Z mean eval                              0.0637726\n",
      "Z variance eval                          0.25891\n",
      "AverageTrainReturn_all_train_tasks      -0.0448784\n",
      "AverageReturn_all_train_tasks            8.52839\n",
      "AverageReturn_all_test_tasks            -0.0502774\n",
      "Number of train steps total          29000\n",
      "Number of env steps total           132000\n",
      "Number of rollouts total                 0\n",
      "Train Time (s)                          29.4982\n",
      "(Previous) Eval Time (s)                 5.31632\n",
      "Sample Time (s)                          3.09328\n",
      "Epoch Time (s)                          37.9078\n",
      "Total Train Time (s)                  2692.92\n",
      "Epoch                                   57\n",
      "----------------------------------  ---------------\n",
      "2020-06-11 14:54:49.031549 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #57 | Epoch Duration: 37.92425322532654\n",
      "2020-06-11 14:54:49.032550 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #57 | Started Training: True\n",
      "----------------------------------  ---------------\n",
      "Z mean train                             0.0671152\n",
      "Z variance train                         0.871158\n",
      "KL Divergence                            0.14291\n",
      "KL Loss                                  0.014291\n",
      "QF Loss                                  0.27127\n",
      "VF Loss                                  0.451315\n",
      "Policy Loss                           -147.981\n",
      "Q Predictions Mean                     146.376\n",
      "Q Predictions Std                        1.84563\n",
      "Q Predictions Max                      150.481\n",
      "Q Predictions Min                      138.354\n",
      "V Predictions Mean                     147.365\n",
      "V Predictions Std                        1.76688\n",
      "V Predictions Max                      150.98\n",
      "V Predictions Min                      139.594\n",
      "Log Pis Mean                            -2.01872\n",
      "Log Pis Std                              0.31251\n",
      "Log Pis Max                             -0.924649\n",
      "Log Pis Min                             -3.52253\n",
      "Policy mu Mean                           0.058909\n",
      "Policy mu Std                            0.109655\n",
      "Policy mu Max                            0.433442\n",
      "Policy mu Min                           -0.13299\n",
      "Policy log std Mean                     -0.13186\n",
      "Policy log std Std                       0.00509832\n",
      "Policy log std Max                      -0.114807\n",
      "Policy log std Min                      -0.152871\n",
      "Z mean eval                              0.0137358\n",
      "Z variance eval                          0.29677\n",
      "AverageTrainReturn_all_train_tasks      -0.0559827\n",
      "AverageReturn_all_train_tasks           -0.0573865\n",
      "AverageReturn_all_test_tasks             2.93631\n",
      "Number of train steps total          29500\n",
      "Number of env steps total           134000\n",
      "Number of rollouts total                 0\n",
      "Train Time (s)                          29.0738\n",
      "(Previous) Eval Time (s)                 5.33233\n",
      "Sample Time (s)                          3.01369\n",
      "Epoch Time (s)                          37.4198\n",
      "Total Train Time (s)                  2730.29\n",
      "Epoch                                   58\n",
      "----------------------------------  ---------------\n",
      "2020-06-11 14:55:26.389042 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #58 | Epoch Duration: 37.355493783950806\n",
      "2020-06-11 14:55:26.393040 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #58 | Started Training: True\n",
      "----------------------------------  ---------------\n",
      "Z mean train                             0.0146207\n",
      "Z variance train                         0.939342\n",
      "KL Divergence                            0.0230033\n",
      "KL Loss                                  0.00230033\n",
      "QF Loss                                  0.203958\n",
      "VF Loss                                  0.16374\n",
      "Policy Loss                           -149.176\n",
      "Q Predictions Mean                     147.158\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q Predictions Std                        1.73311\n",
      "Q Predictions Max                      150.434\n",
      "Q Predictions Min                      137.408\n",
      "V Predictions Mean                     148.927\n",
      "V Predictions Std                        1.79881\n",
      "V Predictions Max                      152.214\n",
      "V Predictions Min                      139.548\n",
      "Log Pis Mean                            -2.0171\n",
      "Log Pis Std                              0.299234\n",
      "Log Pis Max                             -0.777831\n",
      "Log Pis Min                             -3.89534\n",
      "Policy mu Mean                           0.0472927\n",
      "Policy mu Std                            0.111617\n",
      "Policy mu Max                            0.411346\n",
      "Policy mu Min                           -0.14445\n",
      "Policy log std Mean                     -0.131846\n",
      "Policy log std Std                       0.00451861\n",
      "Policy log std Max                      -0.120405\n",
      "Policy log std Min                      -0.156793\n",
      "Z mean eval                              0.0189546\n",
      "Z variance eval                          0.280736\n",
      "AverageTrainReturn_all_train_tasks      -0.0646895\n",
      "AverageReturn_all_train_tasks            0.565991\n",
      "AverageReturn_all_test_tasks            -0.0564778\n",
      "Number of train steps total          30000\n",
      "Number of env steps total           136000\n",
      "Number of rollouts total                 0\n",
      "Train Time (s)                          28.9707\n",
      "(Previous) Eval Time (s)                 5.26717\n",
      "Sample Time (s)                          3.20558\n",
      "Epoch Time (s)                          37.4434\n",
      "Total Train Time (s)                  2767.92\n",
      "Epoch                                   59\n",
      "----------------------------------  ---------------\n",
      "2020-06-11 14:56:04.020326 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #59 | Epoch Duration: 37.62528681755066\n",
      "2020-06-11 14:56:04.022327 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #59 | Started Training: True\n",
      "----------------------------------  ---------------\n",
      "Z mean train                             0.0201628\n",
      "Z variance train                         0.914496\n",
      "KL Divergence                            0.0442484\n",
      "KL Loss                                  0.00442484\n",
      "QF Loss                                  0.143312\n",
      "VF Loss                                  0.340905\n",
      "Policy Loss                           -150.233\n",
      "Q Predictions Mean                     148.428\n",
      "Q Predictions Std                        1.66002\n",
      "Q Predictions Max                      152.305\n",
      "Q Predictions Min                      140.747\n",
      "V Predictions Mean                     150.724\n",
      "V Predictions Std                        1.69793\n",
      "V Predictions Max                      154.548\n",
      "V Predictions Min                      142.36\n",
      "Log Pis Mean                            -2.01429\n",
      "Log Pis Std                              0.310944\n",
      "Log Pis Max                             -0.785273\n",
      "Log Pis Min                             -3.89681\n",
      "Policy mu Mean                           0.0318688\n",
      "Policy mu Std                            0.116345\n",
      "Policy mu Max                            0.3894\n",
      "Policy mu Min                           -0.143131\n",
      "Policy log std Mean                     -0.133622\n",
      "Policy log std Std                       0.00538882\n",
      "Policy log std Max                      -0.121521\n",
      "Policy log std Min                      -0.17026\n",
      "Z mean eval                              0.0153228\n",
      "Z variance eval                          0.297437\n",
      "AverageTrainReturn_all_train_tasks      -0.0471047\n",
      "AverageReturn_all_train_tasks           -0.048642\n",
      "AverageReturn_all_test_tasks            -0.0471704\n",
      "Number of train steps total          30500\n",
      "Number of env steps total           138000\n",
      "Number of rollouts total                 0\n",
      "Train Time (s)                          29.2379\n",
      "(Previous) Eval Time (s)                 5.44956\n",
      "Sample Time (s)                          2.98896\n",
      "Epoch Time (s)                          37.6764\n",
      "Total Train Time (s)                  2805.53\n",
      "Epoch                                   60\n",
      "----------------------------------  ---------------\n",
      "2020-06-11 14:56:41.634694 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #60 | Epoch Duration: 37.61137008666992\n",
      "2020-06-11 14:56:41.635693 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #60 | Started Training: True\n",
      "----------------------------------  ---------------\n",
      "Z mean train                             0.00815545\n",
      "Z variance train                         0.928871\n",
      "KL Divergence                            0.0166962\n",
      "KL Loss                                  0.00166962\n",
      "QF Loss                                  0.178461\n",
      "VF Loss                                  0.0611695\n",
      "Policy Loss                           -150.771\n",
      "Q Predictions Mean                     148.773\n",
      "Q Predictions Std                        1.83193\n",
      "Q Predictions Max                      152.598\n",
      "Q Predictions Min                      140.289\n",
      "V Predictions Mean                     150.866\n",
      "V Predictions Std                        1.82328\n",
      "V Predictions Max                      154.576\n",
      "V Predictions Min                      141.633\n",
      "Log Pis Mean                            -2.02365\n",
      "Log Pis Std                              0.329703\n",
      "Log Pis Max                             -0.83271\n",
      "Log Pis Min                             -4.03606\n",
      "Policy mu Mean                           0.0645978\n",
      "Policy mu Std                            0.108147\n",
      "Policy mu Max                            0.420885\n",
      "Policy mu Min                           -0.146514\n",
      "Policy log std Mean                     -0.132741\n",
      "Policy log std Std                       0.00536143\n",
      "Policy log std Max                      -0.121403\n",
      "Policy log std Min                      -0.165917\n",
      "Z mean eval                              0.0173855\n",
      "Z variance eval                          0.184916\n",
      "AverageTrainReturn_all_train_tasks      -0.0504215\n",
      "AverageReturn_all_train_tasks           11.473\n",
      "AverageReturn_all_test_tasks            -0.048114\n",
      "Number of train steps total          31000\n",
      "Number of env steps total           140000\n",
      "Number of rollouts total                 0\n",
      "Train Time (s)                          29.1972\n",
      "(Previous) Eval Time (s)                 5.38424\n",
      "Sample Time (s)                          3.16958\n",
      "Epoch Time (s)                          37.751\n",
      "Total Train Time (s)                  2843.04\n",
      "Epoch                                   61\n",
      "----------------------------------  ---------------\n",
      "2020-06-11 14:57:19.149127 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #61 | Epoch Duration: 37.5124351978302\n",
      "2020-06-11 14:57:19.151125 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #61 | Started Training: True\n",
      "----------------------------------  ---------------\n",
      "Z mean train                             0.0174992\n",
      "Z variance train                         0.589964\n",
      "KL Divergence                            1.23244\n",
      "KL Loss                                  0.123244\n",
      "QF Loss                                  0.968807\n",
      "VF Loss                                  2.6438\n",
      "Policy Loss                           -153.069\n",
      "Q Predictions Mean                     151.37\n",
      "Q Predictions Std                        2.08846\n",
      "Q Predictions Max                      154.74\n",
      "Q Predictions Min                      136.437\n",
      "V Predictions Mean                     151.576\n",
      "V Predictions Std                        2.03277\n",
      "V Predictions Max                      155.022\n",
      "V Predictions Min                      137.211\n",
      "Log Pis Mean                            -2.04043\n",
      "Log Pis Std                              0.295426\n",
      "Log Pis Max                             -0.713536\n",
      "Log Pis Min                             -4.65119\n",
      "Policy mu Mean                           0.0285299\n",
      "Policy mu Std                            0.113462\n",
      "Policy mu Max                            0.428188\n",
      "Policy mu Min                           -0.157441\n",
      "Policy log std Mean                     -0.134454\n",
      "Policy log std Std                       0.00603791\n",
      "Policy log std Max                      -0.105326\n",
      "Policy log std Min                      -0.173818\n",
      "Z mean eval                              0.0215428\n",
      "Z variance eval                          0.296725\n",
      "AverageTrainReturn_all_train_tasks      -0.0505227\n",
      "AverageReturn_all_train_tasks            1.1586\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AverageReturn_all_test_tasks             1.31328\n",
      "Number of train steps total          31500\n",
      "Number of env steps total           142000\n",
      "Number of rollouts total                 0\n",
      "Train Time (s)                          28.896\n",
      "(Previous) Eval Time (s)                 5.14596\n",
      "Sample Time (s)                          3.16284\n",
      "Epoch Time (s)                          37.2048\n",
      "Total Train Time (s)                  2880.35\n",
      "Epoch                                   62\n",
      "----------------------------------  ---------------\n",
      "2020-06-11 14:57:56.453067 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #62 | Epoch Duration: 37.300941467285156\n",
      "2020-06-11 14:57:56.454065 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #62 | Started Training: True\n",
      "----------------------------------  ---------------\n",
      "Z mean train                             0.0171742\n",
      "Z variance train                         0.962574\n",
      "KL Divergence                            0.0157\n",
      "KL Loss                                  0.00157\n",
      "QF Loss                                  0.145954\n",
      "VF Loss                                  0.230625\n",
      "Policy Loss                           -153.394\n",
      "Q Predictions Mean                     151.668\n",
      "Q Predictions Std                        1.87611\n",
      "Q Predictions Max                      155.079\n",
      "Q Predictions Min                      135.649\n",
      "V Predictions Mean                     153.812\n",
      "V Predictions Std                        1.8731\n",
      "V Predictions Max                      157.347\n",
      "V Predictions Min                      138.261\n",
      "Log Pis Mean                            -2.01365\n",
      "Log Pis Std                              0.313604\n",
      "Log Pis Max                             -0.947832\n",
      "Log Pis Min                             -3.74131\n",
      "Policy mu Mean                           0.0608814\n",
      "Policy mu Std                            0.114835\n",
      "Policy mu Max                            0.467055\n",
      "Policy mu Min                           -0.14774\n",
      "Policy log std Mean                     -0.139489\n",
      "Policy log std Std                       0.00681502\n",
      "Policy log std Max                      -0.125797\n",
      "Policy log std Min                      -0.18072\n",
      "Z mean eval                              0.0308482\n",
      "Z variance eval                          0.29197\n",
      "AverageTrainReturn_all_train_tasks      -0.0495127\n",
      "AverageReturn_all_train_tasks           -0.046944\n",
      "AverageReturn_all_test_tasks            -0.0473693\n",
      "Number of train steps total          32000\n",
      "Number of env steps total           144000\n",
      "Number of rollouts total                 0\n",
      "Train Time (s)                          29.1288\n",
      "(Previous) Eval Time (s)                 5.24234\n",
      "Sample Time (s)                          3.10091\n",
      "Epoch Time (s)                          37.4721\n",
      "Total Train Time (s)                  2917.88\n",
      "Epoch                                   63\n",
      "----------------------------------  ---------------\n",
      "2020-06-11 14:58:33.996347 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #63 | Epoch Duration: 37.541282176971436\n",
      "2020-06-11 14:58:33.997346 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #63 | Started Training: True\n",
      "----------------------------------  ---------------\n",
      "Z mean train                             0.0300867\n",
      "Z variance train                         0.911381\n",
      "KL Divergence                            0.0550465\n",
      "KL Loss                                  0.00550465\n",
      "QF Loss                                  0.148845\n",
      "VF Loss                                  0.0519103\n",
      "Policy Loss                           -154.724\n",
      "Q Predictions Mean                     152.816\n",
      "Q Predictions Std                        2.08486\n",
      "Q Predictions Max                      157.045\n",
      "Q Predictions Min                      139.633\n",
      "V Predictions Mean                     154.777\n",
      "V Predictions Std                        2.06173\n",
      "V Predictions Max                      158.878\n",
      "V Predictions Min                      142.545\n",
      "Log Pis Mean                            -2.01014\n",
      "Log Pis Std                              0.350146\n",
      "Log Pis Max                             -0.711523\n",
      "Log Pis Min                             -4.18603\n",
      "Policy mu Mean                           0.0478557\n",
      "Policy mu Std                            0.132605\n",
      "Policy mu Max                            0.461745\n",
      "Policy mu Min                           -0.155815\n",
      "Policy log std Mean                     -0.132164\n",
      "Policy log std Std                       0.00990523\n",
      "Policy log std Max                      -0.118943\n",
      "Policy log std Min                      -0.191765\n",
      "Z mean eval                              0.0248492\n",
      "Z variance eval                          0.261116\n",
      "AverageTrainReturn_all_train_tasks      -0.0495945\n",
      "AverageReturn_all_train_tasks           -0.0512473\n",
      "AverageReturn_all_test_tasks            -0.0466886\n",
      "Number of train steps total          32500\n",
      "Number of env steps total           146000\n",
      "Number of rollouts total                 0\n",
      "Train Time (s)                          29.0738\n",
      "(Previous) Eval Time (s)                 5.3113\n",
      "Sample Time (s)                          3.00011\n",
      "Epoch Time (s)                          37.3852\n",
      "Total Train Time (s)                  2955.26\n",
      "Epoch                                   64\n",
      "----------------------------------  ---------------\n",
      "2020-06-11 14:59:11.373400 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #64 | Epoch Duration: 37.37405252456665\n",
      "2020-06-11 14:59:11.375398 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #64 | Started Training: True\n",
      "----------------------------------  ---------------\n",
      "Z mean train                             0.0297313\n",
      "Z variance train                         0.834575\n",
      "KL Divergence                            0.1811\n",
      "KL Loss                                  0.01811\n",
      "QF Loss                                  0.166522\n",
      "VF Loss                                  0.104975\n",
      "Policy Loss                           -155.827\n",
      "Q Predictions Mean                     154.05\n",
      "Q Predictions Std                        1.8955\n",
      "Q Predictions Max                      156.802\n",
      "Q Predictions Min                      142.478\n",
      "V Predictions Mean                     155.644\n",
      "V Predictions Std                        1.89859\n",
      "V Predictions Max                      158.654\n",
      "V Predictions Min                      144.323\n",
      "Log Pis Mean                            -2.00868\n",
      "Log Pis Std                              0.308502\n",
      "Log Pis Max                             -0.681779\n",
      "Log Pis Min                             -3.36211\n",
      "Policy mu Mean                           0.0466106\n",
      "Policy mu Std                            0.114208\n",
      "Policy mu Max                            0.433482\n",
      "Policy mu Min                           -0.17283\n",
      "Policy log std Mean                     -0.135737\n",
      "Policy log std Std                       0.00655479\n",
      "Policy log std Max                      -0.121825\n",
      "Policy log std Min                      -0.174277\n",
      "Z mean eval                              0.0204233\n",
      "Z variance eval                          0.296598\n",
      "AverageTrainReturn_all_train_tasks      -0.0490942\n",
      "AverageReturn_all_train_tasks            0.15031\n",
      "AverageReturn_all_test_tasks            -0.0487045\n",
      "Number of train steps total          33000\n",
      "Number of env steps total           148000\n",
      "Number of rollouts total                 0\n",
      "Train Time (s)                          28.9702\n",
      "(Previous) Eval Time (s)                 5.3005\n",
      "Sample Time (s)                          3.07508\n",
      "Epoch Time (s)                          37.3458\n",
      "Total Train Time (s)                  2992.58\n",
      "Epoch                                   65\n",
      "----------------------------------  ---------------\n",
      "2020-06-11 14:59:48.684830 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #65 | Epoch Duration: 37.30843257904053\n",
      "2020-06-11 14:59:48.684830 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #65 | Started Training: True\n",
      "----------------------------------  ---------------\n",
      "Z mean train                             0.0198696\n",
      "Z variance train                         0.938738\n",
      "KL Divergence                            0.021112\n",
      "KL Loss                                  0.0021112\n",
      "QF Loss                                  0.171695\n",
      "VF Loss                                  0.127602\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy Loss                           -156.141\n",
      "Q Predictions Mean                     153.898\n",
      "Q Predictions Std                        1.97365\n",
      "Q Predictions Max                      158.314\n",
      "Q Predictions Min                      139.962\n",
      "V Predictions Mean                     155.874\n",
      "V Predictions Std                        1.97374\n",
      "V Predictions Max                      160.274\n",
      "V Predictions Min                      142.018\n",
      "Log Pis Mean                            -2.01309\n",
      "Log Pis Std                              0.322526\n",
      "Log Pis Max                             -0.924039\n",
      "Log Pis Min                             -3.8133\n",
      "Policy mu Mean                           0.0579489\n",
      "Policy mu Std                            0.110099\n",
      "Policy mu Max                            0.45296\n",
      "Policy mu Min                           -0.163157\n",
      "Policy log std Mean                     -0.130282\n",
      "Policy log std Std                       0.00782799\n",
      "Policy log std Max                      -0.118731\n",
      "Policy log std Min                      -0.174246\n",
      "Z mean eval                              0.0150428\n",
      "Z variance eval                          0.245576\n",
      "AverageTrainReturn_all_train_tasks      -0.0484031\n",
      "AverageReturn_all_train_tasks           -0.0506274\n",
      "AverageReturn_all_test_tasks            -0.0501381\n",
      "Number of train steps total          33500\n",
      "Number of env steps total           150000\n",
      "Number of rollouts total                 0\n",
      "Train Time (s)                          30.6281\n",
      "(Previous) Eval Time (s)                 5.2621\n",
      "Sample Time (s)                          3.16272\n",
      "Epoch Time (s)                          39.0529\n",
      "Total Train Time (s)                  3032.4\n",
      "Epoch                                   66\n",
      "----------------------------------  ---------------\n",
      "2020-06-11 15:00:28.512282 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #66 | Epoch Duration: 39.82645297050476\n",
      "2020-06-11 15:00:28.513282 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #66 | Started Training: True\n",
      "----------------------------------  ---------------\n",
      "Z mean train                             0.0137569\n",
      "Z variance train                         0.778865\n",
      "KL Divergence                            0.286418\n",
      "KL Loss                                  0.0286418\n",
      "QF Loss                                  0.196049\n",
      "VF Loss                                  0.174929\n",
      "Policy Loss                           -157.962\n",
      "Q Predictions Mean                     155.88\n",
      "Q Predictions Std                        1.84641\n",
      "Q Predictions Max                      159.367\n",
      "Q Predictions Min                      146.483\n",
      "V Predictions Mean                     157.682\n",
      "V Predictions Std                        1.85009\n",
      "V Predictions Max                      161.142\n",
      "V Predictions Min                      148.416\n",
      "Log Pis Mean                            -2.02221\n",
      "Log Pis Std                              0.353839\n",
      "Log Pis Max                             -0.95773\n",
      "Log Pis Min                             -4.5358\n",
      "Policy mu Mean                           0.0575979\n",
      "Policy mu Std                            0.123004\n",
      "Policy mu Max                            0.438028\n",
      "Policy mu Min                           -0.14524\n",
      "Policy log std Mean                     -0.13716\n",
      "Policy log std Std                       0.00638667\n",
      "Policy log std Max                      -0.124365\n",
      "Policy log std Min                      -0.166421\n",
      "Z mean eval                              0.0343728\n",
      "Z variance eval                          0.232181\n",
      "AverageTrainReturn_all_train_tasks      -0.0588343\n",
      "AverageReturn_all_train_tasks           -0.0548648\n",
      "AverageReturn_all_test_tasks            -0.0554607\n",
      "Number of train steps total          34000\n",
      "Number of env steps total           152000\n",
      "Number of rollouts total                 0\n",
      "Train Time (s)                          29.2498\n",
      "(Previous) Eval Time (s)                 6.03498\n",
      "Sample Time (s)                          3.23468\n",
      "Epoch Time (s)                          38.5195\n",
      "Total Train Time (s)                  3070.07\n",
      "Epoch                                   67\n",
      "----------------------------------  ---------------\n",
      "2020-06-11 15:01:06.195464 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #67 | Epoch Duration: 37.680182695388794\n",
      "2020-06-11 15:01:06.196463 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #67 | Started Training: True\n",
      "----------------------------------  ---------------\n",
      "Z mean train                             0.0311611\n",
      "Z variance train                         0.733357\n",
      "KL Divergence                            0.456328\n",
      "KL Loss                                  0.0456328\n",
      "QF Loss                                  0.573601\n",
      "VF Loss                                  0.464605\n",
      "Policy Loss                           -158.488\n",
      "Q Predictions Mean                     156.126\n",
      "Q Predictions Std                        2.13531\n",
      "Q Predictions Max                      159.927\n",
      "Q Predictions Min                      138.625\n",
      "V Predictions Mean                     158.298\n",
      "V Predictions Std                        2.03057\n",
      "V Predictions Max                      162.172\n",
      "V Predictions Min                      141.822\n",
      "Log Pis Mean                            -2.02181\n",
      "Log Pis Std                              0.305908\n",
      "Log Pis Max                             -0.672455\n",
      "Log Pis Min                             -3.67527\n",
      "Policy mu Mean                           0.0583831\n",
      "Policy mu Std                            0.105161\n",
      "Policy mu Max                            0.419533\n",
      "Policy mu Min                           -0.150092\n",
      "Policy log std Mean                     -0.129611\n",
      "Policy log std Std                       0.00497318\n",
      "Policy log std Max                      -0.119482\n",
      "Policy log std Min                      -0.164029\n",
      "Z mean eval                              0.0211015\n",
      "Z variance eval                          0.259837\n",
      "AverageTrainReturn_all_train_tasks      -0.046156\n",
      "AverageReturn_all_train_tasks           -0.047783\n",
      "AverageReturn_all_test_tasks             0.238354\n",
      "Number of train steps total          34500\n",
      "Number of env steps total           154000\n",
      "Number of rollouts total                 0\n",
      "Train Time (s)                          28.8276\n",
      "(Previous) Eval Time (s)                 5.19582\n",
      "Sample Time (s)                          3.01663\n",
      "Epoch Time (s)                          37.0401\n",
      "Total Train Time (s)                  3107.42\n",
      "Epoch                                   68\n",
      "----------------------------------  ---------------\n",
      "2020-06-11 15:01:43.539015 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #68 | Epoch Duration: 37.34055304527283\n",
      "2020-06-11 15:01:43.540014 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #68 | Started Training: True\n",
      "----------------------------------  ---------------\n",
      "Z mean train                             0.0199158\n",
      "Z variance train                         0.807516\n",
      "KL Divergence                            0.221617\n",
      "KL Loss                                  0.0221617\n",
      "QF Loss                                  0.247733\n",
      "VF Loss                                  0.346582\n",
      "Policy Loss                           -158.12\n",
      "Q Predictions Mean                     156.586\n",
      "Q Predictions Std                        1.93608\n",
      "Q Predictions Max                      160.43\n",
      "Q Predictions Min                      144.512\n",
      "V Predictions Mean                     158.501\n",
      "V Predictions Std                        1.93739\n",
      "V Predictions Max                      162.02\n",
      "V Predictions Min                      145.711\n",
      "Log Pis Mean                            -2.01679\n",
      "Log Pis Std                              0.355401\n",
      "Log Pis Max                             -0.634402\n",
      "Log Pis Min                             -4.81541\n",
      "Policy mu Mean                           0.0590444\n",
      "Policy mu Std                            0.119656\n",
      "Policy mu Max                            0.475961\n",
      "Policy mu Min                           -0.134511\n",
      "Policy log std Mean                     -0.131706\n",
      "Policy log std Std                       0.00490876\n",
      "Policy log std Max                      -0.120686\n",
      "Policy log std Min                      -0.160738\n",
      "Z mean eval                              0.025616\n",
      "Z variance eval                          0.286257\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AverageTrainReturn_all_train_tasks       0.27683\n",
      "AverageReturn_all_train_tasks            1.37662\n",
      "AverageReturn_all_test_tasks            -0.0471614\n",
      "Number of train steps total          35000\n",
      "Number of env steps total           156000\n",
      "Number of rollouts total                 0\n",
      "Train Time (s)                          29.0567\n",
      "(Previous) Eval Time (s)                 5.49672\n",
      "Sample Time (s)                          3.00615\n",
      "Epoch Time (s)                          37.5595\n",
      "Total Train Time (s)                  3144.67\n",
      "Epoch                                   69\n",
      "----------------------------------  ---------------\n",
      "2020-06-11 15:02:20.787995 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #69 | Epoch Duration: 37.24598217010498\n",
      "2020-06-11 15:02:20.787995 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #69 | Started Training: True\n",
      "----------------------------------  ---------------\n",
      "Z mean train                             0.0235528\n",
      "Z variance train                         0.9067\n",
      "KL Divergence                            0.0711881\n",
      "KL Loss                                  0.00711881\n",
      "QF Loss                                  0.319573\n",
      "VF Loss                                  0.227076\n",
      "Policy Loss                           -159.203\n",
      "Q Predictions Mean                     156.924\n",
      "Q Predictions Std                        1.92073\n",
      "Q Predictions Max                      160.55\n",
      "Q Predictions Min                      140.972\n",
      "V Predictions Mean                     159.577\n",
      "V Predictions Std                        1.98853\n",
      "V Predictions Max                      163.056\n",
      "V Predictions Min                      144.684\n",
      "Log Pis Mean                            -2.03312\n",
      "Log Pis Std                              0.346337\n",
      "Log Pis Max                             -0.630456\n",
      "Log Pis Min                             -4.44317\n",
      "Policy mu Mean                           0.0710278\n",
      "Policy mu Std                            0.107658\n",
      "Policy mu Max                            0.419643\n",
      "Policy mu Min                           -0.134389\n",
      "Policy log std Mean                     -0.133889\n",
      "Policy log std Std                       0.00712937\n",
      "Policy log std Max                      -0.114634\n",
      "Policy log std Min                      -0.168721\n",
      "Z mean eval                              0.0229675\n",
      "Z variance eval                          0.307644\n",
      "AverageTrainReturn_all_train_tasks      -0.0474702\n",
      "AverageReturn_all_train_tasks           -0.0476353\n",
      "AverageReturn_all_test_tasks            -0.0482136\n",
      "Number of train steps total          35500\n",
      "Number of env steps total           158000\n",
      "Number of rollouts total                 0\n",
      "Train Time (s)                          28.8849\n",
      "(Previous) Eval Time (s)                 5.18347\n",
      "Sample Time (s)                          3.06884\n",
      "Epoch Time (s)                          37.1372\n",
      "Total Train Time (s)                  3181.95\n",
      "Epoch                                   70\n",
      "----------------------------------  ---------------\n",
      "2020-06-11 15:02:58.072598 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #70 | Epoch Duration: 37.28360390663147\n",
      "2020-06-11 15:02:58.073598 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #70 | Started Training: True\n",
      "----------------------------------  ---------------\n",
      "Z mean train                             0.0190343\n",
      "Z variance train                         0.968768\n",
      "KL Divergence                            0.0120869\n",
      "KL Loss                                  0.00120869\n",
      "QF Loss                                  0.182448\n",
      "VF Loss                                  0.102404\n",
      "Policy Loss                           -160.464\n",
      "Q Predictions Mean                     158.226\n",
      "Q Predictions Std                        1.89827\n",
      "Q Predictions Max                      161.396\n",
      "Q Predictions Min                      148.284\n",
      "V Predictions Mean                     160.504\n",
      "V Predictions Std                        1.95477\n",
      "V Predictions Max                      163.711\n",
      "V Predictions Min                      149.753\n",
      "Log Pis Mean                            -2.00969\n",
      "Log Pis Std                              0.32885\n",
      "Log Pis Max                             -0.795948\n",
      "Log Pis Min                             -3.41151\n",
      "Policy mu Mean                           0.0525795\n",
      "Policy mu Std                            0.121073\n",
      "Policy mu Max                            0.416654\n",
      "Policy mu Min                           -0.14448\n",
      "Policy log std Mean                     -0.131973\n",
      "Policy log std Std                       0.00626023\n",
      "Policy log std Max                      -0.122616\n",
      "Policy log std Min                      -0.169761\n",
      "Z mean eval                              0.0114022\n",
      "Z variance eval                          0.276542\n",
      "AverageTrainReturn_all_train_tasks      -0.0546371\n",
      "AverageReturn_all_train_tasks           -0.0578143\n",
      "AverageReturn_all_test_tasks            -0.0535653\n",
      "Number of train steps total          36000\n",
      "Number of env steps total           160000\n",
      "Number of rollouts total                 0\n",
      "Train Time (s)                          28.746\n",
      "(Previous) Eval Time (s)                 5.32926\n",
      "Sample Time (s)                          3.12502\n",
      "Epoch Time (s)                          37.2003\n",
      "Total Train Time (s)                  3218.96\n",
      "Epoch                                   71\n",
      "----------------------------------  ---------------\n",
      "2020-06-11 15:03:35.074317 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #71 | Epoch Duration: 36.999717235565186\n",
      "2020-06-11 15:03:35.075315 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #71 | Started Training: True\n",
      "----------------------------------  ---------------\n",
      "Z mean train                             0.00963642\n",
      "Z variance train                         0.855451\n",
      "KL Divergence                            0.110512\n",
      "KL Loss                                  0.0110512\n",
      "QF Loss                                  0.29191\n",
      "VF Loss                                  0.142111\n",
      "Policy Loss                           -160.134\n",
      "Q Predictions Mean                     157.992\n",
      "Q Predictions Std                        1.9364\n",
      "Q Predictions Max                      161.816\n",
      "Q Predictions Min                      148.118\n",
      "V Predictions Mean                     160.187\n",
      "V Predictions Std                        1.87453\n",
      "V Predictions Max                      163.916\n",
      "V Predictions Min                      149.291\n",
      "Log Pis Mean                            -2.03541\n",
      "Log Pis Std                              0.340809\n",
      "Log Pis Max                             -0.653372\n",
      "Log Pis Min                             -4.46046\n",
      "Policy mu Mean                           0.0634054\n",
      "Policy mu Std                            0.114031\n",
      "Policy mu Max                            0.447405\n",
      "Policy mu Min                           -0.150156\n",
      "Policy log std Mean                     -0.132054\n",
      "Policy log std Std                       0.00433889\n",
      "Policy log std Max                      -0.120205\n",
      "Policy log std Min                      -0.159502\n",
      "Z mean eval                              0.013762\n",
      "Z variance eval                          0.314028\n",
      "AverageTrainReturn_all_train_tasks       1.36765\n",
      "AverageReturn_all_train_tasks            0.442326\n",
      "AverageReturn_all_test_tasks             9.60247\n",
      "Number of train steps total          36500\n",
      "Number of env steps total           162000\n",
      "Number of rollouts total                 0\n",
      "Train Time (s)                          28.8413\n",
      "(Previous) Eval Time (s)                 5.12881\n",
      "Sample Time (s)                          2.93037\n",
      "Epoch Time (s)                          36.9005\n",
      "Total Train Time (s)                  3255.98\n",
      "Epoch                                   72\n",
      "----------------------------------  ---------------\n",
      "2020-06-11 15:04:12.104975 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #72 | Epoch Duration: 37.028661251068115\n",
      "2020-06-11 15:04:12.105975 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #72 | Started Training: True\n",
      "----------------------------------  ---------------\n",
      "Z mean train                             0.012727\n",
      "Z variance train                         0.936213\n",
      "KL Divergence                            0.0335217\n",
      "KL Loss                                  0.00335217\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QF Loss                                  0.0884508\n",
      "VF Loss                                  0.0608248\n",
      "Policy Loss                           -161.207\n",
      "Q Predictions Mean                     159.28\n",
      "Q Predictions Std                        1.92797\n",
      "Q Predictions Max                      163.568\n",
      "Q Predictions Min                      146.662\n",
      "V Predictions Mean                     161.298\n",
      "V Predictions Std                        1.86061\n",
      "V Predictions Max                      165.412\n",
      "V Predictions Min                      148.955\n",
      "Log Pis Mean                            -2.00408\n",
      "Log Pis Std                              0.325505\n",
      "Log Pis Max                             -0.858606\n",
      "Log Pis Min                             -3.30331\n",
      "Policy mu Mean                           0.0493454\n",
      "Policy mu Std                            0.127117\n",
      "Policy mu Max                            0.443056\n",
      "Policy mu Min                           -0.155487\n",
      "Policy log std Mean                     -0.135091\n",
      "Policy log std Std                       0.00811448\n",
      "Policy log std Max                      -0.121782\n",
      "Policy log std Min                      -0.188403\n",
      "Z mean eval                              0.030179\n",
      "Z variance eval                          0.339227\n",
      "AverageTrainReturn_all_train_tasks      -0.0576591\n",
      "AverageReturn_all_train_tasks            0.846488\n",
      "AverageReturn_all_test_tasks             0.545566\n",
      "Number of train steps total          37000\n",
      "Number of env steps total           164000\n",
      "Number of rollouts total                 0\n",
      "Train Time (s)                          28.8215\n",
      "(Previous) Eval Time (s)                 5.25739\n",
      "Sample Time (s)                          3.01142\n",
      "Epoch Time (s)                          37.0903\n",
      "Total Train Time (s)                  3293.07\n",
      "Epoch                                   73\n",
      "----------------------------------  ---------------\n",
      "2020-06-11 15:04:49.188528 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #73 | Epoch Duration: 37.0815532207489\n",
      "2020-06-11 15:04:49.189527 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #73 | Started Training: True\n",
      "----------------------------------  ---------------\n",
      "Z mean train                             0.028838\n",
      "Z variance train                         1.01733\n",
      "KL Divergence                            0.0117845\n",
      "KL Loss                                  0.00117845\n",
      "QF Loss                                  0.234291\n",
      "VF Loss                                  0.224569\n",
      "Policy Loss                           -162.023\n",
      "Q Predictions Mean                     160.262\n",
      "Q Predictions Std                        2.04677\n",
      "Q Predictions Max                      163.63\n",
      "Q Predictions Min                      147.713\n",
      "V Predictions Mean                     161.923\n",
      "V Predictions Std                        2.14419\n",
      "V Predictions Max                      165.795\n",
      "V Predictions Min                      148.876\n",
      "Log Pis Mean                            -2.01167\n",
      "Log Pis Std                              0.367111\n",
      "Log Pis Max                             -0.753732\n",
      "Log Pis Min                             -3.88649\n",
      "Policy mu Mean                           0.0531714\n",
      "Policy mu Std                            0.129322\n",
      "Policy mu Max                            0.469121\n",
      "Policy mu Min                           -0.150175\n",
      "Policy log std Mean                     -0.133397\n",
      "Policy log std Std                       0.00867561\n",
      "Policy log std Max                      -0.116799\n",
      "Policy log std Min                      -0.178997\n",
      "Z mean eval                              0.024851\n",
      "Z variance eval                          0.304558\n",
      "AverageTrainReturn_all_train_tasks      -0.057535\n",
      "AverageReturn_all_train_tasks           -0.0533111\n",
      "AverageReturn_all_test_tasks            -0.0563148\n",
      "Number of train steps total          37500\n",
      "Number of env steps total           166000\n",
      "Number of rollouts total                 0\n",
      "Train Time (s)                          29.019\n",
      "(Previous) Eval Time (s)                 5.24863\n",
      "Sample Time (s)                          3.00037\n",
      "Epoch Time (s)                          37.268\n",
      "Total Train Time (s)                  3330.24\n",
      "Epoch                                   74\n",
      "----------------------------------  ---------------\n",
      "2020-06-11 15:05:26.368130 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #74 | Epoch Duration: 37.17760348320007\n",
      "2020-06-11 15:05:26.369130 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #74 | Started Training: True\n",
      "----------------------------------  ---------------\n",
      "Z mean train                             0.0231837\n",
      "Z variance train                         0.950709\n",
      "KL Divergence                            0.0201323\n",
      "KL Loss                                  0.00201323\n",
      "QF Loss                                  0.157376\n",
      "VF Loss                                  0.176568\n",
      "Policy Loss                           -163.18\n",
      "Q Predictions Mean                     160.986\n",
      "Q Predictions Std                        1.83044\n",
      "Q Predictions Max                      164.858\n",
      "Q Predictions Min                      150.567\n",
      "V Predictions Mean                     163.278\n",
      "V Predictions Std                        1.81702\n",
      "V Predictions Max                      166.936\n",
      "V Predictions Min                      152.038\n",
      "Log Pis Mean                            -2.0202\n",
      "Log Pis Std                              0.33021\n",
      "Log Pis Max                             -0.839842\n",
      "Log Pis Min                             -4.0996\n",
      "Policy mu Mean                           0.0538678\n",
      "Policy mu Std                            0.121047\n",
      "Policy mu Max                            0.456698\n",
      "Policy mu Min                           -0.148392\n",
      "Policy log std Mean                     -0.133331\n",
      "Policy log std Std                       0.005845\n",
      "Policy log std Max                      -0.120474\n",
      "Policy log std Min                      -0.171949\n",
      "Z mean eval                              0.0108795\n",
      "Z variance eval                          0.298685\n",
      "AverageTrainReturn_all_train_tasks      -0.0480315\n",
      "AverageReturn_all_train_tasks           -0.0476887\n",
      "AverageReturn_all_test_tasks            -0.0485333\n",
      "Number of train steps total          38000\n",
      "Number of env steps total           168000\n",
      "Number of rollouts total                 0\n",
      "Train Time (s)                          28.9531\n",
      "(Previous) Eval Time (s)                 5.15775\n",
      "Sample Time (s)                          2.94334\n",
      "Epoch Time (s)                          37.0542\n",
      "Total Train Time (s)                  3367.45\n",
      "Epoch                                   75\n",
      "----------------------------------  ---------------\n",
      "2020-06-11 15:06:03.578521 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #75 | Epoch Duration: 37.20539355278015\n",
      "2020-06-11 15:06:03.578521 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #75 | Started Training: True\n",
      "----------------------------------  ---------------\n",
      "Z mean train                             0.011014\n",
      "Z variance train                         0.95196\n",
      "KL Divergence                            0.0145781\n",
      "KL Loss                                  0.00145781\n",
      "QF Loss                                  0.103983\n",
      "VF Loss                                  0.128217\n",
      "Policy Loss                           -163.689\n",
      "Q Predictions Mean                     161.66\n",
      "Q Predictions Std                        2.12209\n",
      "Q Predictions Max                      165.517\n",
      "Q Predictions Min                      151.895\n",
      "V Predictions Mean                     163.563\n",
      "V Predictions Std                        2.09133\n",
      "V Predictions Max                      167.292\n",
      "V Predictions Min                      153.626\n",
      "Log Pis Mean                            -2.03477\n",
      "Log Pis Std                              0.360081\n",
      "Log Pis Max                             -1.03493\n",
      "Log Pis Min                             -6.29591\n",
      "Policy mu Mean                           0.0580792\n",
      "Policy mu Std                            0.1255\n",
      "Policy mu Max                            0.440659\n",
      "Policy mu Min                           -0.14013\n",
      "Policy log std Mean                     -0.1328\n",
      "Policy log std Std                       0.00692794\n",
      "Policy log std Max                      -0.115558\n",
      "Policy log std Min                      -0.173321\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z mean eval                              0.00762611\n",
      "Z variance eval                          0.283241\n",
      "AverageTrainReturn_all_train_tasks       0.119868\n",
      "AverageReturn_all_train_tasks           -0.0536994\n",
      "AverageReturn_all_test_tasks             0.607667\n",
      "Number of train steps total          38500\n",
      "Number of env steps total           170000\n",
      "Number of rollouts total                 0\n",
      "Train Time (s)                          29.0895\n",
      "(Previous) Eval Time (s)                 5.30966\n",
      "Sample Time (s)                          3.16226\n",
      "Epoch Time (s)                          37.5614\n",
      "Total Train Time (s)                  3404.89\n",
      "Epoch                                   76\n",
      "----------------------------------  ---------------\n",
      "2020-06-11 15:06:41.023963 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #76 | Epoch Duration: 37.44444298744202\n",
      "2020-06-11 15:06:41.024963 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #76 | Started Training: True\n",
      "----------------------------------  ---------------\n",
      "Z mean train                             0.00729615\n",
      "Z variance train                         0.8515\n",
      "KL Divergence                            0.124312\n",
      "KL Loss                                  0.0124312\n",
      "QF Loss                                  0.125644\n",
      "VF Loss                                  0.0783299\n",
      "Policy Loss                           -165.141\n",
      "Q Predictions Mean                     163.147\n",
      "Q Predictions Std                        2.21595\n",
      "Q Predictions Max                      167.124\n",
      "Q Predictions Min                      146.018\n",
      "V Predictions Mean                     164.951\n",
      "V Predictions Std                        2.25206\n",
      "V Predictions Max                      168.962\n",
      "V Predictions Min                      147.788\n",
      "Log Pis Mean                            -2.01442\n",
      "Log Pis Std                              0.343619\n",
      "Log Pis Max                             -0.925067\n",
      "Log Pis Min                             -3.68296\n",
      "Policy mu Mean                           0.0462145\n",
      "Policy mu Std                            0.132165\n",
      "Policy mu Max                            0.44262\n",
      "Policy mu Min                           -0.159454\n",
      "Policy log std Mean                     -0.132587\n",
      "Policy log std Std                       0.00741545\n",
      "Policy log std Max                      -0.121573\n",
      "Policy log std Min                      -0.178546\n",
      "Z mean eval                              0.0143896\n",
      "Z variance eval                          0.302879\n",
      "AverageTrainReturn_all_train_tasks       0.640549\n",
      "AverageReturn_all_train_tasks            0.101461\n",
      "AverageReturn_all_test_tasks             0.706441\n",
      "Number of train steps total          39000\n",
      "Number of env steps total           172000\n",
      "Number of rollouts total                 0\n",
      "Train Time (s)                          29.1114\n",
      "(Previous) Eval Time (s)                 5.19203\n",
      "Sample Time (s)                          2.96328\n",
      "Epoch Time (s)                          37.2667\n",
      "Total Train Time (s)                  3442.08\n",
      "Epoch                                   77\n",
      "----------------------------------  ---------------\n",
      "2020-06-11 15:07:18.208085 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #77 | Epoch Duration: 37.1821231842041\n",
      "2020-06-11 15:07:18.209085 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #77 | Started Training: True\n",
      "----------------------------------  ---------------\n",
      "Z mean train                             0.0146758\n",
      "Z variance train                         0.942971\n",
      "KL Divergence                            0.0172896\n",
      "KL Loss                                  0.00172896\n",
      "QF Loss                                  0.126324\n",
      "VF Loss                                  0.165834\n",
      "Policy Loss                           -165.003\n",
      "Q Predictions Mean                     163.123\n",
      "Q Predictions Std                        2.19345\n",
      "Q Predictions Max                      167.778\n",
      "Q Predictions Min                      154.315\n",
      "V Predictions Mean                     165.237\n",
      "V Predictions Std                        2.13337\n",
      "V Predictions Max                      169.503\n",
      "V Predictions Min                      155.962\n",
      "Log Pis Mean                            -2.00913\n",
      "Log Pis Std                              0.347288\n",
      "Log Pis Max                             -0.671231\n",
      "Log Pis Min                             -4.43428\n",
      "Policy mu Mean                           0.0636106\n",
      "Policy mu Std                            0.12738\n",
      "Policy mu Max                            0.449111\n",
      "Policy mu Min                           -0.165788\n",
      "Policy log std Mean                     -0.136404\n",
      "Policy log std Std                       0.00725509\n",
      "Policy log std Max                      -0.121063\n",
      "Policy log std Min                      -0.172516\n",
      "Z mean eval                              0.0110577\n",
      "Z variance eval                          0.251664\n",
      "AverageTrainReturn_all_train_tasks      -0.0490877\n",
      "AverageReturn_all_train_tasks           -0.0487157\n",
      "AverageReturn_all_test_tasks            -0.0490346\n",
      "Number of train steps total          39500\n",
      "Number of env steps total           174000\n",
      "Number of rollouts total                 0\n",
      "Train Time (s)                          28.7153\n",
      "(Previous) Eval Time (s)                 5.10664\n",
      "Sample Time (s)                          2.98667\n",
      "Epoch Time (s)                          36.8086\n",
      "Total Train Time (s)                  3479.06\n",
      "Epoch                                   78\n",
      "----------------------------------  ---------------\n",
      "2020-06-11 15:07:55.184626 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #78 | Epoch Duration: 36.97554016113281\n",
      "2020-06-11 15:07:55.188624 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #78 | Started Training: True\n",
      "----------------------------------  ---------------\n",
      "Z mean train                             0.00764011\n",
      "Z variance train                         0.79217\n",
      "KL Divergence                            0.222079\n",
      "KL Loss                                  0.0222079\n",
      "QF Loss                                  0.131553\n",
      "VF Loss                                  0.0706344\n",
      "Policy Loss                           -166.318\n",
      "Q Predictions Mean                     164.182\n",
      "Q Predictions Std                        2.08556\n",
      "Q Predictions Max                      168.167\n",
      "Q Predictions Min                      151.065\n",
      "V Predictions Mean                     166.199\n",
      "V Predictions Std                        2.03741\n",
      "V Predictions Max                      170.003\n",
      "V Predictions Min                      152.833\n",
      "Log Pis Mean                            -2.01567\n",
      "Log Pis Std                              0.354111\n",
      "Log Pis Max                             -0.819769\n",
      "Log Pis Min                             -5.29066\n",
      "Policy mu Mean                           0.0557356\n",
      "Policy mu Std                            0.123676\n",
      "Policy mu Max                            0.43222\n",
      "Policy mu Min                           -0.150435\n",
      "Policy log std Mean                     -0.134389\n",
      "Policy log std Std                       0.00485746\n",
      "Policy log std Max                      -0.123533\n",
      "Policy log std Min                      -0.158428\n",
      "Z mean eval                              0.01222\n",
      "Z variance eval                          0.26758\n",
      "AverageTrainReturn_all_train_tasks      -0.0590463\n",
      "AverageReturn_all_train_tasks           -0.059261\n",
      "AverageReturn_all_test_tasks            -0.0586316\n",
      "Number of train steps total          40000\n",
      "Number of env steps total           176000\n",
      "Number of rollouts total                 0\n",
      "Train Time (s)                          29.0505\n",
      "(Previous) Eval Time (s)                 5.27344\n",
      "Sample Time (s)                          2.98551\n",
      "Epoch Time (s)                          37.3095\n",
      "Total Train Time (s)                  3516.21\n",
      "Epoch                                   79\n",
      "----------------------------------  ---------------\n",
      "2020-06-11 15:08:32.341792 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #79 | Epoch Duration: 37.15216875076294\n",
      "2020-06-11 15:08:32.342791 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #79 | Started Training: True\n",
      "----------------------------------  ---------------\n",
      "Z mean train                             0.0127209\n",
      "Z variance train                         0.85847\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KL Divergence                            0.113249\n",
      "KL Loss                                  0.0113249\n",
      "QF Loss                                  0.123566\n",
      "VF Loss                                  0.178773\n",
      "Policy Loss                           -166.88\n",
      "Q Predictions Mean                     164.811\n",
      "Q Predictions Std                        1.85058\n",
      "Q Predictions Max                      167.852\n",
      "Q Predictions Min                      154.093\n",
      "V Predictions Mean                     167.083\n",
      "V Predictions Std                        1.92316\n",
      "V Predictions Max                      170.807\n",
      "V Predictions Min                      155.954\n",
      "Log Pis Mean                            -2.02285\n",
      "Log Pis Std                              0.313766\n",
      "Log Pis Max                             -0.818841\n",
      "Log Pis Min                             -3.38237\n",
      "Policy mu Mean                           0.0409987\n",
      "Policy mu Std                            0.122227\n",
      "Policy mu Max                            0.428969\n",
      "Policy mu Min                           -0.156131\n",
      "Policy log std Mean                     -0.133947\n",
      "Policy log std Std                       0.00764071\n",
      "Policy log std Max                      -0.118972\n",
      "Policy log std Min                      -0.183532\n",
      "Z mean eval                              0.0167928\n",
      "Z variance eval                          0.250578\n",
      "AverageTrainReturn_all_train_tasks      -0.0507983\n",
      "AverageReturn_all_train_tasks           -0.048644\n",
      "AverageReturn_all_test_tasks             0.701254\n",
      "Number of train steps total          40500\n",
      "Number of env steps total           178000\n",
      "Number of rollouts total                 0\n",
      "Train Time (s)                          29.077\n",
      "(Previous) Eval Time (s)                 5.1154\n",
      "Sample Time (s)                          2.93105\n",
      "Epoch Time (s)                          37.1235\n",
      "Total Train Time (s)                  3553.69\n",
      "Epoch                                   80\n",
      "----------------------------------  ---------------\n",
      "2020-06-11 15:09:09.815884 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #80 | Epoch Duration: 37.47309231758118\n",
      "2020-06-11 15:09:09.816883 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #80 | Started Training: True\n",
      "----------------------------------  ---------------\n",
      "Z mean train                             0.0185824\n",
      "Z variance train                         0.824832\n",
      "KL Divergence                            0.212044\n",
      "KL Loss                                  0.0212044\n",
      "QF Loss                                  0.332718\n",
      "VF Loss                                  0.416026\n",
      "Policy Loss                           -167.132\n",
      "Q Predictions Mean                     165.198\n",
      "Q Predictions Std                        2.00184\n",
      "Q Predictions Max                      169.319\n",
      "Q Predictions Min                      156.218\n",
      "V Predictions Mean                     166.557\n",
      "V Predictions Std                        2.00596\n",
      "V Predictions Max                      170.72\n",
      "V Predictions Min                      157.129\n",
      "Log Pis Mean                            -2.02242\n",
      "Log Pis Std                              0.335781\n",
      "Log Pis Max                             -0.884785\n",
      "Log Pis Min                             -3.93721\n",
      "Policy mu Mean                           0.0650148\n",
      "Policy mu Std                            0.1139\n",
      "Policy mu Max                            0.4432\n",
      "Policy mu Min                           -0.151781\n",
      "Policy log std Mean                     -0.133261\n",
      "Policy log std Std                       0.00625269\n",
      "Policy log std Max                      -0.116336\n",
      "Policy log std Min                      -0.16875\n",
      "Z mean eval                              0.00526081\n",
      "Z variance eval                          0.226132\n",
      "AverageTrainReturn_all_train_tasks       3.00187\n",
      "AverageReturn_all_train_tasks           -0.0480537\n",
      "AverageReturn_all_test_tasks             3.63895\n",
      "Number of train steps total          41000\n",
      "Number of env steps total           180000\n",
      "Number of rollouts total                 0\n",
      "Train Time (s)                          29.8692\n",
      "(Previous) Eval Time (s)                 5.46446\n",
      "Sample Time (s)                          3.03688\n",
      "Epoch Time (s)                          38.3705\n",
      "Total Train Time (s)                  3592.01\n",
      "Epoch                                   81\n",
      "----------------------------------  ---------------\n",
      "2020-06-11 15:09:48.143697 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #81 | Epoch Duration: 38.32581400871277\n",
      "2020-06-11 15:09:48.144697 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #81 | Started Training: True\n",
      "----------------------------------  ---------------\n",
      "Z mean train                             0.00538576\n",
      "Z variance train                         0.722606\n",
      "KL Divergence                            0.45734\n",
      "KL Loss                                  0.045734\n",
      "QF Loss                                  0.162566\n",
      "VF Loss                                  0.166327\n",
      "Policy Loss                           -167.012\n",
      "Q Predictions Mean                     165.31\n",
      "Q Predictions Std                        1.9569\n",
      "Q Predictions Max                      169.133\n",
      "Q Predictions Min                      155.933\n",
      "V Predictions Mean                     167.315\n",
      "V Predictions Std                        1.98651\n",
      "V Predictions Max                      171.258\n",
      "V Predictions Min                      158.234\n",
      "Log Pis Mean                            -2.00122\n",
      "Log Pis Std                              0.332581\n",
      "Log Pis Max                             -0.71239\n",
      "Log Pis Min                             -3.25294\n",
      "Policy mu Mean                           0.0618195\n",
      "Policy mu Std                            0.127176\n",
      "Policy mu Max                            0.464822\n",
      "Policy mu Min                           -0.166074\n",
      "Policy log std Mean                     -0.133041\n",
      "Policy log std Std                       0.00656507\n",
      "Policy log std Max                      -0.121848\n",
      "Policy log std Min                      -0.166837\n",
      "Z mean eval                              0.0956073\n",
      "Z variance eval                          0.265454\n",
      "AverageTrainReturn_all_train_tasks       0.80041\n",
      "AverageReturn_all_train_tasks            1.17039\n",
      "AverageReturn_all_test_tasks             3.77045\n",
      "Number of train steps total          41500\n",
      "Number of env steps total           182000\n",
      "Number of rollouts total                 0\n",
      "Train Time (s)                          30.4232\n",
      "(Previous) Eval Time (s)                 5.42012\n",
      "Sample Time (s)                          2.99319\n",
      "Epoch Time (s)                          38.8365\n",
      "Total Train Time (s)                  3631.31\n",
      "Epoch                                   82\n",
      "----------------------------------  ---------------\n",
      "2020-06-11 15:10:27.437272 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #82 | Epoch Duration: 39.29157567024231\n",
      "2020-06-11 15:10:27.438271 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #82 | Started Training: True\n",
      "----------------------------------  ---------------\n",
      "Z mean train                             0.0977071\n",
      "Z variance train                         0.847649\n",
      "KL Divergence                            0.242981\n",
      "KL Loss                                  0.0242981\n",
      "QF Loss                                  1.07579\n",
      "VF Loss                                  0.135618\n",
      "Policy Loss                           -167.66\n",
      "Q Predictions Mean                     165.724\n",
      "Q Predictions Std                        2.3042\n",
      "Q Predictions Max                      169.355\n",
      "Q Predictions Min                      153.415\n",
      "V Predictions Mean                     167.621\n",
      "V Predictions Std                        2.33127\n",
      "V Predictions Max                      171.239\n",
      "V Predictions Min                      155.614\n",
      "Log Pis Mean                            -2.01719\n",
      "Log Pis Std                              0.32674\n",
      "Log Pis Max                             -0.754925\n",
      "Log Pis Min                             -3.90009\n",
      "Policy mu Mean                           0.0508788\n",
      "Policy mu Std                            0.12124\n",
      "Policy mu Max                            0.426106\n",
      "Policy mu Min                           -0.140103\n",
      "Policy log std Mean                     -0.13315\n",
      "Policy log std Std                       0.00761443\n",
      "Policy log std Max                      -0.123195\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy log std Min                      -0.181804\n",
      "Z mean eval                              0.0134069\n",
      "Z variance eval                          0.294703\n",
      "AverageTrainReturn_all_train_tasks      -0.0509577\n",
      "AverageReturn_all_train_tasks           -0.0499551\n",
      "AverageReturn_all_test_tasks            -0.0500628\n",
      "Number of train steps total          42000\n",
      "Number of env steps total           184000\n",
      "Number of rollouts total                 0\n",
      "Train Time (s)                          29.3316\n",
      "(Previous) Eval Time (s)                 5.87451\n",
      "Sample Time (s)                          3.14241\n",
      "Epoch Time (s)                          38.3485\n",
      "Total Train Time (s)                  3668.99\n",
      "Epoch                                   83\n",
      "----------------------------------  ---------------\n",
      "2020-06-11 15:11:05.135258 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #83 | Epoch Duration: 37.69598722457886\n",
      "2020-06-11 15:11:05.138257 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #83 | Started Training: True\n",
      "----------------------------------  ---------------\n",
      "Z mean train                             0.0127652\n",
      "Z variance train                         0.935374\n",
      "KL Divergence                            0.0222953\n",
      "KL Loss                                  0.00222953\n",
      "QF Loss                                  0.160637\n",
      "VF Loss                                  0.116887\n",
      "Policy Loss                           -169.052\n",
      "Q Predictions Mean                     167.041\n",
      "Q Predictions Std                        2.14616\n",
      "Q Predictions Max                      171.439\n",
      "Q Predictions Min                      155.392\n",
      "V Predictions Mean                     168.875\n",
      "V Predictions Std                        2.13903\n",
      "V Predictions Max                      173.291\n",
      "V Predictions Min                      156.626\n",
      "Log Pis Mean                            -2.00697\n",
      "Log Pis Std                              0.365591\n",
      "Log Pis Max                             -0.932643\n",
      "Log Pis Min                             -6.57315\n",
      "Policy mu Mean                           0.047002\n",
      "Policy mu Std                            0.131551\n",
      "Policy mu Max                            0.462636\n",
      "Policy mu Min                           -0.172139\n",
      "Policy log std Mean                     -0.133275\n",
      "Policy log std Std                       0.00578267\n",
      "Policy log std Max                      -0.120528\n",
      "Policy log std Min                      -0.16964\n",
      "Z mean eval                              0.00563089\n",
      "Z variance eval                          0.264859\n",
      "AverageTrainReturn_all_train_tasks      -0.051534\n",
      "AverageReturn_all_train_tasks           -0.0502099\n",
      "AverageReturn_all_test_tasks            -0.049237\n",
      "Number of train steps total          42500\n",
      "Number of env steps total           186000\n",
      "Number of rollouts total                 0\n",
      "Train Time (s)                          29.3585\n",
      "(Previous) Eval Time (s)                 5.22228\n",
      "Sample Time (s)                          3.06431\n",
      "Epoch Time (s)                          37.6451\n",
      "Total Train Time (s)                  3706.64\n",
      "Epoch                                   84\n",
      "----------------------------------  ---------------\n",
      "2020-06-11 15:11:42.775618 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #84 | Epoch Duration: 37.636361837387085\n",
      "2020-06-11 15:11:42.776626 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #84 | Started Training: True\n",
      "----------------------------------  ---------------\n",
      "Z mean train                             0.00582098\n",
      "Z variance train                         0.884634\n",
      "KL Divergence                            0.0786052\n",
      "KL Loss                                  0.00786052\n",
      "QF Loss                                  0.0972007\n",
      "VF Loss                                  0.060434\n",
      "Policy Loss                           -169.283\n",
      "Q Predictions Mean                     167.216\n",
      "Q Predictions Std                        2.36522\n",
      "Q Predictions Max                      170.85\n",
      "Q Predictions Min                      147.829\n",
      "V Predictions Mean                     169.278\n",
      "V Predictions Std                        2.34523\n",
      "V Predictions Max                      172.802\n",
      "V Predictions Min                      150.313\n",
      "Log Pis Mean                            -2.00925\n",
      "Log Pis Std                              0.349932\n",
      "Log Pis Max                             -0.611636\n",
      "Log Pis Min                             -3.33549\n",
      "Policy mu Mean                           0.0560952\n",
      "Policy mu Std                            0.130891\n",
      "Policy mu Max                            0.442706\n",
      "Policy mu Min                           -0.153445\n",
      "Policy log std Mean                     -0.138386\n",
      "Policy log std Std                       0.00696344\n",
      "Policy log std Max                      -0.121761\n",
      "Policy log std Min                      -0.177915\n",
      "Z mean eval                              0.0144958\n",
      "Z variance eval                          0.299551\n",
      "AverageTrainReturn_all_train_tasks      -0.0491537\n",
      "AverageReturn_all_train_tasks            0.151568\n",
      "AverageReturn_all_test_tasks            -0.0484633\n",
      "Number of train steps total          43000\n",
      "Number of env steps total           188000\n",
      "Number of rollouts total                 0\n",
      "Train Time (s)                          29.4628\n",
      "(Previous) Eval Time (s)                 5.21392\n",
      "Sample Time (s)                          3.13588\n",
      "Epoch Time (s)                          37.8126\n",
      "Total Train Time (s)                  3744.44\n",
      "Epoch                                   85\n",
      "----------------------------------  ---------------\n",
      "2020-06-11 15:12:20.569262 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #85 | Epoch Duration: 37.791645765304565\n",
      "2020-06-11 15:12:20.569262 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #85 | Started Training: True\n",
      "----------------------------------  ----------------\n",
      "Z mean train                             0.0161448\n",
      "Z variance train                         0.989103\n",
      "KL Divergence                            0.00485471\n",
      "KL Loss                                  0.000485471\n",
      "QF Loss                                  0.158329\n",
      "VF Loss                                  0.094411\n",
      "Policy Loss                           -169.389\n",
      "Q Predictions Mean                     167.536\n",
      "Q Predictions Std                        2.26168\n",
      "Q Predictions Max                      171.497\n",
      "Q Predictions Min                      155.813\n",
      "V Predictions Mean                     169.212\n",
      "V Predictions Std                        2.29865\n",
      "V Predictions Max                      173.189\n",
      "V Predictions Min                      157.991\n",
      "Log Pis Mean                            -2.00546\n",
      "Log Pis Std                              0.364307\n",
      "Log Pis Max                             -0.620057\n",
      "Log Pis Min                             -4.1281\n",
      "Policy mu Mean                           0.0738087\n",
      "Policy mu Std                            0.131395\n",
      "Policy mu Max                            0.488929\n",
      "Policy mu Min                           -0.156766\n",
      "Policy log std Mean                     -0.137779\n",
      "Policy log std Std                       0.00634726\n",
      "Policy log std Max                      -0.125806\n",
      "Policy log std Min                      -0.174904\n",
      "Z mean eval                              0.0129731\n",
      "Z variance eval                          0.287406\n",
      "AverageTrainReturn_all_train_tasks      -0.0490634\n",
      "AverageReturn_all_train_tasks           -0.0476153\n",
      "AverageReturn_all_test_tasks            -0.0491997\n",
      "Number of train steps total          43500\n",
      "Number of env steps total           190000\n",
      "Number of rollouts total                 0\n",
      "Train Time (s)                          29.0794\n",
      "(Previous) Eval Time (s)                 5.19197\n",
      "Sample Time (s)                          3.09514\n",
      "Epoch Time (s)                          37.3665\n",
      "Total Train Time (s)                  3781.76\n",
      "Epoch                                   86\n",
      "----------------------------------  ----------------\n",
      "2020-06-11 15:12:57.902834 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #86 | Epoch Duration: 37.33257341384888\n",
      "2020-06-11 15:12:57.903834 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #86 | Started Training: True\n",
      "----------------------------------  ---------------\n",
      "Z mean train                             0.0137495\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z variance train                         0.912725\n",
      "KL Divergence                            0.0384186\n",
      "KL Loss                                  0.00384186\n",
      "QF Loss                                  0.192694\n",
      "VF Loss                                  0.0555933\n",
      "Policy Loss                           -170.675\n",
      "Q Predictions Mean                     168.897\n",
      "Q Predictions Std                        2.36201\n",
      "Q Predictions Max                      172.623\n",
      "Q Predictions Min                      155.573\n",
      "V Predictions Mean                     170.765\n",
      "V Predictions Std                        2.39674\n",
      "V Predictions Max                      174.574\n",
      "V Predictions Min                      157.555\n",
      "Log Pis Mean                            -2.00716\n",
      "Log Pis Std                              0.351788\n",
      "Log Pis Max                             -0.898302\n",
      "Log Pis Min                             -3.94722\n",
      "Policy mu Mean                           0.0461247\n",
      "Policy mu Std                            0.131485\n",
      "Policy mu Max                            0.447093\n",
      "Policy mu Min                           -0.151689\n",
      "Policy log std Mean                     -0.133455\n",
      "Policy log std Std                       0.00848351\n",
      "Policy log std Max                      -0.115445\n",
      "Policy log std Min                      -0.178551\n",
      "Z mean eval                              0.013913\n",
      "Z variance eval                          0.275358\n",
      "AverageTrainReturn_all_train_tasks      -0.0492749\n",
      "AverageReturn_all_train_tasks           -0.0485641\n",
      "AverageReturn_all_test_tasks            -0.0506155\n",
      "Number of train steps total          44000\n",
      "Number of env steps total           192000\n",
      "Number of rollouts total                 0\n",
      "Train Time (s)                          29.4181\n",
      "(Previous) Eval Time (s)                 5.15798\n",
      "Sample Time (s)                          3.0347\n",
      "Epoch Time (s)                          37.6108\n",
      "Total Train Time (s)                  3819.35\n",
      "Epoch                                   87\n",
      "----------------------------------  ---------------\n",
      "2020-06-11 15:13:35.490735 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #87 | Epoch Duration: 37.585901975631714\n",
      "2020-06-11 15:13:35.491731 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #87 | Started Training: True\n",
      "----------------------------------  ---------------\n",
      "Z mean train                             0.0142681\n",
      "Z variance train                         0.879476\n",
      "KL Divergence                            0.0847978\n",
      "KL Loss                                  0.00847978\n",
      "QF Loss                                  0.122963\n",
      "VF Loss                                  0.284814\n",
      "Policy Loss                           -171.471\n",
      "Q Predictions Mean                     169.285\n",
      "Q Predictions Std                        2.01154\n",
      "Q Predictions Max                      173.175\n",
      "Q Predictions Min                      159.825\n",
      "V Predictions Mean                     171.445\n",
      "V Predictions Std                        1.94985\n",
      "V Predictions Max                      174.738\n",
      "V Predictions Min                      160.481\n",
      "Log Pis Mean                            -2.02998\n",
      "Log Pis Std                              0.335628\n",
      "Log Pis Max                             -0.791897\n",
      "Log Pis Min                             -3.38361\n",
      "Policy mu Mean                           0.0574588\n",
      "Policy mu Std                            0.125371\n",
      "Policy mu Max                            0.423872\n",
      "Policy mu Min                           -0.162563\n",
      "Policy log std Mean                     -0.134992\n",
      "Policy log std Std                       0.0094719\n",
      "Policy log std Max                      -0.116\n",
      "Policy log std Min                      -0.190372\n",
      "Z mean eval                              0.00910037\n",
      "Z variance eval                          0.255158\n",
      "AverageTrainReturn_all_train_tasks      -0.0537097\n",
      "AverageReturn_all_train_tasks            0.138916\n",
      "AverageReturn_all_test_tasks            -0.0498483\n",
      "Number of train steps total          44500\n",
      "Number of env steps total           194000\n",
      "Number of rollouts total                 0\n",
      "Train Time (s)                          29.4699\n",
      "(Previous) Eval Time (s)                 5.13299\n",
      "Sample Time (s)                          3.02316\n",
      "Epoch Time (s)                          37.6261\n",
      "Total Train Time (s)                  3856.99\n",
      "Epoch                                   88\n",
      "----------------------------------  ---------------\n",
      "2020-06-11 15:14:13.132660 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #88 | Epoch Duration: 37.63892960548401\n",
      "2020-06-11 15:14:13.132660 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #88 | Started Training: True\n",
      "----------------------------------  ---------------\n",
      "Z mean train                             0.0088921\n",
      "Z variance train                         0.818537\n",
      "KL Divergence                            0.178781\n",
      "KL Loss                                  0.0178781\n",
      "QF Loss                                  0.145792\n",
      "VF Loss                                  0.0990766\n",
      "Policy Loss                           -170.429\n",
      "Q Predictions Mean                     168.425\n",
      "Q Predictions Std                        2.34068\n",
      "Q Predictions Max                      172.371\n",
      "Q Predictions Min                      155.61\n",
      "V Predictions Mean                     170.341\n",
      "V Predictions Std                        2.36299\n",
      "V Predictions Max                      174.474\n",
      "V Predictions Min                      156.702\n",
      "Log Pis Mean                            -2.0094\n",
      "Log Pis Std                              0.346278\n",
      "Log Pis Max                             -0.772999\n",
      "Log Pis Min                             -3.68931\n",
      "Policy mu Mean                           0.0669905\n",
      "Policy mu Std                            0.123049\n",
      "Policy mu Max                            0.434813\n",
      "Policy mu Min                           -0.150258\n",
      "Policy log std Mean                     -0.134956\n",
      "Policy log std Std                       0.00732538\n",
      "Policy log std Max                      -0.119843\n",
      "Policy log std Min                      -0.174444\n",
      "Z mean eval                              0.00922531\n",
      "Z variance eval                          0.301521\n",
      "AverageTrainReturn_all_train_tasks      -0.0510641\n",
      "AverageReturn_all_train_tasks           -0.0525535\n",
      "AverageReturn_all_test_tasks            -0.0468614\n",
      "Number of train steps total          45000\n",
      "Number of env steps total           196000\n",
      "Number of rollouts total                 0\n",
      "Train Time (s)                          29.2779\n",
      "(Previous) Eval Time (s)                 5.14594\n",
      "Sample Time (s)                          3.01032\n",
      "Epoch Time (s)                          37.4342\n",
      "Total Train Time (s)                  3894.61\n",
      "Epoch                                   89\n",
      "----------------------------------  ---------------\n",
      "2020-06-11 15:14:50.750017 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #89 | Epoch Duration: 37.61635708808899\n",
      "2020-06-11 15:14:50.751016 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #89 | Started Training: True\n",
      "----------------------------------  ----------------\n",
      "Z mean train                             0.00912592\n",
      "Z variance train                         0.981948\n",
      "KL Divergence                            0.00616516\n",
      "KL Loss                                  0.000616516\n",
      "QF Loss                                  0.220309\n",
      "VF Loss                                  0.52851\n",
      "Policy Loss                           -171.789\n",
      "Q Predictions Mean                     169.776\n",
      "Q Predictions Std                        2.50008\n",
      "Q Predictions Max                      173.669\n",
      "Q Predictions Min                      155.631\n",
      "V Predictions Mean                     172.435\n",
      "V Predictions Std                        2.51529\n",
      "V Predictions Max                      176.65\n",
      "V Predictions Min                      158.752\n",
      "Log Pis Mean                            -2.00419\n",
      "Log Pis Std                              0.358487\n",
      "Log Pis Max                             -0.757168\n",
      "Log Pis Min                             -3.63505\n",
      "Policy mu Mean                           0.0423462\n",
      "Policy mu Std                            0.140147\n",
      "Policy mu Max                            0.481116\n",
      "Policy mu Min                           -0.168628\n",
      "Policy log std Mean                     -0.132669\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy log std Std                       0.00885169\n",
      "Policy log std Max                      -0.115179\n",
      "Policy log std Min                      -0.186362\n",
      "Z mean eval                              0.0234628\n",
      "Z variance eval                          0.276521\n",
      "AverageTrainReturn_all_train_tasks      -0.0480716\n",
      "AverageReturn_all_train_tasks           -0.0481004\n",
      "AverageReturn_all_test_tasks             0.0361348\n",
      "Number of train steps total          45500\n",
      "Number of env steps total           198000\n",
      "Number of rollouts total                 0\n",
      "Train Time (s)                          29.3757\n",
      "(Previous) Eval Time (s)                 5.3275\n",
      "Sample Time (s)                          3.11013\n",
      "Epoch Time (s)                          37.8134\n",
      "Total Train Time (s)                  3932.32\n",
      "Epoch                                   90\n",
      "----------------------------------  ----------------\n",
      "2020-06-11 15:15:28.468345 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #90 | Epoch Duration: 37.7163290977478\n",
      "2020-06-11 15:15:28.470346 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #90 | Started Training: True\n",
      "----------------------------------  ---------------\n",
      "Z mean train                             0.0255818\n",
      "Z variance train                         0.916406\n",
      "KL Divergence                            0.037005\n",
      "KL Loss                                  0.0037005\n",
      "QF Loss                                  0.194867\n",
      "VF Loss                                  0.316696\n",
      "Policy Loss                           -172.272\n",
      "Q Predictions Mean                     170.357\n",
      "Q Predictions Std                        2.1798\n",
      "Q Predictions Max                      174.952\n",
      "Q Predictions Min                      155.811\n",
      "V Predictions Mean                     172.73\n",
      "V Predictions Std                        2.19037\n",
      "V Predictions Max                      177.17\n",
      "V Predictions Min                      158.387\n",
      "Log Pis Mean                            -2.02123\n",
      "Log Pis Std                              0.332873\n",
      "Log Pis Max                             -0.673624\n",
      "Log Pis Min                             -4.75947\n",
      "Policy mu Mean                           0.0606925\n",
      "Policy mu Std                            0.127961\n",
      "Policy mu Max                            0.46175\n",
      "Policy mu Min                           -0.165285\n",
      "Policy log std Mean                     -0.133165\n",
      "Policy log std Std                       0.00794145\n",
      "Policy log std Max                      -0.119432\n",
      "Policy log std Min                      -0.179919\n",
      "Z mean eval                              0.020797\n",
      "Z variance eval                          0.21857\n",
      "AverageTrainReturn_all_train_tasks      -0.0496427\n",
      "AverageReturn_all_train_tasks           -0.0487204\n",
      "AverageReturn_all_test_tasks            -0.0501939\n",
      "Number of train steps total          46000\n",
      "Number of env steps total           200000\n",
      "Number of rollouts total                 0\n",
      "Train Time (s)                          29.799\n",
      "(Previous) Eval Time (s)                 5.2307\n",
      "Sample Time (s)                          3.00782\n",
      "Epoch Time (s)                          38.0375\n",
      "Total Train Time (s)                  3970.63\n",
      "Epoch                                   91\n",
      "----------------------------------  ---------------\n",
      "2020-06-11 15:16:06.776800 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #91 | Epoch Duration: 38.304458141326904\n",
      "2020-06-11 15:16:06.777800 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #91 | Started Training: True\n",
      "----------------------------------  ---------------\n",
      "Z mean train                             0.0218\n",
      "Z variance train                         0.7155\n",
      "KL Divergence                            0.524855\n",
      "KL Loss                                  0.0524855\n",
      "QF Loss                                  1.21964\n",
      "VF Loss                                  0.0923343\n",
      "Policy Loss                           -172.692\n",
      "Q Predictions Mean                     171.69\n",
      "Q Predictions Std                        2.23293\n",
      "Q Predictions Max                      175.308\n",
      "Q Predictions Min                      159.171\n",
      "V Predictions Mean                     172.792\n",
      "V Predictions Std                        2.26113\n",
      "V Predictions Max                      176.793\n",
      "V Predictions Min                      161.344\n",
      "Log Pis Mean                            -2.01486\n",
      "Log Pis Std                              0.364292\n",
      "Log Pis Max                             -0.819065\n",
      "Log Pis Min                             -5.26145\n",
      "Policy mu Mean                           0.0616991\n",
      "Policy mu Std                            0.130979\n",
      "Policy mu Max                            0.464824\n",
      "Policy mu Min                           -0.159257\n",
      "Policy log std Mean                     -0.133934\n",
      "Policy log std Std                       0.00776556\n",
      "Policy log std Max                      -0.119178\n",
      "Policy log std Min                      -0.185672\n",
      "Z mean eval                              0.0337435\n",
      "Z variance eval                          0.194195\n",
      "AverageTrainReturn_all_train_tasks      -0.0492594\n",
      "AverageReturn_all_train_tasks           -0.0497758\n",
      "AverageReturn_all_test_tasks            -0.0506561\n",
      "Number of train steps total          46500\n",
      "Number of env steps total           202000\n",
      "Number of rollouts total                 0\n",
      "Train Time (s)                          29.4448\n",
      "(Previous) Eval Time (s)                 5.49773\n",
      "Sample Time (s)                          3.11773\n",
      "Epoch Time (s)                          38.0602\n",
      "Total Train Time (s)                  4009.35\n",
      "Epoch                                   92\n",
      "----------------------------------  ---------------\n",
      "2020-06-11 15:16:45.499507 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #92 | Epoch Duration: 38.720707178115845\n",
      "2020-06-11 15:16:45.500506 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #92 | Started Training: True\n",
      "----------------------------------  ---------------\n",
      "Z mean train                             0.0360512\n",
      "Z variance train                         0.647599\n",
      "KL Divergence                            0.907489\n",
      "KL Loss                                  0.0907489\n",
      "QF Loss                                  0.63764\n",
      "VF Loss                                  3.77784\n",
      "Policy Loss                           -173.098\n",
      "Q Predictions Mean                     170.84\n",
      "Q Predictions Std                        2.24176\n",
      "Q Predictions Max                      174.452\n",
      "Q Predictions Min                      158.692\n",
      "V Predictions Mean                     171.318\n",
      "V Predictions Std                        2.23997\n",
      "V Predictions Max                      175.501\n",
      "V Predictions Min                      160.352\n",
      "Log Pis Mean                            -2.02659\n",
      "Log Pis Std                              0.367138\n",
      "Log Pis Max                             -0.799764\n",
      "Log Pis Min                             -3.93318\n",
      "Policy mu Mean                           0.0544897\n",
      "Policy mu Std                            0.136375\n",
      "Policy mu Max                            0.472288\n",
      "Policy mu Min                           -0.167978\n",
      "Policy log std Mean                     -0.133328\n",
      "Policy log std Std                       0.00716631\n",
      "Policy log std Max                      -0.120662\n",
      "Policy log std Min                      -0.177066\n",
      "Z mean eval                              0.0259528\n",
      "Z variance eval                          0.161159\n",
      "AverageTrainReturn_all_train_tasks      -0.0484719\n",
      "AverageReturn_all_train_tasks           -0.0475384\n",
      "AverageReturn_all_test_tasks            -0.0472955\n",
      "Number of train steps total          47000\n",
      "Number of env steps total           204000\n",
      "Number of rollouts total                 0\n",
      "Train Time (s)                          29.9844\n",
      "(Previous) Eval Time (s)                 6.15826\n",
      "Sample Time (s)                          3.028\n",
      "Epoch Time (s)                          39.1707\n",
      "Total Train Time (s)                  4047.64\n",
      "Epoch                                   93\n",
      "----------------------------------  ---------------\n",
      "2020-06-11 15:17:23.788464 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #93 | Epoch Duration: 38.28595805168152\n",
      "2020-06-11 15:17:23.789464 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #93 | Started Training: True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------  ---------------\n",
      "Z mean train                             0.0276164\n",
      "Z variance train                         0.531502\n",
      "KL Divergence                            1.65394\n",
      "KL Loss                                  0.165394\n",
      "QF Loss                                  0.155225\n",
      "VF Loss                                  0.0930382\n",
      "Policy Loss                           -173.124\n",
      "Q Predictions Mean                     171.38\n",
      "Q Predictions Std                        2.44915\n",
      "Q Predictions Max                      175.567\n",
      "Q Predictions Min                      157.694\n",
      "V Predictions Mean                     173.07\n",
      "V Predictions Std                        2.4748\n",
      "V Predictions Max                      177.411\n",
      "V Predictions Min                      160.364\n",
      "Log Pis Mean                            -2.00976\n",
      "Log Pis Std                              0.328608\n",
      "Log Pis Max                             -0.616345\n",
      "Log Pis Min                             -3.39264\n",
      "Policy mu Mean                           0.0583489\n",
      "Policy mu Std                            0.130905\n",
      "Policy mu Max                            0.476896\n",
      "Policy mu Min                           -0.161394\n",
      "Policy log std Mean                     -0.13634\n",
      "Policy log std Std                       0.00849853\n",
      "Policy log std Max                      -0.125018\n",
      "Policy log std Min                      -0.189289\n",
      "Z mean eval                              0.0201114\n",
      "Z variance eval                          0.26029\n",
      "AverageTrainReturn_all_train_tasks      -0.0498089\n",
      "AverageReturn_all_train_tasks           -0.0475291\n",
      "AverageReturn_all_test_tasks            -0.0510693\n",
      "Number of train steps total          47500\n",
      "Number of env steps total           206000\n",
      "Number of rollouts total                 0\n",
      "Train Time (s)                          29.1513\n",
      "(Previous) Eval Time (s)                 5.27288\n",
      "Sample Time (s)                          3.04933\n",
      "Epoch Time (s)                          37.4735\n",
      "Total Train Time (s)                  4085.05\n",
      "Epoch                                   94\n",
      "----------------------------------  ---------------\n",
      "2020-06-11 15:18:01.203292 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #94 | Epoch Duration: 37.41282939910889\n",
      "2020-06-11 15:18:01.207291 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #94 | Started Training: True\n",
      "----------------------------------  ---------------\n",
      "Z mean train                             0.0222643\n",
      "Z variance train                         0.898227\n",
      "KL Divergence                            0.0707416\n",
      "KL Loss                                  0.00707416\n",
      "QF Loss                                  0.249964\n",
      "VF Loss                                  0.332954\n",
      "Policy Loss                           -173.901\n",
      "Q Predictions Mean                     171.806\n",
      "Q Predictions Std                        2.16089\n",
      "Q Predictions Max                      175.212\n",
      "Q Predictions Min                      161.653\n",
      "V Predictions Mean                     173.891\n",
      "V Predictions Std                        2.13077\n",
      "V Predictions Max                      178.056\n",
      "V Predictions Min                      163.771\n",
      "Log Pis Mean                            -2.01199\n",
      "Log Pis Std                              0.350324\n",
      "Log Pis Max                             -0.711066\n",
      "Log Pis Min                             -4.4261\n",
      "Policy mu Mean                           0.0495928\n",
      "Policy mu Std                            0.130242\n",
      "Policy mu Max                            0.446939\n",
      "Policy mu Min                           -0.16855\n",
      "Policy log std Mean                     -0.133088\n",
      "Policy log std Std                       0.00695466\n",
      "Policy log std Max                      -0.11987\n",
      "Policy log std Min                      -0.175153\n",
      "Z mean eval                              0.0210875\n",
      "Z variance eval                          0.198143\n",
      "AverageTrainReturn_all_train_tasks      -0.0517999\n",
      "AverageReturn_all_train_tasks           -0.0489048\n",
      "AverageReturn_all_test_tasks             0.0498879\n",
      "Number of train steps total          48000\n",
      "Number of env steps total           208000\n",
      "Number of rollouts total                 0\n",
      "Train Time (s)                          29.155\n",
      "(Previous) Eval Time (s)                 5.21229\n",
      "Sample Time (s)                          3.01992\n",
      "Epoch Time (s)                          37.3872\n",
      "Total Train Time (s)                  4122.47\n",
      "Epoch                                   95\n",
      "----------------------------------  ---------------\n",
      "2020-06-11 15:18:38.627792 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #95 | Epoch Duration: 37.41850304603577\n",
      "2020-06-11 15:18:38.628791 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #95 | Started Training: True\n",
      "----------------------------------  ---------------\n",
      "Z mean train                             0.025374\n",
      "Z variance train                         0.671862\n",
      "KL Divergence                            0.747282\n",
      "KL Loss                                  0.0747282\n",
      "QF Loss                                  0.172421\n",
      "VF Loss                                  0.247275\n",
      "Policy Loss                           -173.669\n",
      "Q Predictions Mean                     171.854\n",
      "Q Predictions Std                        2.32716\n",
      "Q Predictions Max                      175.69\n",
      "Q Predictions Min                      160.159\n",
      "V Predictions Mean                     173.926\n",
      "V Predictions Std                        2.35991\n",
      "V Predictions Max                      178.058\n",
      "V Predictions Min                      162.335\n",
      "Log Pis Mean                            -2.01816\n",
      "Log Pis Std                              0.388829\n",
      "Log Pis Max                             -0.650796\n",
      "Log Pis Min                             -6.03101\n",
      "Policy mu Mean                           0.0672964\n",
      "Policy mu Std                            0.129255\n",
      "Policy mu Max                            0.48781\n",
      "Policy mu Min                           -0.160819\n",
      "Policy log std Mean                     -0.135121\n",
      "Policy log std Std                       0.00899612\n",
      "Policy log std Max                      -0.121324\n",
      "Policy log std Min                      -0.194961\n",
      "Z mean eval                              0.0101385\n",
      "Z variance eval                          0.238792\n",
      "AverageTrainReturn_all_train_tasks       1.00244\n",
      "AverageReturn_all_train_tasks           -0.049788\n",
      "AverageReturn_all_test_tasks            -0.0493919\n",
      "Number of train steps total          48500\n",
      "Number of env steps total           210000\n",
      "Number of rollouts total                 0\n",
      "Train Time (s)                          29.297\n",
      "(Previous) Eval Time (s)                 5.24343\n",
      "Sample Time (s)                          2.96489\n",
      "Epoch Time (s)                          37.5053\n",
      "Total Train Time (s)                  4160.02\n",
      "Epoch                                   96\n",
      "----------------------------------  ---------------\n",
      "2020-06-11 15:19:16.167829 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #96 | Epoch Duration: 37.53703832626343\n",
      "2020-06-11 15:19:16.168828 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #96 | Started Training: True\n",
      "----------------------------------  ---------------\n",
      "Z mean train                             0.0111945\n",
      "Z variance train                         0.77239\n",
      "KL Divergence                            0.307842\n",
      "KL Loss                                  0.0307842\n",
      "QF Loss                                  0.213698\n",
      "VF Loss                                  0.12095\n",
      "Policy Loss                           -174.19\n",
      "Q Predictions Mean                     172.256\n",
      "Q Predictions Std                        2.54058\n",
      "Q Predictions Max                      176.628\n",
      "Q Predictions Min                      159.943\n",
      "V Predictions Mean                     174.361\n",
      "V Predictions Std                        2.56308\n",
      "V Predictions Max                      179.175\n",
      "V Predictions Min                      161.737\n",
      "Log Pis Mean                            -2.00844\n",
      "Log Pis Std                              0.341071\n",
      "Log Pis Max                             -0.709332\n",
      "Log Pis Min                             -3.55091\n",
      "Policy mu Mean                           0.0594311\n",
      "Policy mu Std                            0.131277\n",
      "Policy mu Max                            0.464697\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy mu Min                           -0.163214\n",
      "Policy log std Mean                     -0.133595\n",
      "Policy log std Std                       0.00715426\n",
      "Policy log std Max                      -0.119323\n",
      "Policy log std Min                      -0.173621\n",
      "Z mean eval                              0.0286764\n",
      "Z variance eval                          0.18948\n",
      "AverageTrainReturn_all_train_tasks      -0.0517069\n",
      "AverageReturn_all_train_tasks            0.62526\n",
      "AverageReturn_all_test_tasks            -0.0477973\n",
      "Number of train steps total          49000\n",
      "Number of env steps total           212000\n",
      "Number of rollouts total                 0\n",
      "Train Time (s)                          29.1478\n",
      "(Previous) Eval Time (s)                 5.27482\n",
      "Sample Time (s)                          3.09655\n",
      "Epoch Time (s)                          37.5192\n",
      "Total Train Time (s)                  4197.4\n",
      "Epoch                                   97\n",
      "----------------------------------  ---------------\n",
      "2020-06-11 15:19:53.553305 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #97 | Epoch Duration: 37.38347816467285\n",
      "2020-06-11 15:19:53.554305 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #97 | Started Training: True\n",
      "----------------------------------  ---------------\n",
      "Z mean train                             0.0293784\n",
      "Z variance train                         0.60852\n",
      "KL Divergence                            1.04471\n",
      "KL Loss                                  0.104471\n",
      "QF Loss                                  0.163499\n",
      "VF Loss                                  0.0485749\n",
      "Policy Loss                           -174.305\n",
      "Q Predictions Mean                     172.261\n",
      "Q Predictions Std                        2.40194\n",
      "Q Predictions Max                      176.04\n",
      "Q Predictions Min                      155.68\n",
      "V Predictions Mean                     174.249\n",
      "V Predictions Std                        2.42207\n",
      "V Predictions Max                      177.87\n",
      "V Predictions Min                      158.008\n",
      "Log Pis Mean                            -1.97867\n",
      "Log Pis Std                              0.369108\n",
      "Log Pis Max                             -0.48038\n",
      "Log Pis Min                             -3.57983\n",
      "Policy mu Mean                           0.0685623\n",
      "Policy mu Std                            0.138845\n",
      "Policy mu Max                            0.465278\n",
      "Policy mu Min                           -0.175291\n",
      "Policy log std Mean                     -0.132462\n",
      "Policy log std Std                       0.00899518\n",
      "Policy log std Max                      -0.116376\n",
      "Policy log std Min                      -0.187792\n",
      "Z mean eval                              0.00573763\n",
      "Z variance eval                          0.286455\n",
      "AverageTrainReturn_all_train_tasks      -0.0470854\n",
      "AverageReturn_all_train_tasks           -0.0479461\n",
      "AverageReturn_all_test_tasks            -0.0480998\n",
      "Number of train steps total          49500\n",
      "Number of env steps total           214000\n",
      "Number of rollouts total                 0\n",
      "Train Time (s)                          31.4314\n",
      "(Previous) Eval Time (s)                 5.13954\n",
      "Sample Time (s)                          2.97085\n",
      "Epoch Time (s)                          39.5418\n",
      "Total Train Time (s)                  4248.8\n",
      "Epoch                                   98\n",
      "----------------------------------  ---------------\n",
      "2020-06-11 15:20:45.005684 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #98 | Epoch Duration: 51.450379610061646\n",
      "2020-06-11 15:20:45.007683 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #98 | Started Training: True\n",
      "----------------------------------  ---------------\n",
      "Z mean train                             0.0056149\n",
      "Z variance train                         0.967724\n",
      "KL Divergence                            0.0104378\n",
      "KL Loss                                  0.00104378\n",
      "QF Loss                                  0.102937\n",
      "VF Loss                                  0.0833823\n",
      "Policy Loss                           -174.55\n",
      "Q Predictions Mean                     172.577\n",
      "Q Predictions Std                        2.47456\n",
      "Q Predictions Max                      176.142\n",
      "Q Predictions Min                      158.715\n",
      "V Predictions Mean                     174.627\n",
      "V Predictions Std                        2.51614\n",
      "V Predictions Max                      178.325\n",
      "V Predictions Min                      159.573\n",
      "Log Pis Mean                            -1.9975\n",
      "Log Pis Std                              0.337704\n",
      "Log Pis Max                             -0.794569\n",
      "Log Pis Min                             -3.92842\n",
      "Policy mu Mean                           0.0564406\n",
      "Policy mu Std                            0.129459\n",
      "Policy mu Max                            0.448447\n",
      "Policy mu Min                           -0.16132\n",
      "Policy log std Mean                     -0.135888\n",
      "Policy log std Std                       0.00933558\n",
      "Policy log std Max                      -0.123361\n",
      "Policy log std Min                      -0.197483\n",
      "Z mean eval                              0.0102483\n",
      "Z variance eval                          0.227198\n",
      "AverageTrainReturn_all_train_tasks      -0.0486217\n",
      "AverageReturn_all_train_tasks           -0.0519283\n",
      "AverageReturn_all_test_tasks            -0.0510723\n",
      "Number of train steps total          50000\n",
      "Number of env steps total           216000\n",
      "Number of rollouts total                 0\n",
      "Train Time (s)                          38.6396\n",
      "(Previous) Eval Time (s)                17.048\n",
      "Sample Time (s)                          5.62633\n",
      "Epoch Time (s)                          61.3139\n",
      "Total Train Time (s)                  4298.7\n",
      "Epoch                                   99\n",
      "----------------------------------  ---------------\n",
      "2020-06-11 15:21:34.862910 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #99 | Epoch Duration: 49.85322856903076\n",
      "2020-06-11 15:21:34.865908 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #99 | Started Training: True\n",
      "----------------------------------  ---------------\n",
      "Z mean train                             0.0103233\n",
      "Z variance train                         0.732656\n",
      "KL Divergence                            0.436572\n",
      "KL Loss                                  0.0436572\n",
      "QF Loss                                  0.433504\n",
      "VF Loss                                  0.300255\n",
      "Policy Loss                           -175.496\n",
      "Q Predictions Mean                     173.73\n",
      "Q Predictions Std                        2.39424\n",
      "Q Predictions Max                      177.776\n",
      "Q Predictions Min                      160.403\n",
      "V Predictions Mean                     175.879\n",
      "V Predictions Std                        2.39168\n",
      "V Predictions Max                      179.647\n",
      "V Predictions Min                      161.979\n",
      "Log Pis Mean                            -1.9961\n",
      "Log Pis Std                              0.337325\n",
      "Log Pis Max                             -0.662255\n",
      "Log Pis Min                             -3.3387\n",
      "Policy mu Mean                           0.0488834\n",
      "Policy mu Std                            0.139787\n",
      "Policy mu Max                            0.470627\n",
      "Policy mu Min                           -0.196502\n",
      "Policy log std Mean                     -0.133753\n",
      "Policy log std Std                       0.00909173\n",
      "Policy log std Max                      -0.117116\n",
      "Policy log std Min                      -0.193515\n",
      "Z mean eval                              0.0137894\n",
      "Z variance eval                          0.254467\n",
      "AverageTrainReturn_all_train_tasks      -0.0486734\n",
      "AverageReturn_all_train_tasks           -0.0467646\n",
      "AverageReturn_all_test_tasks            -0.0490889\n",
      "Number of train steps total          50500\n",
      "Number of env steps total           218000\n",
      "Number of rollouts total                 0\n",
      "Train Time (s)                          31.2247\n",
      "(Previous) Eval Time (s)                 5.58682\n",
      "Sample Time (s)                          3.27011\n",
      "Epoch Time (s)                          40.0816\n",
      "Total Train Time (s)                  4338.89\n",
      "Epoch                                  100\n",
      "----------------------------------  ---------------\n",
      "2020-06-11 15:22:15.049838 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #100 | Epoch Duration: 40.181931018829346\n",
      "2020-06-11 15:22:15.050838 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #100 | Started Training: True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " MADE IT 1 TIMES TO GOAL \n",
      "\n",
      "----------------------------------  ---------------\n",
      "Z mean train                             0.0132613\n",
      "Z variance train                         0.811475\n",
      "KL Divergence                            0.175225\n",
      "KL Loss                                  0.0175225\n",
      "QF Loss                                  0.210375\n",
      "VF Loss                                  0.204893\n",
      "Policy Loss                           -175.381\n",
      "Q Predictions Mean                     173.563\n",
      "Q Predictions Std                        2.57783\n",
      "Q Predictions Max                      178.517\n",
      "Q Predictions Min                      157.066\n",
      "V Predictions Mean                     175.378\n",
      "V Predictions Std                        2.48171\n",
      "V Predictions Max                      179.365\n",
      "V Predictions Min                      157.921\n",
      "Log Pis Mean                            -2.03496\n",
      "Log Pis Std                              0.370298\n",
      "Log Pis Max                             -0.815955\n",
      "Log Pis Min                             -4.54874\n",
      "Policy mu Mean                           0.0537599\n",
      "Policy mu Std                            0.132245\n",
      "Policy mu Max                            0.457882\n",
      "Policy mu Min                           -0.184347\n",
      "Policy log std Mean                     -0.132991\n",
      "Policy log std Std                       0.00969\n",
      "Policy log std Max                      -0.119196\n",
      "Policy log std Min                      -0.195279\n",
      "Z mean eval                              0.00412364\n",
      "Z variance eval                          0.262548\n",
      "AverageTrainReturn_all_train_tasks      -0.051858\n",
      "AverageReturn_all_train_tasks            2.4272\n",
      "AverageReturn_all_test_tasks            -0.0491198\n",
      "Number of train steps total          51000\n",
      "Number of env steps total           220067\n",
      "Number of rollouts total                 0\n",
      "Train Time (s)                          35.3553\n",
      "(Previous) Eval Time (s)                 5.68724\n",
      "Sample Time (s)                          3.47801\n",
      "Epoch Time (s)                          44.5205\n",
      "Total Train Time (s)                  4383.59\n",
      "Epoch                                  101\n",
      "----------------------------------  ---------------\n",
      "2020-06-11 15:22:59.762837 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #101 | Epoch Duration: 44.71100091934204\n",
      "2020-06-11 15:22:59.763837 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #101 | Started Training: True\n",
      "----------------------------------  ---------------\n",
      "Z mean train                             0.00433177\n",
      "Z variance train                         0.882099\n",
      "KL Divergence                            0.109771\n",
      "KL Loss                                  0.0109771\n",
      "QF Loss                                  0.291164\n",
      "VF Loss                                  1.14596\n",
      "Policy Loss                           -176.123\n",
      "Q Predictions Mean                     174.166\n",
      "Q Predictions Std                        2.64776\n",
      "Q Predictions Max                      177.937\n",
      "Q Predictions Min                      153.175\n",
      "V Predictions Mean                     175.086\n",
      "V Predictions Std                        2.61251\n",
      "V Predictions Max                      178.746\n",
      "V Predictions Min                      153.546\n",
      "Log Pis Mean                            -1.9928\n",
      "Log Pis Std                              0.35341\n",
      "Log Pis Max                             -0.435529\n",
      "Log Pis Min                             -4.12525\n",
      "Policy mu Mean                           0.0471565\n",
      "Policy mu Std                            0.145896\n",
      "Policy mu Max                            0.475872\n",
      "Policy mu Min                           -0.155427\n",
      "Policy log std Mean                     -0.133508\n",
      "Policy log std Std                       0.0102433\n",
      "Policy log std Max                      -0.118246\n",
      "Policy log std Min                      -0.180582\n",
      "Z mean eval                              0.105092\n",
      "Z variance eval                          0.0937118\n",
      "AverageTrainReturn_all_train_tasks      -0.0490764\n",
      "AverageReturn_all_train_tasks           -0.0472369\n",
      "AverageReturn_all_test_tasks             0.0756389\n",
      "Number of train steps total          51500\n",
      "Number of env steps total           222067\n",
      "Number of rollouts total                 0\n",
      "Train Time (s)                          33.6171\n",
      "(Previous) Eval Time (s)                 5.87831\n",
      "Sample Time (s)                          4.26945\n",
      "Epoch Time (s)                          43.7649\n",
      "Total Train Time (s)                  4429.76\n",
      "Epoch                                  102\n",
      "----------------------------------  ---------------\n",
      "2020-06-11 15:23:45.944369 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #102 | Epoch Duration: 46.17953276634216\n",
      "2020-06-11 15:23:45.945371 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #102 | Started Training: True\n",
      "----------------------------------  ---------------\n",
      "Z mean train                             0.116234\n",
      "Z variance train                         0.311035\n",
      "KL Divergence                            5.02607\n",
      "KL Loss                                  0.502607\n",
      "QF Loss                                  0.831752\n",
      "VF Loss                                 16.3024\n",
      "Policy Loss                           -175.169\n",
      "Q Predictions Mean                     174.015\n",
      "Q Predictions Std                        2.37074\n",
      "Q Predictions Max                      177.97\n",
      "Q Predictions Min                      160.936\n",
      "V Predictions Mean                     178.857\n",
      "V Predictions Std                        2.64309\n",
      "V Predictions Max                      183.678\n",
      "V Predictions Min                      164.044\n",
      "Log Pis Mean                            -2.0147\n",
      "Log Pis Std                              0.379732\n",
      "Log Pis Max                             -0.584836\n",
      "Log Pis Min                             -4.9052\n",
      "Policy mu Mean                           0.0579992\n",
      "Policy mu Std                            0.133046\n",
      "Policy mu Max                            0.452143\n",
      "Policy mu Min                           -0.165729\n",
      "Policy log std Mean                     -0.133822\n",
      "Policy log std Std                       0.00854968\n",
      "Policy log std Max                      -0.118517\n",
      "Policy log std Min                      -0.18162\n",
      "Z mean eval                              0.0134949\n",
      "Z variance eval                          0.321405\n",
      "AverageTrainReturn_all_train_tasks      -0.0486365\n",
      "AverageReturn_all_train_tasks           -0.0491937\n",
      "AverageReturn_all_test_tasks            -0.0514201\n",
      "Number of train steps total          52000\n",
      "Number of env steps total           224067\n",
      "Number of rollouts total                 0\n",
      "Train Time (s)                          31.2383\n",
      "(Previous) Eval Time (s)                 8.29228\n",
      "Sample Time (s)                          3.29152\n",
      "Epoch Time (s)                          42.8221\n",
      "Total Train Time (s)                  4470.27\n",
      "Epoch                                  103\n",
      "----------------------------------  ---------------\n",
      "2020-06-11 15:24:26.437716 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #103 | Epoch Duration: 40.491347312927246\n",
      "2020-06-11 15:24:26.439715 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #103 | Started Training: True\n",
      "----------------------------------  ---------------\n",
      "Z mean train                             0.0160588\n",
      "Z variance train                         0.961839\n",
      "KL Divergence                            0.0132152\n",
      "KL Loss                                  0.00132152\n",
      "QF Loss                                  0.107679\n",
      "VF Loss                                  0.056637\n",
      "Policy Loss                           -177.093\n",
      "Q Predictions Mean                     175.062\n",
      "Q Predictions Std                        2.18332\n",
      "Q Predictions Max                      178.624\n",
      "Q Predictions Min                      163.437\n",
      "V Predictions Mean                     177.227\n",
      "V Predictions Std                        2.19138\n",
      "V Predictions Max                      180.726\n",
      "V Predictions Min                      165.994\n",
      "Log Pis Mean                            -2.00776\n",
      "Log Pis Std                              0.349594\n",
      "Log Pis Max                             -0.642007\n",
      "Log Pis Min                             -3.30361\n",
      "Policy mu Mean                           0.0612314\n",
      "Policy mu Std                            0.141424\n",
      "Policy mu Max                            0.465404\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy mu Min                           -0.154928\n",
      "Policy log std Mean                     -0.1341\n",
      "Policy log std Std                       0.00903839\n",
      "Policy log std Max                      -0.119804\n",
      "Policy log std Min                      -0.189786\n",
      "Z mean eval                              0.0127561\n",
      "Z variance eval                          0.303988\n",
      "AverageTrainReturn_all_train_tasks      -0.0483035\n",
      "AverageReturn_all_train_tasks           -0.048816\n",
      "AverageReturn_all_test_tasks            -0.0493552\n",
      "Number of train steps total          52500\n",
      "Number of env steps total           226067\n",
      "Number of rollouts total                 0\n",
      "Train Time (s)                          34.4945\n",
      "(Previous) Eval Time (s)                 5.96221\n",
      "Sample Time (s)                          3.24121\n",
      "Epoch Time (s)                          43.6979\n",
      "Total Train Time (s)                  4514.48\n",
      "Epoch                                  104\n",
      "----------------------------------  ---------------\n",
      "2020-06-11 15:25:10.654477 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #104 | Epoch Duration: 44.21376180648804\n",
      "2020-06-11 15:25:10.655477 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #104 | Started Training: True\n",
      "----------------------------------  ---------------\n",
      "Z mean train                             0.0129931\n",
      "Z variance train                         0.940994\n",
      "KL Divergence                            0.0229127\n",
      "KL Loss                                  0.00229127\n",
      "QF Loss                                  0.15708\n",
      "VF Loss                                  0.0846801\n",
      "Policy Loss                           -176.528\n",
      "Q Predictions Mean                     174.528\n",
      "Q Predictions Std                        2.45128\n",
      "Q Predictions Max                      178.545\n",
      "Q Predictions Min                      162.143\n",
      "V Predictions Mean                     176.47\n",
      "V Predictions Std                        2.48218\n",
      "V Predictions Max                      180.564\n",
      "V Predictions Min                      163.789\n",
      "Log Pis Mean                            -2.02839\n",
      "Log Pis Std                              0.361572\n",
      "Log Pis Max                             -0.634109\n",
      "Log Pis Min                             -4.59677\n",
      "Policy mu Mean                           0.0574073\n",
      "Policy mu Std                            0.129692\n",
      "Policy mu Max                            0.466722\n",
      "Policy mu Min                           -0.171587\n",
      "Policy log std Mean                     -0.130651\n",
      "Policy log std Std                       0.0100401\n",
      "Policy log std Max                      -0.114503\n",
      "Policy log std Min                      -0.190155\n",
      "Z mean eval                              0.0251454\n",
      "Z variance eval                          0.251198\n",
      "AverageTrainReturn_all_train_tasks      -0.0484425\n",
      "AverageReturn_all_train_tasks            0.349847\n",
      "AverageReturn_all_test_tasks             0.535858\n",
      "Number of train steps total          53000\n",
      "Number of env steps total           228067\n",
      "Number of rollouts total                 0\n",
      "Train Time (s)                          30.8701\n",
      "(Previous) Eval Time (s)                 6.47862\n",
      "Sample Time (s)                          3.29369\n",
      "Epoch Time (s)                          40.6424\n",
      "Total Train Time (s)                  4554.51\n",
      "Epoch                                  105\n",
      "----------------------------------  ---------------\n",
      "2020-06-11 15:25:50.677483 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #105 | Epoch Duration: 40.01900792121887\n",
      "2020-06-11 15:25:50.679482 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #105 | Started Training: True\n",
      "----------------------------------  ---------------\n",
      "Z mean train                             0.023656\n",
      "Z variance train                         0.764003\n",
      "KL Divergence                            0.322469\n",
      "KL Loss                                  0.0322469\n",
      "QF Loss                                  1.69154\n",
      "VF Loss                                  2.13486\n",
      "Policy Loss                           -175.829\n",
      "Q Predictions Mean                     174.04\n",
      "Q Predictions Std                        2.65507\n",
      "Q Predictions Max                      179.036\n",
      "Q Predictions Min                      160.454\n",
      "V Predictions Mean                     177.205\n",
      "V Predictions Std                        2.73526\n",
      "V Predictions Max                      181.693\n",
      "V Predictions Min                      162.745\n",
      "Log Pis Mean                            -2.00534\n",
      "Log Pis Std                              0.346262\n",
      "Log Pis Max                             -0.758063\n",
      "Log Pis Min                             -4.26538\n",
      "Policy mu Mean                           0.0509904\n",
      "Policy mu Std                            0.13035\n",
      "Policy mu Max                            0.459242\n",
      "Policy mu Min                           -0.163071\n",
      "Policy log std Mean                     -0.135084\n",
      "Policy log std Std                       0.00805711\n",
      "Policy log std Max                      -0.121269\n",
      "Policy log std Min                      -0.181618\n",
      "Z mean eval                              0.0339559\n",
      "Z variance eval                          0.274075\n",
      "AverageTrainReturn_all_train_tasks      -0.0463833\n",
      "AverageReturn_all_train_tasks            0.0737788\n",
      "AverageReturn_all_test_tasks            -0.0508754\n",
      "Number of train steps total          53500\n",
      "Number of env steps total           230067\n",
      "Number of rollouts total                 0\n",
      "Train Time (s)                          31.1569\n",
      "(Previous) Eval Time (s)                 5.8548\n",
      "Sample Time (s)                          3.18511\n",
      "Epoch Time (s)                          40.1969\n",
      "Total Train Time (s)                  4596.45\n",
      "Epoch                                  106\n",
      "----------------------------------  ---------------\n",
      "2020-06-11 15:26:32.630193 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #106 | Epoch Duration: 41.947712659835815\n",
      "2020-06-11 15:26:32.632191 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #106 | Started Training: True\n",
      "----------------------------------  ---------------\n",
      "Z mean train                             0.0329089\n",
      "Z variance train                         0.876514\n",
      "KL Divergence                            0.104914\n",
      "KL Loss                                  0.0104914\n",
      "QF Loss                                  0.222039\n",
      "VF Loss                                  0.0739479\n",
      "Policy Loss                           -177.892\n",
      "Q Predictions Mean                     175.864\n",
      "Q Predictions Std                        2.353\n",
      "Q Predictions Max                      179.97\n",
      "Q Predictions Min                      164.273\n",
      "V Predictions Mean                     177.747\n",
      "V Predictions Std                        2.27622\n",
      "V Predictions Max                      181.555\n",
      "V Predictions Min                      165.923\n",
      "Log Pis Mean                            -2.00272\n",
      "Log Pis Std                              0.35602\n",
      "Log Pis Max                             -0.548467\n",
      "Log Pis Min                             -3.50046\n",
      "Policy mu Mean                           0.0538273\n",
      "Policy mu Std                            0.141891\n",
      "Policy mu Max                            0.499497\n",
      "Policy mu Min                           -0.178158\n",
      "Policy log std Mean                     -0.135504\n",
      "Policy log std Std                       0.00814112\n",
      "Policy log std Max                      -0.123044\n",
      "Policy log std Min                      -0.18661\n",
      "Z mean eval                              0.0239411\n",
      "Z variance eval                          0.242072\n",
      "AverageTrainReturn_all_train_tasks      -0.0525859\n",
      "AverageReturn_all_train_tasks           -0.0498805\n",
      "AverageReturn_all_test_tasks            -0.0506061\n",
      "Number of train steps total          54000\n",
      "Number of env steps total           232067\n",
      "Number of rollouts total                 0\n",
      "Train Time (s)                          32.7384\n",
      "(Previous) Eval Time (s)                 7.60553\n",
      "Sample Time (s)                          3.43928\n",
      "Epoch Time (s)                          43.7832\n",
      "Total Train Time (s)                  4639.13\n",
      "Epoch                                  107\n",
      "----------------------------------  ---------------\n",
      "2020-06-11 15:27:15.312593 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #107 | Epoch Duration: 42.679402351379395\n",
      "2020-06-11 15:27:15.313593 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #107 | Started Training: True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------  ---------------\n",
      "Z mean train                             0.0241308\n",
      "Z variance train                         0.771051\n",
      "KL Divergence                            0.361995\n",
      "KL Loss                                  0.0361995\n",
      "QF Loss                                  0.405998\n",
      "VF Loss                                  0.808749\n",
      "Policy Loss                           -177.687\n",
      "Q Predictions Mean                     175.753\n",
      "Q Predictions Std                        2.55554\n",
      "Q Predictions Max                      180.795\n",
      "Q Predictions Min                      160.925\n",
      "V Predictions Mean                     178.48\n",
      "V Predictions Std                        2.6144\n",
      "V Predictions Max                      183.723\n",
      "V Predictions Min                      164.239\n",
      "Log Pis Mean                            -2.00284\n",
      "Log Pis Std                              0.357128\n",
      "Log Pis Max                             -0.786299\n",
      "Log Pis Min                             -3.98739\n",
      "Policy mu Mean                           0.0664207\n",
      "Policy mu Std                            0.137109\n",
      "Policy mu Max                            0.468461\n",
      "Policy mu Min                           -0.171159\n",
      "Policy log std Mean                     -0.134907\n",
      "Policy log std Std                       0.00954636\n",
      "Policy log std Max                      -0.121026\n",
      "Policy log std Min                      -0.189423\n",
      "Z mean eval                              0.0119116\n",
      "Z variance eval                          0.274222\n",
      "AverageTrainReturn_all_train_tasks      -0.0483036\n",
      "AverageReturn_all_train_tasks           -0.0481482\n",
      "AverageReturn_all_test_tasks            -0.0498536\n",
      "Number of train steps total          54500\n",
      "Number of env steps total           234067\n",
      "Number of rollouts total                 0\n",
      "Train Time (s)                          36.5591\n",
      "(Previous) Eval Time (s)                 6.5015\n",
      "Sample Time (s)                          3.29967\n",
      "Epoch Time (s)                          46.3603\n",
      "Total Train Time (s)                  4685.59\n",
      "Epoch                                  108\n",
      "----------------------------------  ---------------\n",
      "2020-06-11 15:28:01.764658 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #108 | Epoch Duration: 46.45006608963013\n",
      "2020-06-11 15:28:01.765658 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #108 | Started Training: True\n",
      "----------------------------------  ---------------\n",
      "Z mean train                             0.0100064\n",
      "Z variance train                         0.907785\n",
      "KL Divergence                            0.0567765\n",
      "KL Loss                                  0.00567765\n",
      "QF Loss                                  0.162664\n",
      "VF Loss                                  0.281139\n",
      "Policy Loss                           -178.903\n",
      "Q Predictions Mean                     176.849\n",
      "Q Predictions Std                        2.7026\n",
      "Q Predictions Max                      181.121\n",
      "Q Predictions Min                      161.425\n",
      "V Predictions Mean                     179.295\n",
      "V Predictions Std                        2.67802\n",
      "V Predictions Max                      183.05\n",
      "V Predictions Min                      163.5\n",
      "Log Pis Mean                            -2.0238\n",
      "Log Pis Std                              0.375944\n",
      "Log Pis Max                             -0.833405\n",
      "Log Pis Min                             -5.48921\n",
      "Policy mu Mean                           0.0423067\n",
      "Policy mu Std                            0.143232\n",
      "Policy mu Max                            0.480607\n",
      "Policy mu Min                           -0.186135\n",
      "Policy log std Mean                     -0.134969\n",
      "Policy log std Std                       0.00944388\n",
      "Policy log std Max                      -0.120022\n",
      "Policy log std Min                      -0.186009\n",
      "Z mean eval                              0.00700137\n",
      "Z variance eval                          0.288876\n",
      "AverageTrainReturn_all_train_tasks      -0.0491939\n",
      "AverageReturn_all_train_tasks           -0.0488609\n",
      "AverageReturn_all_test_tasks            -0.0478725\n",
      "Number of train steps total          55000\n",
      "Number of env steps total           236067\n",
      "Number of rollouts total                 0\n",
      "Train Time (s)                          34.0314\n",
      "(Previous) Eval Time (s)                 6.5915\n",
      "Sample Time (s)                          4.3207\n",
      "Epoch Time (s)                          44.9436\n",
      "Total Train Time (s)                  4729.77\n",
      "Epoch                                  109\n",
      "----------------------------------  ---------------\n",
      "2020-06-11 15:28:45.977521 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #109 | Epoch Duration: 44.21086311340332\n",
      "2020-06-11 15:28:45.978519 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #109 | Started Training: True\n",
      "----------------------------------  ---------------\n",
      "Z mean train                             0.00696945\n",
      "Z variance train                         0.920813\n",
      "KL Divergence                            0.0363904\n",
      "KL Loss                                  0.00363904\n",
      "QF Loss                                  0.180344\n",
      "VF Loss                                  0.107151\n",
      "Policy Loss                           -178.977\n",
      "Q Predictions Mean                     177.116\n",
      "Q Predictions Std                        2.69222\n",
      "Q Predictions Max                      181.226\n",
      "Q Predictions Min                      162.732\n",
      "V Predictions Mean                     178.74\n",
      "V Predictions Std                        2.72667\n",
      "V Predictions Max                      183.065\n",
      "V Predictions Min                      164.973\n",
      "Log Pis Mean                            -2.0034\n",
      "Log Pis Std                              0.339508\n",
      "Log Pis Max                             -0.817302\n",
      "Log Pis Min                             -3.49864\n",
      "Policy mu Mean                           0.0479993\n",
      "Policy mu Std                            0.13451\n",
      "Policy mu Max                            0.44255\n",
      "Policy mu Min                           -0.163746\n",
      "Policy log std Mean                     -0.136492\n",
      "Policy log std Std                       0.00873314\n",
      "Policy log std Max                      -0.124413\n",
      "Policy log std Min                      -0.186645\n",
      "Z mean eval                              0.00976625\n",
      "Z variance eval                          0.197174\n",
      "AverageTrainReturn_all_train_tasks      -0.0480636\n",
      "AverageReturn_all_train_tasks           -0.0494084\n",
      "AverageReturn_all_test_tasks            -0.0481972\n",
      "Number of train steps total          55500\n",
      "Number of env steps total           238067\n",
      "Number of rollouts total                 0\n",
      "Train Time (s)                          33.6763\n",
      "(Previous) Eval Time (s)                 5.85802\n",
      "Sample Time (s)                          3.71892\n",
      "Epoch Time (s)                          43.2533\n",
      "Total Train Time (s)                  4773.48\n",
      "Epoch                                  110\n",
      "----------------------------------  ---------------\n",
      "2020-06-11 15:29:29.660277 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #110 | Epoch Duration: 43.680757999420166\n",
      "2020-06-11 15:29:29.662275 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #110 | Started Training: True\n",
      "----------------------------------  --------------\n",
      "Z mean train                             0.0101286\n",
      "Z variance train                         0.629448\n",
      "KL Divergence                            0.929704\n",
      "KL Loss                                  0.0929704\n",
      "QF Loss                                  0.174242\n",
      "VF Loss                                  0.154739\n",
      "Policy Loss                           -179.035\n",
      "Q Predictions Mean                     177.113\n",
      "Q Predictions Std                        2.4657\n",
      "Q Predictions Max                      180.947\n",
      "Q Predictions Min                      166.666\n",
      "V Predictions Mean                     178.767\n",
      "V Predictions Std                        2.53804\n",
      "V Predictions Max                      182.709\n",
      "V Predictions Min                      169.483\n",
      "Log Pis Mean                            -1.99861\n",
      "Log Pis Std                              0.382859\n",
      "Log Pis Max                             -0.590001\n",
      "Log Pis Min                             -3.72371\n",
      "Policy mu Mean                           0.062072\n",
      "Policy mu Std                            0.141558\n",
      "Policy mu Max                            0.470512\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy mu Min                           -0.17\n",
      "Policy log std Mean                     -0.132706\n",
      "Policy log std Std                       0.0077805\n",
      "Policy log std Max                      -0.119056\n",
      "Policy log std Min                      -0.172414\n",
      "Z mean eval                              0.0159312\n",
      "Z variance eval                          0.195399\n",
      "AverageTrainReturn_all_train_tasks      -0.0556961\n",
      "AverageReturn_all_train_tasks            3.33877\n",
      "AverageReturn_all_test_tasks             3.55769\n",
      "Number of train steps total          56000\n",
      "Number of env steps total           240067\n",
      "Number of rollouts total                 0\n",
      "Train Time (s)                          33.1431\n",
      "(Previous) Eval Time (s)                 6.2845\n",
      "Sample Time (s)                          3.77045\n",
      "Epoch Time (s)                          43.1981\n",
      "Total Train Time (s)                  4816.31\n",
      "Epoch                                  111\n",
      "----------------------------------  --------------\n",
      "2020-06-11 15:30:12.486785 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #111 | Epoch Duration: 42.82351112365723\n",
      "2020-06-11 15:30:12.487784 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #111 | Started Training: True\n",
      "----------------------------------  ---------------\n",
      "Z mean train                             0.0166109\n",
      "Z variance train                         0.623324\n",
      "KL Divergence                            0.927189\n",
      "KL Loss                                  0.0927189\n",
      "QF Loss                                  0.178786\n",
      "VF Loss                                  0.0646455\n",
      "Policy Loss                           -178.849\n",
      "Q Predictions Mean                     176.817\n",
      "Q Predictions Std                        2.67307\n",
      "Q Predictions Max                      181.089\n",
      "Q Predictions Min                      159.494\n",
      "V Predictions Mean                     178.965\n",
      "V Predictions Std                        2.6782\n",
      "V Predictions Max                      183.092\n",
      "V Predictions Min                      161.835\n",
      "Log Pis Mean                            -2.0037\n",
      "Log Pis Std                              0.373304\n",
      "Log Pis Max                             -0.631322\n",
      "Log Pis Min                             -4.12743\n",
      "Policy mu Mean                           0.0594267\n",
      "Policy mu Std                            0.136897\n",
      "Policy mu Max                            0.481481\n",
      "Policy mu Min                           -0.183354\n",
      "Policy log std Mean                     -0.133805\n",
      "Policy log std Std                       0.00919956\n",
      "Policy log std Max                      -0.119329\n",
      "Policy log std Min                      -0.183915\n",
      "Z mean eval                              0.0063986\n",
      "Z variance eval                          0.288412\n",
      "AverageTrainReturn_all_train_tasks      -0.0532772\n",
      "AverageReturn_all_train_tasks           -0.0490335\n",
      "AverageReturn_all_test_tasks            -0.0498411\n",
      "Number of train steps total          56500\n",
      "Number of env steps total           242067\n",
      "Number of rollouts total                 0\n",
      "Train Time (s)                          36.8091\n",
      "(Previous) Eval Time (s)                 5.9099\n",
      "Sample Time (s)                          5.44211\n",
      "Epoch Time (s)                          48.1612\n",
      "Total Train Time (s)                  4864.4\n",
      "Epoch                                  112\n",
      "----------------------------------  ---------------\n",
      "2020-06-11 15:31:00.587121 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #112 | Epoch Duration: 48.09833765029907\n",
      "2020-06-11 15:31:00.590120 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #112 | Started Training: True\n",
      "----------------------------------  ---------------\n",
      "Z mean train                             0.00708577\n",
      "Z variance train                         0.900683\n",
      "KL Divergence                            0.0491464\n",
      "KL Loss                                  0.00491464\n",
      "QF Loss                                  0.576003\n",
      "VF Loss                                  0.522074\n",
      "Policy Loss                           -179.69\n",
      "Q Predictions Mean                     177.702\n",
      "Q Predictions Std                        2.47999\n",
      "Q Predictions Max                      181.436\n",
      "Q Predictions Min                      160.454\n",
      "V Predictions Mean                     179.253\n",
      "V Predictions Std                        2.51017\n",
      "V Predictions Max                      182.992\n",
      "V Predictions Min                      162.319\n",
      "Log Pis Mean                            -2.01209\n",
      "Log Pis Std                              0.377985\n",
      "Log Pis Max                             -0.608432\n",
      "Log Pis Min                             -4.31113\n",
      "Policy mu Mean                           0.0571722\n",
      "Policy mu Std                            0.145998\n",
      "Policy mu Max                            0.530808\n",
      "Policy mu Min                           -0.175213\n",
      "Policy log std Mean                     -0.137075\n",
      "Policy log std Std                       0.00894854\n",
      "Policy log std Max                      -0.122874\n",
      "Policy log std Min                      -0.195263\n",
      "Z mean eval                              0.012051\n",
      "Z variance eval                          0.274743\n",
      "AverageTrainReturn_all_train_tasks      -0.050663\n",
      "AverageReturn_all_train_tasks           -0.0501955\n",
      "AverageReturn_all_test_tasks            -0.0501031\n",
      "Number of train steps total          57000\n",
      "Number of env steps total           244067\n",
      "Number of rollouts total                 0\n",
      "Train Time (s)                          35.4597\n",
      "(Previous) Eval Time (s)                 5.84685\n",
      "Sample Time (s)                          3.91966\n",
      "Epoch Time (s)                          45.2262\n",
      "Total Train Time (s)                  4911.37\n",
      "Epoch                                  113\n",
      "----------------------------------  ---------------\n",
      "2020-06-11 15:31:47.557971 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #113 | Epoch Duration: 46.96585202217102\n",
      "2020-06-11 15:31:47.559970 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #113 | Started Training: True\n",
      "----------------------------------  ---------------\n",
      "Z mean train                             0.0129063\n",
      "Z variance train                         0.86129\n",
      "KL Divergence                            0.0959141\n",
      "KL Loss                                  0.00959141\n",
      "QF Loss                                  0.218122\n",
      "VF Loss                                  0.941456\n",
      "Policy Loss                           -179.7\n",
      "Q Predictions Mean                     177.897\n",
      "Q Predictions Std                        2.65853\n",
      "Q Predictions Max                      181.953\n",
      "Q Predictions Min                      164.359\n",
      "V Predictions Mean                     178.876\n",
      "V Predictions Std                        2.68218\n",
      "V Predictions Max                      183.22\n",
      "V Predictions Min                      164.742\n",
      "Log Pis Mean                            -2.00122\n",
      "Log Pis Std                              0.36334\n",
      "Log Pis Max                             -0.755543\n",
      "Log Pis Min                             -3.07096\n",
      "Policy mu Mean                           0.0504947\n",
      "Policy mu Std                            0.14899\n",
      "Policy mu Max                            0.497808\n",
      "Policy mu Min                           -0.175117\n",
      "Policy log std Mean                     -0.13384\n",
      "Policy log std Std                       0.00976213\n",
      "Policy log std Max                      -0.119342\n",
      "Policy log std Min                      -0.19292\n",
      "Z mean eval                              0.0237793\n",
      "Z variance eval                          0.271976\n",
      "AverageTrainReturn_all_train_tasks      -0.0487069\n",
      "AverageReturn_all_train_tasks            1.20181\n",
      "AverageReturn_all_test_tasks            -0.0489346\n",
      "Number of train steps total          57500\n",
      "Number of env steps total           246067\n",
      "Number of rollouts total                 0\n",
      "Train Time (s)                          35.836\n",
      "(Previous) Eval Time (s)                 7.58614\n",
      "Sample Time (s)                          3.65314\n",
      "Epoch Time (s)                          47.0753\n",
      "Total Train Time (s)                  4957.92\n",
      "Epoch                                  114\n",
      "----------------------------------  ---------------\n",
      "2020-06-11 15:32:34.109332 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #114 | Epoch Duration: 46.54836392402649\n",
      "2020-06-11 15:32:34.110332 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #114 | Started Training: True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------  ---------------\n",
      "Z mean train                             0.0255523\n",
      "Z variance train                         0.83448\n",
      "KL Divergence                            0.160265\n",
      "KL Loss                                  0.0160265\n",
      "QF Loss                                  0.566525\n",
      "VF Loss                                  0.179349\n",
      "Policy Loss                           -180.059\n",
      "Q Predictions Mean                     177.765\n",
      "Q Predictions Std                        2.37695\n",
      "Q Predictions Max                      183.075\n",
      "Q Predictions Min                      164.818\n",
      "V Predictions Mean                     179.866\n",
      "V Predictions Std                        2.44064\n",
      "V Predictions Max                      185.973\n",
      "V Predictions Min                      166.539\n",
      "Log Pis Mean                            -2.00911\n",
      "Log Pis Std                              0.364498\n",
      "Log Pis Max                             -0.713922\n",
      "Log Pis Min                             -4.586\n",
      "Policy mu Mean                           0.0647093\n",
      "Policy mu Std                            0.125196\n",
      "Policy mu Max                            0.439766\n",
      "Policy mu Min                           -0.179321\n",
      "Policy log std Mean                     -0.131607\n",
      "Policy log std Std                       0.00915156\n",
      "Policy log std Max                      -0.11911\n",
      "Policy log std Min                      -0.185466\n",
      "Z mean eval                              0.00738927\n",
      "Z variance eval                          0.273369\n",
      "AverageTrainReturn_all_train_tasks      -0.0481637\n",
      "AverageReturn_all_train_tasks           -0.0521637\n",
      "AverageReturn_all_test_tasks            10.7114\n",
      "Number of train steps total          58000\n",
      "Number of env steps total           248067\n",
      "Number of rollouts total                 0\n",
      "Train Time (s)                          33.721\n",
      "(Previous) Eval Time (s)                 7.05864\n",
      "Sample Time (s)                          3.60137\n",
      "Epoch Time (s)                          44.381\n",
      "Total Train Time (s)                  5003.17\n",
      "Epoch                                  115\n",
      "----------------------------------  ---------------\n",
      "2020-06-11 15:33:19.363315 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #115 | Epoch Duration: 45.252983808517456\n",
      "2020-06-11 15:33:19.364315 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #115 | Started Training: True\n",
      "----------------------------------  ---------------\n",
      "Z mean train                             0.00711828\n",
      "Z variance train                         0.855109\n",
      "KL Divergence                            0.107874\n",
      "KL Loss                                  0.0107874\n",
      "QF Loss                                  0.306523\n",
      "VF Loss                                  0.436322\n",
      "Policy Loss                           -178.807\n",
      "Q Predictions Mean                     176.982\n",
      "Q Predictions Std                        2.67011\n",
      "Q Predictions Max                      182.017\n",
      "Q Predictions Min                      164.613\n",
      "V Predictions Mean                     178.233\n",
      "V Predictions Std                        2.707\n",
      "V Predictions Max                      183.575\n",
      "V Predictions Min                      165.737\n",
      "Log Pis Mean                            -2.01795\n",
      "Log Pis Std                              0.360761\n",
      "Log Pis Max                             -0.433474\n",
      "Log Pis Min                             -3.19491\n",
      "Policy mu Mean                           0.0616667\n",
      "Policy mu Std                            0.138538\n",
      "Policy mu Max                            0.474222\n",
      "Policy mu Min                           -0.168105\n",
      "Policy log std Mean                     -0.132526\n",
      "Policy log std Std                       0.0109379\n",
      "Policy log std Max                      -0.116531\n",
      "Policy log std Min                      -0.186843\n",
      "Z mean eval                              0.00899728\n",
      "Z variance eval                          0.30284\n",
      "AverageTrainReturn_all_train_tasks      -0.0456299\n",
      "AverageReturn_all_train_tasks           -0.0534709\n",
      "AverageReturn_all_test_tasks            -0.0488797\n",
      "Number of train steps total          58500\n",
      "Number of env steps total           250067\n",
      "Number of rollouts total                 0\n",
      "Train Time (s)                          36.828\n",
      "(Previous) Eval Time (s)                 7.92989\n",
      "Sample Time (s)                          5.33796\n",
      "Epoch Time (s)                          50.0959\n",
      "Total Train Time (s)                  5052\n",
      "Epoch                                  116\n",
      "----------------------------------  ---------------\n",
      "2020-06-11 15:34:08.192550 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #116 | Epoch Duration: 48.827234745025635\n",
      "2020-06-11 15:34:08.195548 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #116 | Started Training: True\n",
      "----------------------------------  ---------------\n",
      "Z mean train                             0.0101248\n",
      "Z variance train                         0.962997\n",
      "KL Divergence                            0.0119815\n",
      "KL Loss                                  0.00119815\n",
      "QF Loss                                  0.345977\n",
      "VF Loss                                  0.677302\n",
      "Policy Loss                           -180.144\n",
      "Q Predictions Mean                     178.247\n",
      "Q Predictions Std                        2.67076\n",
      "Q Predictions Max                      182.864\n",
      "Q Predictions Min                      164.882\n",
      "V Predictions Mean                     180.684\n",
      "V Predictions Std                        2.74494\n",
      "V Predictions Max                      185.236\n",
      "V Predictions Min                      166.77\n",
      "Log Pis Mean                            -2.02333\n",
      "Log Pis Std                              0.339098\n",
      "Log Pis Max                             -0.659762\n",
      "Log Pis Min                             -3.3049\n",
      "Policy mu Mean                           0.0646412\n",
      "Policy mu Std                            0.131554\n",
      "Policy mu Max                            0.489051\n",
      "Policy mu Min                           -0.17071\n",
      "Policy log std Mean                     -0.13091\n",
      "Policy log std Std                       0.00845677\n",
      "Policy log std Max                      -0.117742\n",
      "Policy log std Min                      -0.181508\n",
      "Z mean eval                              0.0306801\n",
      "Z variance eval                          0.195207\n",
      "AverageTrainReturn_all_train_tasks      -0.047272\n",
      "AverageReturn_all_train_tasks            1.68814\n",
      "AverageReturn_all_test_tasks            -0.0486693\n",
      "Number of train steps total          59000\n",
      "Number of env steps total           252067\n",
      "Number of rollouts total                 0\n",
      "Train Time (s)                          37.2521\n",
      "(Previous) Eval Time (s)                 6.6608\n",
      "Sample Time (s)                          4.95479\n",
      "Epoch Time (s)                          48.8677\n",
      "Total Train Time (s)                  5100.15\n",
      "Epoch                                  117\n",
      "----------------------------------  ---------------\n",
      "2020-06-11 15:34:56.345985 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #117 | Epoch Duration: 48.14943742752075\n",
      "2020-06-11 15:34:56.346984 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #117 | Started Training: True\n",
      "----------------------------------  ---------------\n",
      "Z mean train                             0.031317\n",
      "Z variance train                         0.61973\n",
      "KL Divergence                            1.01393\n",
      "KL Loss                                  0.101393\n",
      "QF Loss                                  0.902568\n",
      "VF Loss                                  6.38643\n",
      "Policy Loss                           -179.605\n",
      "Q Predictions Mean                     176.743\n",
      "Q Predictions Std                        2.63027\n",
      "Q Predictions Max                      181.676\n",
      "Q Predictions Min                      162.629\n",
      "V Predictions Mean                     177.151\n",
      "V Predictions Std                        2.63529\n",
      "V Predictions Max                      182.226\n",
      "V Predictions Min                      162.798\n",
      "Log Pis Mean                            -2.00165\n",
      "Log Pis Std                              0.379106\n",
      "Log Pis Max                             -0.575754\n",
      "Log Pis Min                             -5.36777\n",
      "Policy mu Mean                           0.0646402\n",
      "Policy mu Std                            0.137805\n",
      "Policy mu Max                            0.482933\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy mu Min                           -0.186299\n",
      "Policy log std Mean                     -0.132656\n",
      "Policy log std Std                       0.00925839\n",
      "Policy log std Max                      -0.117246\n",
      "Policy log std Min                      -0.183088\n",
      "Z mean eval                              0.0249754\n",
      "Z variance eval                          0.245819\n",
      "AverageTrainReturn_all_train_tasks       1.94579\n",
      "AverageReturn_all_train_tasks            3.12371\n",
      "AverageReturn_all_test_tasks             0.758112\n",
      "Number of train steps total          59500\n",
      "Number of env steps total           254067\n",
      "Number of rollouts total                 0\n",
      "Train Time (s)                          34.5384\n",
      "(Previous) Eval Time (s)                 5.94202\n",
      "Sample Time (s)                          4.23753\n",
      "Epoch Time (s)                          44.718\n",
      "Total Train Time (s)                  5146\n",
      "Epoch                                  118\n",
      "----------------------------------  ---------------\n",
      "2020-06-11 15:35:42.190760 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #118 | Epoch Duration: 45.84277534484863\n",
      "2020-06-11 15:35:42.191759 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #118 | Started Training: True\n",
      "----------------------------------  ---------------\n",
      "Z mean train                             0.02533\n",
      "Z variance train                         0.775143\n",
      "KL Divergence                            0.300786\n",
      "KL Loss                                  0.0300786\n",
      "QF Loss                                  0.290538\n",
      "VF Loss                                  0.539787\n",
      "Policy Loss                           -180.313\n",
      "Q Predictions Mean                     178.643\n",
      "Q Predictions Std                        2.48274\n",
      "Q Predictions Max                      181.909\n",
      "Q Predictions Min                      167.744\n",
      "V Predictions Mean                     180.866\n",
      "V Predictions Std                        2.56116\n",
      "V Predictions Max                      184.923\n",
      "V Predictions Min                      169.153\n",
      "Log Pis Mean                            -1.99778\n",
      "Log Pis Std                              0.362719\n",
      "Log Pis Max                             -0.81978\n",
      "Log Pis Min                             -4.14885\n",
      "Policy mu Mean                           0.0805646\n",
      "Policy mu Std                            0.129267\n",
      "Policy mu Max                            0.461973\n",
      "Policy mu Min                           -0.173106\n",
      "Policy log std Mean                     -0.132826\n",
      "Policy log std Std                       0.00902191\n",
      "Policy log std Max                      -0.119729\n",
      "Policy log std Min                      -0.180091\n",
      "Z mean eval                              0.0065951\n",
      "Z variance eval                          0.301719\n",
      "AverageTrainReturn_all_train_tasks      -0.051585\n",
      "AverageReturn_all_train_tasks            0.4139\n",
      "AverageReturn_all_test_tasks            -0.0473327\n",
      "Number of train steps total          60000\n",
      "Number of env steps total           256067\n",
      "Number of rollouts total                 0\n",
      "Train Time (s)                          36.7635\n",
      "(Previous) Eval Time (s)                 7.06657\n",
      "Sample Time (s)                          4.31094\n",
      "Epoch Time (s)                          48.141\n",
      "Total Train Time (s)                  5193.12\n",
      "Epoch                                  119\n",
      "----------------------------------  ---------------\n",
      "2020-06-11 15:36:29.320007 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #119 | Epoch Duration: 47.128247022628784\n",
      "2020-06-11 15:36:29.321006 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #119 | Started Training: True\n",
      "----------------------------------  ----------------\n",
      "Z mean train                             0.00610924\n",
      "Z variance train                         0.972717\n",
      "KL Divergence                            0.00493806\n",
      "KL Loss                                  0.000493807\n",
      "QF Loss                                  0.165556\n",
      "VF Loss                                  0.0667248\n",
      "Policy Loss                           -180.461\n",
      "Q Predictions Mean                     178.475\n",
      "Q Predictions Std                        2.54927\n",
      "Q Predictions Max                      182.306\n",
      "Q Predictions Min                      164.804\n",
      "V Predictions Mean                     180.543\n",
      "V Predictions Std                        2.59166\n",
      "V Predictions Max                      184.507\n",
      "V Predictions Min                      164.862\n",
      "Log Pis Mean                            -2.03609\n",
      "Log Pis Std                              0.357281\n",
      "Log Pis Max                             -0.696565\n",
      "Log Pis Min                             -3.81912\n",
      "Policy mu Mean                           0.0659997\n",
      "Policy mu Std                            0.127972\n",
      "Policy mu Max                            0.465098\n",
      "Policy mu Min                           -0.175833\n",
      "Policy log std Mean                     -0.132606\n",
      "Policy log std Std                       0.00873146\n",
      "Policy log std Max                      -0.118136\n",
      "Policy log std Min                      -0.182933\n",
      "Z mean eval                              0.0326459\n",
      "Z variance eval                          0.246348\n",
      "AverageTrainReturn_all_train_tasks      -0.0504306\n",
      "AverageReturn_all_train_tasks            1.07396\n",
      "AverageReturn_all_test_tasks             4.49994\n",
      "Number of train steps total          60500\n",
      "Number of env steps total           258067\n",
      "Number of rollouts total                 0\n",
      "Train Time (s)                          37.0873\n",
      "(Previous) Eval Time (s)                 6.05355\n",
      "Sample Time (s)                          3.73962\n",
      "Epoch Time (s)                          46.8805\n",
      "Total Train Time (s)                  5240.53\n",
      "Epoch                                  120\n",
      "----------------------------------  ----------------\n",
      "2020-06-11 15:37:16.731864 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #120 | Epoch Duration: 47.408857583999634\n",
      "2020-06-11 15:37:16.734868 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #120 | Started Training: True\n",
      "----------------------------------  --------------\n",
      "Z mean train                             0.0329663\n",
      "Z variance train                         0.780874\n",
      "KL Divergence                            0.31327\n",
      "KL Loss                                  0.031327\n",
      "QF Loss                                  0.358706\n",
      "VF Loss                                  3.43858\n",
      "Policy Loss                           -180.118\n",
      "Q Predictions Mean                     179.056\n",
      "Q Predictions Std                        2.72156\n",
      "Q Predictions Max                      182.934\n",
      "Q Predictions Min                      166.945\n",
      "V Predictions Mean                     181.933\n",
      "V Predictions Std                        2.73166\n",
      "V Predictions Max                      185.603\n",
      "V Predictions Min                      169.541\n",
      "Log Pis Mean                            -1.98902\n",
      "Log Pis Std                              0.411667\n",
      "Log Pis Max                             -0.5861\n",
      "Log Pis Min                             -5.11499\n",
      "Policy mu Mean                           0.0675846\n",
      "Policy mu Std                            0.138268\n",
      "Policy mu Max                            0.487203\n",
      "Policy mu Min                           -0.172761\n",
      "Policy log std Mean                     -0.132207\n",
      "Policy log std Std                       0.0102715\n",
      "Policy log std Max                      -0.119164\n",
      "Policy log std Min                      -0.189743\n",
      "Z mean eval                              0.0100568\n",
      "Z variance eval                          0.226006\n",
      "AverageTrainReturn_all_train_tasks      -0.0472965\n",
      "AverageReturn_all_train_tasks           -0.0489083\n",
      "AverageReturn_all_test_tasks            -0.0482111\n",
      "Number of train steps total          61000\n",
      "Number of env steps total           260067\n",
      "Number of rollouts total                 0\n",
      "Train Time (s)                          38.5507\n",
      "(Previous) Eval Time (s)                 6.58214\n",
      "Sample Time (s)                          3.80763\n",
      "Epoch Time (s)                          48.9405\n",
      "Total Train Time (s)                  5288.98\n",
      "Epoch                                  121\n",
      "----------------------------------  --------------\n",
      "2020-06-11 15:38:05.188703 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #121 | Epoch Duration: 48.45184254646301\n",
      "2020-06-11 15:38:05.190703 Hora de verano romance | [output\\Peg2D\\2020_06_11_14_10_07] Iteration #121 | Started Training: True\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-c70952ece1d2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    114\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[1;31m# run the algorithm\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 116\u001b[1;33m \u001b[0malgorithm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Desktop\\Alvaro\\Imperial College\\MSc\\Project\\meta_robot\\backend\\core\\meta_rl_algorithm.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    211\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    212\u001b[0m             \u001b[1;31m# eval\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 213\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_try_to_eval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mit_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    214\u001b[0m             \u001b[0mgt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstamp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'eval'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\Alvaro\\Imperial College\\MSc\\Project\\meta_robot\\backend\\core\\meta_rl_algorithm.py\u001b[0m in \u001b[0;36m_try_to_eval\u001b[1;34m(self, epoch)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_extra_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_extra_data_to_save\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_can_evaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    263\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    264\u001b[0m             \u001b[0mparams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_epoch_snapshot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\Alvaro\\Imperial College\\MSc\\Project\\meta_robot\\backend\\core\\meta_rl_algorithm.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, epoch)\u001b[0m\n\u001b[0;32m    462\u001b[0m         \u001b[0mtrain_returns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_returns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    463\u001b[0m         \u001b[1;31m### eval train tasks with on-policy data to match eval of test tasks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 464\u001b[1;33m         \u001b[0mtrain_final_returns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_online_returns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_eval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    465\u001b[0m         \u001b[0meval_util\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'train online returns'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    466\u001b[0m         \u001b[0meval_util\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_online_returns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\Alvaro\\Imperial College\\MSc\\Project\\meta_robot\\backend\\core\\meta_rl_algorithm.py\u001b[0m in \u001b[0;36m_do_eval\u001b[1;34m(self, indices, epoch)\u001b[0m\n\u001b[0;32m    409\u001b[0m             \u001b[0mall_rets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    410\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_evals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 411\u001b[1;33m                 \u001b[0mpaths\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollect_paths\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    412\u001b[0m                 \u001b[0mall_rets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0meval_util\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_average_returns\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpaths\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    413\u001b[0m             \u001b[0mfinal_returns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mall_rets\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\Alvaro\\Imperial College\\MSc\\Project\\meta_robot\\backend\\core\\meta_rl_algorithm.py\u001b[0m in \u001b[0;36mcollect_paths\u001b[1;34m(self, idx, epoch, run)\u001b[0m\n\u001b[0;32m    381\u001b[0m         \u001b[0mnum_trajs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    382\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[0mnum_transitions\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_steps_per_eval\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 383\u001b[1;33m             \u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msampler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobtain_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdeterministic\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval_deterministic\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_samples\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_steps_per_eval\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mnum_transitions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_trajs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccum_context\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    384\u001b[0m             \u001b[0mpaths\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    385\u001b[0m             \u001b[0mnum_transitions\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mnum\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\Alvaro\\Imperial College\\MSc\\Project\\meta_robot\\backend\\samplers\\in_place.py\u001b[0m in \u001b[0;36mobtain_samples\u001b[1;34m(self, deterministic, max_samples, max_trajs, accum_context, resample)\u001b[0m\n\u001b[0;32m     48\u001b[0m             \u001b[1;31m# Rollout function is actually the collector\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m             path = rollout(\n\u001b[1;32m---> 50\u001b[1;33m                 self.env, policy, max_path_length=self.max_path_length, accum_context=accum_context)\n\u001b[0m\u001b[0;32m     51\u001b[0m             \u001b[1;31m# save the latent context that generated this trajectory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m             \u001b[0mpath\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'context'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpolicy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\Alvaro\\Imperial College\\MSc\\Project\\meta_robot\\backend\\samplers\\util.py\u001b[0m in \u001b[0;36mrollout\u001b[1;34m(env, agent, max_path_length, accum_context, animated, save_frames)\u001b[0m\n\u001b[0;32m     39\u001b[0m         \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m     \u001b[1;32mwhile\u001b[0m \u001b[0mpath_length\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mmax_path_length\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m         \u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0magent_info\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0magent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_action\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m         \u001b[0mnext_o\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0md\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menv_info\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;31m# update the agent's current context\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\Alvaro\\Imperial College\\MSc\\Project\\meta_robot\\backend\\torch\\PEARL\\policies.py\u001b[0m in \u001b[0;36mget_action\u001b[1;34m(self, observation)\u001b[0m\n\u001b[0;32m    141\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_action\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobservation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    142\u001b[0m         return self.stochastic_policy.get_action(observation,\n\u001b[1;32m--> 143\u001b[1;33m                                                  deterministic=True)\n\u001b[0m\u001b[0;32m    144\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    145\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_actions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobservations\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\Alvaro\\Imperial College\\MSc\\Project\\meta_robot\\backend\\torch\\PEARL\\agent.py\u001b[0m in \u001b[0;36mget_action\u001b[1;34m(self, obs, deterministic)\u001b[0m\n\u001b[0;32m    153\u001b[0m         \u001b[0mobs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mptu\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    154\u001b[0m         \u001b[0min_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mobs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mz\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 155\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpolicy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_action\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0min_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdeterministic\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdeterministic\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    156\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    157\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mset_num_steps_total\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\Alvaro\\Imperial College\\MSc\\Project\\meta_robot\\backend\\torch\\PEARL\\policies.py\u001b[0m in \u001b[0;36mget_action\u001b[1;34m(self, obs, deterministic)\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_action\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdeterministic\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m         \u001b[0mactions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_actions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdeterministic\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdeterministic\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mactions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\autograd\\grad_mode.py\u001b[0m in \u001b[0;36mdecorate_no_grad\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     47\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mdecorate_no_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mdecorate_no_grad\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\Alvaro\\Imperial College\\MSc\\Project\\meta_robot\\backend\\torch\\PEARL\\policies.py\u001b[0m in \u001b[0;36mget_actions\u001b[1;34m(self, obs, deterministic)\u001b[0m\n\u001b[0;32m     73\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_actions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdeterministic\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 75\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdeterministic\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdeterministic\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     76\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp_ify\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\Alvaro\\Imperial College\\MSc\\Project\\meta_robot\\backend\\torch\\PEARL\\policies.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, obs, reparameterize, deterministic, return_log_prob)\u001b[0m\n\u001b[0;32m     90\u001b[0m         \u001b[0mh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfcs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 92\u001b[1;33m             \u001b[0mh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhidden_activation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     93\u001b[0m         \u001b[0mmean\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlast_fc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstd\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    540\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 541\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    542\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\linear.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 87\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mlinear\u001b[1;34m(input, weight, bias)\u001b[0m\n\u001b[0;32m   1368\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1369\u001b[0m         \u001b[1;31m# fused op is marginally faster\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1370\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1371\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1372\u001b[0m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Launcher for experiments with PEARL\n",
    "\"\"\"\n",
    "import sys\n",
    "sys.path.append(\"\")\n",
    "\n",
    "import os\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import click\n",
    "import json\n",
    "import torch\n",
    "\n",
    "from envs.metaENV import ENV\n",
    "# from backend.envs.wrappers import NormalizedBoxEnv\n",
    "from backend.torch.PEARL.policies import TanhGaussianPolicy\n",
    "from backend.torch.networks import FlattenMlp, MlpEncoder, RecurrentEncoder\n",
    "from backend.torch.PEARL.sac import PEARLSoftActorCritic\n",
    "from backend.torch.PEARL.agent import PEARLAgent\n",
    "from backend.launchers.launcher_util import setup_logger\n",
    "import backend.torch.pytorch_util as ptu\n",
    "from configs.default import default_config\n",
    "\n",
    "variant = default_config\n",
    "gpu = 0\n",
    "docker = False\n",
    "debug = False\n",
    "\n",
    "env = ENV()\n",
    "tasks = env.get_all_task_idx()\n",
    "obs_dim = int(np.prod(env.observation_space.shape))\n",
    "action_dim = int(np.prod(env.action_space.shape))\n",
    "print(obs_dim, action_dim)\n",
    "reward_dim = 1\n",
    "\n",
    "# instantiate networks\n",
    "latent_dim = variant['latent_size']\n",
    "context_encoder_input_dim = 2 * obs_dim + action_dim + reward_dim if variant['algo_params']['use_next_obs_in_context'] else obs_dim + action_dim + reward_dim\n",
    "context_encoder_output_dim = latent_dim * 2 if variant['algo_params']['use_information_bottleneck'] else latent_dim\n",
    "net_size = variant['net_size']\n",
    "recurrent = variant['algo_params']['recurrent']\n",
    "encoder_model = RecurrentEncoder if recurrent else MlpEncoder\n",
    "\n",
    "context_encoder = encoder_model(\n",
    "    hidden_sizes=[200, 200, 200],\n",
    "    input_size=context_encoder_input_dim,\n",
    "    output_size=context_encoder_output_dim,\n",
    ")\n",
    "qf1 = FlattenMlp(\n",
    "    hidden_sizes=[net_size, net_size, net_size],\n",
    "    input_size=obs_dim + action_dim + latent_dim,\n",
    "    output_size=1,\n",
    ")\n",
    "qf2 = FlattenMlp(\n",
    "    hidden_sizes=[net_size, net_size, net_size],\n",
    "    input_size=obs_dim + action_dim + latent_dim,\n",
    "    output_size=1,\n",
    ")\n",
    "vf = FlattenMlp(\n",
    "    hidden_sizes=[net_size, net_size, net_size],\n",
    "    input_size=obs_dim + latent_dim,\n",
    "    output_size=1,\n",
    ")\n",
    "policy = TanhGaussianPolicy(\n",
    "    hidden_sizes=[net_size, net_size, net_size],\n",
    "    obs_dim=obs_dim + latent_dim,\n",
    "    latent_dim=latent_dim,\n",
    "    action_dim=action_dim,\n",
    ")\n",
    "agent = PEARLAgent(\n",
    "    latent_dim,\n",
    "    context_encoder,\n",
    "    policy,\n",
    "    **variant['algo_params']\n",
    ")\n",
    "algorithm = PEARLSoftActorCritic(\n",
    "    env=env,\n",
    "    train_tasks=list(tasks[:variant['n_train_tasks']]),\n",
    "    eval_tasks=list(tasks[-variant['n_eval_tasks']:]),\n",
    "    nets=[agent, qf1, qf2, vf],\n",
    "    latent_dim=latent_dim,\n",
    "    **variant['algo_params']\n",
    ")\n",
    "\n",
    "# optionally load pre-trained weights\n",
    "if variant['path_to_weights'] is not None:\n",
    "    path = variant['path_to_weights']\n",
    "    context_encoder.load_state_dict(torch.load(os.path.join(path, 'context_encoder.pth')))\n",
    "    qf1.load_state_dict(torch.load(os.path.join(path, 'qf1.pth')))\n",
    "    qf2.load_state_dict(torch.load(os.path.join(path, 'qf2.pth')))\n",
    "    vf.load_state_dict(torch.load(os.path.join(path, 'vf.pth')))\n",
    "    # TODO hacky, revisit after model refactor\n",
    "    algorithm.networks[-2].load_state_dict(torch.load(os.path.join(path, 'target_vf.pth')))\n",
    "    policy.load_state_dict(torch.load(os.path.join(path, 'policy.pth')))\n",
    "\n",
    "# optional GPU mode\n",
    "ptu.set_gpu_mode(variant['util_params']['use_gpu'], variant['util_params']['gpu_id'])\n",
    "if ptu.gpu_enabled():\n",
    "    algorithm.to()\n",
    "\n",
    "# debugging triggers a lot of printing and logs to a debug directory\n",
    "DEBUG = variant['util_params']['debug']\n",
    "os.environ['DEBUG'] = str(int(DEBUG))\n",
    "\n",
    "# create logging directory\n",
    "# TODO support Docker\n",
    "exp_id = 'debug' if DEBUG else None\n",
    "experiment_log_dir = setup_logger(variant['env_name'], variant=variant, exp_id=exp_id, base_log_dir=variant['util_params']['base_log_dir'])\n",
    "\n",
    "# optionally save eval trajectories as pkl files\n",
    "if variant['algo_params']['dump_eval_paths']:\n",
    "    pickle_dir = experiment_log_dir + '/eval_trajectories'\n",
    "    pathlib.Path(pickle_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# run the algorithm\n",
    "algorithm.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'observations': array([[ 0.41332293, -0.3903222 ,  0.99874047, -0.05017444]]),\n",
       " 'actions': array([[0.96866971, 0.18616225, 0.60435963]]),\n",
       " 'rewards': array([[-0.00056691]]),\n",
       " 'terminals': array([[0]], dtype=uint8),\n",
       " 'next_observations': array([[ 0.41676584, -0.38431384,  0.99907   , -0.04311778]]),\n",
       " 'sparse_rewards': array([[0.]])}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algorithm.replay_buffer.random_batch(0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monitor tasks (4 training 1 eval), indexes, Normalisation, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TanhGaussianPolicy(\n",
       "  (fc0): Linear(in_features=9, out_features=300, bias=True)\n",
       "  (fc1): Linear(in_features=300, out_features=300, bias=True)\n",
       "  (fc2): Linear(in_features=300, out_features=300, bias=True)\n",
       "  (last_fc): Linear(in_features=300, out_features=3, bias=True)\n",
       "  (last_fc_log_std): Linear(in_features=300, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PEARLAgent(\n",
       "  (context_encoder): MlpEncoder(\n",
       "    (fc0): Linear(in_features=8, out_features=200, bias=True)\n",
       "    (fc1): Linear(in_features=200, out_features=200, bias=True)\n",
       "    (fc2): Linear(in_features=200, out_features=200, bias=True)\n",
       "    (last_fc): Linear(in_features=200, out_features=10, bias=True)\n",
       "  )\n",
       "  (policy): TanhGaussianPolicy(\n",
       "    (fc0): Linear(in_features=9, out_features=300, bias=True)\n",
       "    (fc1): Linear(in_features=300, out_features=300, bias=True)\n",
       "    (fc2): Linear(in_features=300, out_features=300, bias=True)\n",
       "    (last_fc): Linear(in_features=300, out_features=3, bias=True)\n",
       "    (last_fc_log_std): Linear(in_features=300, out_features=3, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading chipmunk for Windows (64bit) [C:\\Users\\Alvaro\\Anaconda3\\lib\\site-packages\\pymunk\\chipmunk.dll]\n",
      "Selecting Default variant for notebook compatiblity ... \n",
      "\n",
      "2020-06-12 01:25:57.777159 Hora de verano romance | Variant:\n",
      "2020-06-12 01:25:57.779158 Hora de verano romance | {\n",
      "  \"env_name\": \"Peg2D\",\n",
      "  \"n_train_tasks\": 16,\n",
      "  \"n_eval_tasks\": 4,\n",
      "  \"modality\": \"train\",\n",
      "  \"latent_size\": 4,\n",
      "  \"net_size\": 128,\n",
      "  \"path_to_weights\": null,\n",
      "  \"env_params\": {\n",
      "    \"n_tasks\": 20,\n",
      "    \"randomize_tasks\": true\n",
      "  },\n",
      "  \"algo_params\": {\n",
      "    \"meta_batch\": 8,\n",
      "    \"num_iterations\": 500,\n",
      "    \"num_initial_steps\": 2000,\n",
      "    \"num_tasks_sample\": 5,\n",
      "    \"num_steps_prior\": 250,\n",
      "    \"num_steps_posterior\": 0,\n",
      "    \"num_extra_rl_steps_posterior\": 250,\n",
      "    \"num_train_steps_per_itr\": 1024,\n",
      "    \"num_evals\": 4,\n",
      "    \"num_steps_per_eval\": 250,\n",
      "    \"batch_size\": 256,\n",
      "    \"embedding_batch_size\": 64,\n",
      "    \"embedding_mini_batch_size\": 64,\n",
      "    \"max_path_length\": 250,\n",
      "    \"discount\": 0.99,\n",
      "    \"soft_target_tau\": 0.005,\n",
      "    \"policy_lr\": 0.0003,\n",
      "    \"qf_lr\": 0.0003,\n",
      "    \"vf_lr\": 0.0003,\n",
      "    \"context_lr\": 0.0003,\n",
      "    \"reward_scale\": 10.0,\n",
      "    \"sparse_rewards\": false,\n",
      "    \"kl_lambda\": 0.1,\n",
      "    \"use_information_bottleneck\": true,\n",
      "    \"use_next_obs_in_context\": false,\n",
      "    \"update_post_train\": 1,\n",
      "    \"num_exp_traj_eval\": 1,\n",
      "    \"recurrent\": false,\n",
      "    \"dump_eval_paths\": false\n",
      "  },\n",
      "  \"util_params\": {\n",
      "    \"base_log_dir\": \"output\",\n",
      "    \"use_gpu\": false,\n",
      "    \"gpu_id\": 0,\n",
      "    \"debug\": false,\n",
      "    \"docker\": false\n",
      "  }\n",
      "}\n",
      "1\n",
      "(-0.1387800331843928, False)\n",
      "<pymunk.shapes.Poly object at 0x0000024B8CCBDB38> Body(6074.15926535898, 20279593.06727851, Body.DYNAMIC)\n",
      "(-0.1395272925201375, False)\n",
      "(-0.14080079966765618, False)\n",
      "<pymunk.shapes.Poly object at 0x0000024B8CCBDB38> Body(6074.15926535898, 20279593.06727851, Body.DYNAMIC)\n",
      "(-0.14188043442787068, False)\n",
      "<pymunk.shapes.Segment object at 0x0000024B8CCBD668> Body(Body.STATIC)\n",
      "(-0.14116663718999883, False)\n",
      "<pymunk.shapes.Poly object at 0x0000024B8CCBDB38> Body(6074.15926535898, 20279593.06727851, Body.DYNAMIC)\n",
      "(-0.1414291000259708, False)\n",
      "(-0.14169995375840683, False)\n",
      "(-0.14172087681354506, False)\n",
      "<pymunk.shapes.Poly object at 0x0000024B8CCBDB38> Body(6074.15926535898, 20279593.06727851, Body.DYNAMIC)\n",
      "(-0.14219080319002766, False)\n",
      "(-0.14248933712867295, False)\n",
      "2\n",
      "Vec2d(1100.4316852828488, 546.5582850672239) Vec2d(999.6137997165458, 547.0324523960912)\n",
      "MADE IT, CONGRATS\n",
      "Vec2d(1100.9890822887835, 546.6742512885357) Vec2d(1000.1850500782156, 547.155463738314)\n",
      "MADE IT, CONGRATS\n",
      "Vec2d(1101.5221188490723, 546.7276984002907) Vec2d(1000.7735996109778, 547.0524199202117)\n",
      "MADE IT, CONGRATS\n",
      "Vec2d(1102.1638880135765, 546.5302080829754) Vec2d(1001.3389680150997, 547.0868217232864)\n",
      "MADE IT, CONGRATS\n",
      "Vec2d(1102.8093054312917, 546.5941136046551) Vec2d(1001.9826467272851, 547.0524713640326)\n",
      "MADE IT, CONGRATS\n",
      "Vec2d(1103.4346600249016, 546.609524194566) Vec2d(1002.5363920146901, 547.0572608304046)\n",
      "MADE IT, CONGRATS\n",
      "Vec2d(1103.934749909485, 546.7231405379039) Vec2d(1003.1225141184311, 547.1169667582507)\n",
      "MADE IT, CONGRATS\n",
      "Vec2d(1104.4537763910373, 546.6916644042287) Vec2d(1003.7142478884438, 547.0198631446897)\n",
      "MADE IT, CONGRATS\n",
      "Vec2d(1105.1534738781097, 546.4969122930248) Vec2d(1004.2497491608209, 546.9881500285076)\n",
      "MADE IT, CONGRATS\n",
      "Vec2d(1105.683732433132, 546.6902904425285) Vec2d(1004.9017927940138, 547.1177018433075)\n",
      "MADE IT, CONGRATS\n",
      "Vec2d(1106.2349651775162, 546.6588151219477) Vec2d(1005.4077135935277, 547.0928294273659)\n",
      "MADE IT, CONGRATS\n",
      "Vec2d(1106.8675169597047, 546.5549833060687) Vec2d(1005.9935470723645, 547.0665482421049)\n",
      "MADE IT, CONGRATS\n",
      "Vec2d(1107.341819137962, 546.5540345909967) Vec2d(1006.5776555428245, 547.0709698453184)\n",
      "MADE IT, CONGRATS\n",
      "Vec2d(1108.0048603699663, 546.6863679632006) Vec2d(1007.1075097062757, 547.1128491925667)\n",
      "MADE IT, CONGRATS\n",
      "Vec2d(1108.4600084228887, 546.5444603122231) Vec2d(1007.7346438404082, 547.1104663701134)\n",
      "MADE IT, CONGRATS\n",
      "Vec2d(1109.0823777585988, 546.4669270555921) Vec2d(1008.2141221458371, 547.1419796542381)\n",
      "MADE IT, CONGRATS\n",
      "Vec2d(1109.5941794533755, 546.7528005681783) Vec2d(1008.7985495445249, 547.0919613031346)\n",
      "MADE IT, CONGRATS\n",
      "Vec2d(1110.2360847762927, 546.5399175136035) Vec2d(1009.3079957549727, 547.0249225718815)\n",
      "MADE IT, CONGRATS\n",
      "Vec2d(1110.7173304327712, 546.6486851121982) Vec2d(1009.8870610826416, 547.1428719444943)\n",
      "MADE IT, CONGRATS\n",
      "Vec2d(1111.3671526332118, 546.6103801437515) Vec2d(1010.5290523293273, 547.1413575342824)\n",
      "MADE IT, CONGRATS\n",
      "Vec2d(1111.9954310853434, 546.710326461333) Vec2d(1011.1810480656966, 547.0345689556821)\n",
      "MADE IT, CONGRATS\n",
      "Vec2d(1112.6301624671446, 546.554305584414) Vec2d(1011.7417056366936, 546.9953893099279)\n",
      "MADE IT, CONGRATS\n",
      "Vec2d(1113.1266029233752, 546.7213308987804) Vec2d(1012.3409753492816, 547.1177724574267)\n",
      "MADE IT, CONGRATS\n",
      "Vec2d(1113.6744804399946, 546.667466870334) Vec2d(1012.839287090953, 547.0893637648091)\n",
      "MADE IT, CONGRATS\n",
      "Vec2d(1114.4779489783737, 546.5351634904837) Vec2d(1013.6402197053194, 547.1626651183469)\n",
      "MADE IT, CONGRATS\n",
      "Vec2d(1115.0024322680997, 546.6312419622361) Vec2d(1014.2415141154689, 547.1780950801815)\n",
      "MADE IT, CONGRATS\n",
      "Vec2d(1115.7290230081333, 546.638263420133) Vec2d(1014.8427805018332, 547.1230930247492)\n",
      "MADE IT, CONGRATS\n",
      "Vec2d(1116.3535770681024, 546.7510514895156) Vec2d(1015.4925994953448, 547.0944646147966)\n",
      "MADE IT, CONGRATS\n",
      "Vec2d(1116.896020636394, 546.532001537212) Vec2d(1016.0728518531091, 547.1689815202145)\n",
      "MADE IT, CONGRATS\n",
      "Vec2d(1117.38023429328, 546.5846854382186) Vec2d(1016.6290390846563, 547.1849627254511)\n",
      "MADE IT, CONGRATS\n",
      "Vec2d(1118.0388062995094, 546.3924755405432) Vec2d(1017.1521964152317, 547.0079112148437)\n",
      "MADE IT, CONGRATS\n",
      "Vec2d(1118.5900187096663, 546.7933092086429) Vec2d(1017.7321241992822, 547.0939930976765)\n",
      "MADE IT, CONGRATS\n",
      "Vec2d(1119.1090602626382, 546.4896367242758) Vec2d(1018.3407831157341, 547.0947446346214)\n",
      "MADE IT, CONGRATS\n",
      "Vec2d(1119.701622213292, 546.5236018799461) Vec2d(1018.8260176820571, 547.0517749165783)\n",
      "MADE IT, CONGRATS\n",
      "Vec2d(1120.2246798600652, 546.8947129809632) Vec2d(1019.3923070734941, 547.10586432954)\n",
      "MADE IT, CONGRATS\n",
      "Vec2d(1120.8205805403418, 546.4789862773334) Vec2d(1020.0126207741213, 547.0872196125396)\n",
      "MADE IT, CONGRATS\n",
      "Vec2d(1121.4041090880055, 546.6148792290346) Vec2d(1020.6103860665775, 547.1091973246739)\n",
      "MADE IT, CONGRATS\n",
      "Vec2d(1122.030958446263, 546.665041631855) Vec2d(1021.1418083059635, 547.0975027301973)\n",
      "MADE IT, CONGRATS\n",
      "Vec2d(1122.4922129876436, 546.6032698566542) Vec2d(1021.787695659241, 547.044988968807)\n",
      "MADE IT, CONGRATS\n",
      "Vec2d(1123.175974396549, 546.6116598701389) Vec2d(1022.2531598177133, 547.0953526827811)\n",
      "MADE IT, CONGRATS\n",
      "Vec2d(1123.9673799057289, 546.8165527807071) Vec2d(1023.2326782586498, 547.0933997839282)\n",
      "MADE IT, CONGRATS\n",
      "Vec2d(1124.6508935068953, 546.4323681501311) Vec2d(1023.720153715678, 547.0186101084781)\n",
      "MADE IT, CONGRATS\n",
      "Vec2d(1125.2796078094004, 546.7437861843237) Vec2d(1024.5091606319497, 547.1777653730825)\n",
      "MADE IT, CONGRATS\n",
      "Vec2d(1125.841632915524, 546.575580591387) Vec2d(1025.0543938227781, 547.0468789403812)\n",
      "MADE IT, CONGRATS\n",
      "Vec2d(1126.4079704147214, 546.7450113170746) Vec2d(1025.5481894066882, 547.1239095300966)\n",
      "MADE IT, CONGRATS\n",
      "Vec2d(1126.9565937156394, 546.4731389740796) Vec2d(1026.085810531113, 547.1643248587189)\n",
      "MADE IT, CONGRATS\n",
      "Vec2d(1127.5200718621918, 546.7350404512758) Vec2d(1026.7644059172742, 547.153972084155)\n",
      "MADE IT, CONGRATS\n",
      "Vec2d(1128.1473802948576, 546.7091067854313) Vec2d(1027.2377704141675, 547.0558560671687)\n",
      "MADE IT, CONGRATS\n",
      "Vec2d(1128.6911481122295, 546.5831829285487) Vec2d(1027.860745563985, 547.091543035642)\n",
      "MADE IT, CONGRATS\n",
      "Vec2d(1129.2680557487322, 546.659882366335) Vec2d(1028.4728135317532, 547.0944328448787)\n",
      "MADE IT, CONGRATS\n",
      "Vec2d(1129.8457756633095, 546.5531440921364) Vec2d(1028.967769589237, 547.1238548490302)\n",
      "MADE IT, CONGRATS\n",
      "Vec2d(1100.4910111734548, 546.6065968133968) Vec2d(999.7293142515867, 547.0887727094341)\n",
      "MADE IT, CONGRATS\n",
      "Vec2d(1101.1993906988407, 546.531456788611) Vec2d(1000.2810950959118, 547.0596521764274)\n",
      "MADE IT, CONGRATS\n",
      "Vec2d(1101.6260695199783, 546.5351671028512) Vec2d(1000.928147674874, 547.0563012432779)\n",
      "MADE IT, CONGRATS\n",
      "Vec2d(1102.2734105856787, 546.6727848339841) Vec2d(1001.4785532707273, 547.1169375997385)\n",
      "MADE IT, CONGRATS\n",
      "Vec2d(1102.836961654918, 546.6495550540042) Vec2d(1002.0609892176425, 547.0893076435337)\n",
      "MADE IT, CONGRATS\n",
      "Vec2d(1103.5437506192004, 546.4869010307855) Vec2d(1002.6372125068813, 547.0520681739404)\n",
      "MADE IT, CONGRATS\n",
      "Vec2d(1104.0083107006344, 546.5727719444689) Vec2d(1003.2855399365473, 547.0543202910006)\n",
      "MADE IT, CONGRATS\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Launcher for experiments with PEARL\n",
    "\"\"\"\n",
    "import sys\n",
    "sys.path.append(\"\")\n",
    "\n",
    "import os\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import click\n",
    "import json\n",
    "import torch\n",
    "from tensorboardX import SummaryWriter\n",
    "import datetime\n",
    "\n",
    "from envs.metaENV import ENV, VisualiserWrapper\n",
    "from envs.MetaPeg2D import WINDOW_X, WINDOW_Y, ORIGIN, PEG_DEPTH\n",
    "# from backend.envs.wrappers import NormalizedBoxEnv\n",
    "from backend.torch.PEARL.policies import TanhGaussianPolicy\n",
    "from backend.torch.networks import FlattenMlp, MlpEncoder, RecurrentEncoder\n",
    "from backend.torch.PEARL.sac import PEARLSoftActorCritic\n",
    "from backend.torch.PEARL.agent import PEARLAgent\n",
    "from backend.launchers.launcher_util import setup_logger\n",
    "import backend.torch.pytorch_util as ptu\n",
    "from configs.default import default_config\n",
    "\n",
    "print(\"Selecting Default variant for notebook compatiblity ... \\n\")\n",
    "\n",
    "def run_policy(agent, task_idx, framework = 'PEARL'):\n",
    "    env = VisualiserWrapper(WINDOW_X, WINDOW_Y, \"RoboPeg2D Simulation\", vsync = False, resizable = False, visible = True)\n",
    "    env.show = True\n",
    "    env.task_idx = task_idx\n",
    "    env.agent = agent\n",
    "    env.run_policy(agent)\n",
    "\n",
    "def experiment(variant):\n",
    "\n",
    "    log_dir = 'runs/{}_PEARL_{}'.format(datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\"),\n",
    "                                        \"Peg2DRobot\")\n",
    "    writer = SummaryWriter(logdir=log_dir)\n",
    "\n",
    "    env = ENV()\n",
    "    tasks = env.get_all_task_idx()\n",
    "    obs_dim = int(np.prod(env.observation_space.shape))\n",
    "    action_dim = int(np.prod(env.action_space.shape))\n",
    "    reward_dim = 1\n",
    "\n",
    "    # instantiate networks\n",
    "    latent_dim = variant['latent_size']\n",
    "    context_encoder_input_dim = 2 * obs_dim + action_dim + reward_dim if variant['algo_params']['use_next_obs_in_context'] else obs_dim + action_dim + reward_dim\n",
    "    context_encoder_output_dim = latent_dim * 2 if variant['algo_params']['use_information_bottleneck'] else latent_dim\n",
    "    net_size = variant['net_size']\n",
    "    recurrent = variant['algo_params']['recurrent']\n",
    "    encoder_model = RecurrentEncoder if recurrent else MlpEncoder\n",
    "\n",
    "    context_encoder = encoder_model(\n",
    "        hidden_sizes=[128, 128, 128],\n",
    "        input_size=context_encoder_input_dim,\n",
    "        output_size=context_encoder_output_dim,\n",
    "    )\n",
    "    qf1 = FlattenMlp(\n",
    "        hidden_sizes=[net_size, net_size, net_size],\n",
    "        input_size=obs_dim + action_dim + latent_dim,\n",
    "        output_size=1,\n",
    "    )\n",
    "    qf2 = FlattenMlp(\n",
    "        hidden_sizes=[net_size, net_size, net_size],\n",
    "        input_size=obs_dim + action_dim + latent_dim,\n",
    "        output_size=1,\n",
    "    )\n",
    "    vf = FlattenMlp(\n",
    "        hidden_sizes=[net_size, net_size, net_size],\n",
    "        input_size=obs_dim + latent_dim,\n",
    "        output_size=1,\n",
    "    )\n",
    "    policy = TanhGaussianPolicy(\n",
    "        hidden_sizes=[net_size, net_size, net_size],\n",
    "        obs_dim=obs_dim + latent_dim,\n",
    "        latent_dim=latent_dim,\n",
    "        action_dim=action_dim,\n",
    "    )\n",
    "    agent = PEARLAgent(\n",
    "        latent_dim,\n",
    "        context_encoder,\n",
    "        policy,\n",
    "        **variant['algo_params']\n",
    "    )\n",
    "    algorithm = PEARLSoftActorCritic(\n",
    "        env=env,\n",
    "        train_tasks=list(tasks[:variant['n_train_tasks']]),\n",
    "        eval_tasks=list(tasks[-variant['n_eval_tasks']:]),\n",
    "        nets=[agent, qf1, qf2, vf],\n",
    "        latent_dim=latent_dim,\n",
    "        **variant['algo_params']\n",
    "    )\n",
    "\n",
    "    # optionally load pre-trained weights\n",
    "    if True: #variant['path_to_weights'] is not None:\n",
    "#         print(f\"Loading existing weights from {variant['path_to_weights']} ... \\n\")\n",
    "#         path = variant['path_to_weights']\n",
    "        path = \"output/Peg2D/2020_06_12_00_44_26/\"\n",
    "        context_encoder.load_state_dict(torch.load(os.path.join(path, 'context_encoder.pth')))\n",
    "        qf1.load_state_dict(torch.load(os.path.join(path, 'qf1.pth')))\n",
    "        qf2.load_state_dict(torch.load(os.path.join(path, 'qf2.pth')))\n",
    "        vf.load_state_dict(torch.load(os.path.join(path, 'vf.pth')))\n",
    "        # TODO hacky, revisit after model refactor\n",
    "        algorithm.networks[-2].load_state_dict(torch.load(os.path.join(path, 'target_vf.pth')))\n",
    "        policy.load_state_dict(torch.load(os.path.join(path, 'policy.pth')))\n",
    "    else:\n",
    "        assert variant['modality'] is 'train'\n",
    "        \n",
    "    # optional GPU mode\n",
    "    ptu.set_gpu_mode(variant['util_params']['use_gpu'], variant['util_params']['gpu_id'])\n",
    "    if ptu.gpu_enabled():\n",
    "        algorithm.to()\n",
    "\n",
    "    # debugging triggers a lot of printing and logs to a debug directory\n",
    "    DEBUG = variant['util_params']['debug']\n",
    "    os.environ['DEBUG'] = str(int(DEBUG))\n",
    "\n",
    "    # create logging directory\n",
    "    # TODO support Docker\n",
    "    exp_id = 'debug' if DEBUG else None\n",
    "    experiment_log_dir = setup_logger(variant['env_name'], variant=variant, exp_id=exp_id, base_log_dir=variant['util_params']['base_log_dir'])\n",
    "\n",
    "    # optionally save eval trajectories as pkl files\n",
    "    if variant['algo_params']['dump_eval_paths']:\n",
    "        pickle_dir = experiment_log_dir + '/eval_trajectories'\n",
    "        pathlib.Path(pickle_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    if False: #variant['modality'] is 'train':\n",
    "        # run the algorithm\n",
    "        if isinstance(writer, SummaryWriter):\n",
    "            algorithm.writer = writer\n",
    "        algorithm.train()\n",
    "    elif True: # variant['modality'] is 'test':\n",
    "        algorithm.training_mode(False)\n",
    "        run_policy(agent, task_idx=0, framework='PEARL')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    variant = default_config\n",
    "    experiment(variant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "goals = [(975, 250), \n",
    "        (1025, 300),\n",
    "        (1000, 550),\n",
    "        (1000, 350),\n",
    "        (975, 150),\n",
    "        (975, 450),\n",
    "        (1025, 350),\n",
    "        (1000, 400),\n",
    "        (975, 300),\n",
    "        (1010, 380),\n",
    "        (970, 230),\n",
    "        (990, 350),\n",
    "        (960, 500),\n",
    "        (1010, 200),\n",
    "        (1020, 460),\n",
    "        (960, 300),\n",
    "        (1000, 250),\n",
    "        (1025, 150),\n",
    "        (1000, 400),\n",
    "        (975, 500),]\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.scatter([goal[0] for goal in goals], [goal[1] for goal in goals])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading chipmunk for Windows (64bit) [C:\\Users\\Alvaro\\Anaconda3\\lib\\site-packages\\pymunk\\chipmunk.dll]\n",
      "Working on CPU, GPU is too old\n",
      "Target Entropy -3\n",
      "Not using experts, in for meta-training... \n",
      "\n",
      "Working on CPU, GPU is too old\n",
      "Target Entropy -3\n",
      "Loading models from expert/Peg2D/models/actor_ExpertPeg2D_ and expert/Peg2D/models/critic_ExpertPeg2D_\n",
      "Adapting to task 0 on demo 0\n",
      "Speeding out DT by factor 10\n",
      "Ending Task ... \n",
      "\n",
      "Adapting to task 0 on demo 1\n",
      "Speeding out DT by factor 10\n",
      "Ending Task ... \n",
      "\n",
      "Adapting to task 0 on demo 2\n",
      "Speeding out DT by factor 10\n",
      "Ending Task ... \n",
      "\n",
      "Adapting to task 1 on demo 0\n",
      "Speeding out DT by factor 10\n",
      "Ending Task ... \n",
      "\n",
      "Adapting to task 1 on demo 1\n",
      "Speeding out DT by factor 10\n",
      "Ending Task ... \n",
      "\n",
      "Adapting to task 1 on demo 2\n",
      "Speeding out DT by factor 10\n",
      "Ending Task ... \n",
      "\n",
      "Adapting to task 2 on demo 0\n",
      "Speeding out DT by factor 10\n",
      "Ending Task ... \n",
      "\n",
      "Adapting to task 2 on demo 1\n",
      "Speeding out DT by factor 10\n",
      "Ending Task ... \n",
      "\n",
      "Adapting to task 2 on demo 2\n",
      "Speeding out DT by factor 10\n",
      "Ending Task ... \n",
      "\n",
      "Adapting to task 3 on demo 0\n",
      "Speeding out DT by factor 10\n",
      "Ending Task ... \n",
      "\n",
      "Adapting to task 3 on demo 1\n",
      "Speeding out DT by factor 10\n",
      "Ending Task ... \n",
      "\n",
      "Adapting to task 3 on demo 2\n",
      "Speeding out DT by factor 10\n",
      "Ending Task ... \n",
      "\n",
      "Adapting to task 4 on demo 0\n",
      "Speeding out DT by factor 10\n",
      "Ending Task ... \n",
      "\n",
      "Adapting to task 4 on demo 1\n",
      "Speeding out DT by factor 10\n",
      "Ending Task ... \n",
      "\n",
      "Adapting to task 4 on demo 2\n",
      "Speeding out DT by factor 10\n",
      "Ending Task ... \n",
      "\n",
      "Adapting to task 5 on demo 0\n",
      "Speeding out DT by factor 10\n",
      "Ending Task ... \n",
      "\n",
      "Adapting to task 5 on demo 1\n",
      "Speeding out DT by factor 10\n",
      "Ending Task ... \n",
      "\n",
      "Adapting to task 5 on demo 2\n",
      "Speeding out DT by factor 10\n",
      "Ending Task ... \n",
      "\n",
      "Adapting to task 6 on demo 0\n",
      "Speeding out DT by factor 10\n",
      "Ending Task ... \n",
      "\n",
      "Adapting to task 6 on demo 1\n",
      "Speeding out DT by factor 10\n",
      "Ending Task ... \n",
      "\n",
      "Adapting to task 6 on demo 2\n",
      "Speeding out DT by factor 10\n",
      "Ending Task ... \n",
      "\n",
      "Adapting to task 7 on demo 0\n",
      "Speeding out DT by factor 10\n",
      "Ending Task ... \n",
      "\n",
      "Adapting to task 7 on demo 1\n",
      "Speeding out DT by factor 10\n",
      "Ending Task ... \n",
      "\n",
      "Adapting to task 7 on demo 2\n",
      "Speeding out DT by factor 10\n",
      "Ending Task ... \n",
      "\n",
      "Adapting to task 8 on demo 0\n",
      "Speeding out DT by factor 10\n",
      "Ending Task ... \n",
      "\n",
      "Adapting to task 8 on demo 1\n",
      "Speeding out DT by factor 10\n",
      "Ending Task ... \n",
      "\n",
      "Adapting to task 8 on demo 2\n",
      "Speeding out DT by factor 10\n",
      "Ending Task ... \n",
      "\n",
      "Adapting to task 9 on demo 0\n",
      "Speeding out DT by factor 10\n",
      "Ending Task ... \n",
      "\n",
      "Adapting to task 9 on demo 1\n",
      "Speeding out DT by factor 10\n",
      "Ending Task ... \n",
      "\n",
      "Adapting to task 9 on demo 2\n",
      "Speeding out DT by factor 10\n",
      "Ending Task ... \n",
      "\n",
      "Adapting to task 10 on demo 0\n",
      "Speeding out DT by factor 10\n",
      "Ending Task ... \n",
      "\n",
      "Adapting to task 10 on demo 1\n",
      "Speeding out DT by factor 10\n",
      "Ending Task ... \n",
      "\n",
      "Adapting to task 10 on demo 2\n",
      "Speeding out DT by factor 10\n",
      "Ending Task ... \n",
      "\n",
      "Adapting to task 11 on demo 0\n",
      "Speeding out DT by factor 10\n",
      "Ending Task ... \n",
      "\n",
      "Adapting to task 11 on demo 1\n",
      "Speeding out DT by factor 10\n",
      "Ending Task ... \n",
      "\n",
      "Adapting to task 11 on demo 2\n",
      "Speeding out DT by factor 10\n",
      "Ending Task ... \n",
      "\n",
      "Adapting to task 12 on demo 0\n",
      "Speeding out DT by factor 10\n",
      "Ending Task ... \n",
      "\n",
      "Adapting to task 12 on demo 1\n",
      "Speeding out DT by factor 10\n",
      "Ending Task ... \n",
      "\n",
      "Adapting to task 12 on demo 2\n",
      "Speeding out DT by factor 10\n",
      "Ending Task ... \n",
      "\n",
      "Adapting to task 13 on demo 0\n",
      "Speeding out DT by factor 10\n",
      "Ending Task ... \n",
      "\n",
      "Adapting to task 13 on demo 1\n",
      "Speeding out DT by factor 10\n",
      "Ending Task ... \n",
      "\n",
      "Adapting to task 13 on demo 2\n",
      "Speeding out DT by factor 10\n",
      "Ending Task ... \n",
      "\n",
      "Adapting to task 14 on demo 0\n",
      "Speeding out DT by factor 10\n",
      "Ending Task ... \n",
      "\n",
      "Adapting to task 14 on demo 1\n",
      "Speeding out DT by factor 10\n",
      "Ending Task ... \n",
      "\n",
      "Adapting to task 14 on demo 2\n",
      "Speeding out DT by factor 10\n",
      "Ending Task ... \n",
      "\n",
      "Adapting to task 15 on demo 0\n",
      "Speeding out DT by factor 10\n",
      "Ending Task ... \n",
      "\n",
      "Adapting to task 15 on demo 1\n",
      "Speeding out DT by factor 10\n",
      "Ending Task ... \n",
      "\n",
      "Adapting to task 15 on demo 2\n",
      "Speeding out DT by factor 10\n",
      "Ending Task ... \n",
      "\n",
      "Adapting to task 16 on demo 0\n",
      "Speeding out DT by factor 10\n",
      "Ending Task ... \n",
      "\n",
      "Adapting to task 16 on demo 1\n",
      "Speeding out DT by factor 10\n",
      "Ending Task ... \n",
      "\n",
      "Adapting to task 16 on demo 2\n",
      "Speeding out DT by factor 10\n",
      "Ending Task ... \n",
      "\n",
      "Adapting to task 17 on demo 0\n",
      "Speeding out DT by factor 10\n",
      "Ending Task ... \n",
      "\n",
      "Adapting to task 17 on demo 1\n",
      "Speeding out DT by factor 10\n",
      "Ending Task ... \n",
      "\n",
      "Adapting to task 17 on demo 2\n",
      "Speeding out DT by factor 10\n",
      "Ending Task ... \n",
      "\n",
      "Adapting to task 18 on demo 0\n",
      "Speeding out DT by factor 10\n",
      "Ending Task ... \n",
      "\n",
      "Adapting to task 18 on demo 1\n",
      "Speeding out DT by factor 10\n",
      "Ending Task ... \n",
      "\n",
      "Adapting to task 18 on demo 2\n",
      "Speeding out DT by factor 10\n",
      "Ending Task ... \n",
      "\n",
      "Adapting to task 19 on demo 0\n",
      "Speeding out DT by factor 10\n",
      "Ending Task ... \n",
      "\n",
      "Adapting to task 19 on demo 1\n",
      "Speeding out DT by factor 10\n",
      "Ending Task ... \n",
      "\n",
      "Adapting to task 19 on demo 2\n",
      "Speeding out DT by factor 10\n",
      "Ending Task ... \n",
      "\n",
      "Adapting to task 20 on demo 0\n",
      "Speeding out DT by factor 10\n",
      "Ending Task ... \n",
      "\n",
      "Adapting to task 20 on demo 1\n",
      "Speeding out DT by factor 10\n",
      "Ending Task ... \n",
      "\n",
      "Adapting to task 20 on demo 2\n",
      "Speeding out DT by factor 10\n",
      "Ending Task ... \n",
      "\n",
      "Adapting to task 21 on demo 0\n",
      "Speeding out DT by factor 10\n",
      "Ending Task ... \n",
      "\n",
      "Adapting to task 21 on demo 1\n",
      "Speeding out DT by factor 10\n",
      "Ending Task ... \n",
      "\n",
      "Adapting to task 21 on demo 2\n",
      "Speeding out DT by factor 10\n",
      "Ending Task ... \n",
      "\n",
      "Adapting to task 22 on demo 0\n",
      "Speeding out DT by factor 10\n",
      "Ending Task ... \n",
      "\n",
      "Adapting to task 22 on demo 1\n",
      "Speeding out DT by factor 10\n",
      "Ending Task ... \n",
      "\n",
      "Adapting to task 22 on demo 2\n",
      "Speeding out DT by factor 10\n",
      "Ending Task ... \n",
      "\n",
      "Adapting to task 23 on demo 0\n",
      "Speeding out DT by factor 10\n",
      "Ending Task ... \n",
      "\n",
      "Adapting to task 23 on demo 1\n",
      "Speeding out DT by factor 10\n",
      "Ending Task ... \n",
      "\n",
      "Adapting to task 23 on demo 2\n",
      "Speeding out DT by factor 10\n",
      "Ending Task ... \n",
      "\n",
      "Adapting to task 24 on demo 0\n",
      "Speeding out DT by factor 10\n",
      "Ending Task ... \n",
      "\n",
      "Adapting to task 24 on demo 1\n",
      "Speeding out DT by factor 10\n",
      "Ending Task ... \n",
      "\n",
      "Adapting to task 24 on demo 2\n",
      "Speeding out DT by factor 10\n",
      "Ending Task ... \n",
      "\n",
      "Adapting to task 25 on demo 0\n",
      "Speeding out DT by factor 10\n",
      "Ending Task ... \n",
      "\n",
      "Adapting to task 25 on demo 1\n",
      "Speeding out DT by factor 10\n",
      "Ending Task ... \n",
      "\n",
      "Adapting to task 25 on demo 2\n",
      "Speeding out DT by factor 10\n",
      "Ending Task ... \n",
      "\n",
      "Adapting to task 26 on demo 0\n",
      "Speeding out DT by factor 10\n",
      "Ending Task ... \n",
      "\n",
      "Adapting to task 26 on demo 1\n",
      "Speeding out DT by factor 10\n",
      "Ending Task ... \n",
      "\n",
      "Adapting to task 26 on demo 2\n",
      "Speeding out DT by factor 10\n",
      "Ending Task ... \n",
      "\n",
      "Adapting to task 27 on demo 0\n",
      "Speeding out DT by factor 10\n",
      "Ending Task ... \n",
      "\n",
      "Adapting to task 27 on demo 1\n",
      "Speeding out DT by factor 10\n",
      "Ending Task ... \n",
      "\n",
      "Adapting to task 27 on demo 2\n",
      "Speeding out DT by factor 10\n",
      "Ending Task ... \n",
      "\n",
      "Adapting to task 28 on demo 0\n",
      "Speeding out DT by factor 10\n",
      "Ending Task ... \n",
      "\n",
      "Adapting to task 28 on demo 1\n",
      "Speeding out DT by factor 10\n",
      "Ending Task ... \n",
      "\n",
      "Adapting to task 28 on demo 2\n",
      "Speeding out DT by factor 10\n",
      "Ending Task ... \n",
      "\n",
      "Adapting to task 29 on demo 0\n",
      "Speeding out DT by factor 10\n",
      "Ending Task ... \n",
      "\n",
      "Adapting to task 29 on demo 1\n",
      "Speeding out DT by factor 10\n",
      "Ending Task ... \n",
      "\n",
      "Adapting to task 29 on demo 2\n",
      "Speeding out DT by factor 10\n",
      "Ending Task ... \n",
      "\n",
      "Adapting to task 30 on demo 0\n",
      "Speeding out DT by factor 10\n",
      "Ending Task ... \n",
      "\n",
      "Adapting to task 30 on demo 1\n",
      "Speeding out DT by factor 10\n",
      "Ending Task ... \n",
      "\n",
      "Adapting to task 30 on demo 2\n",
      "Speeding out DT by factor 10\n",
      "Ending Task ... \n",
      "\n",
      "Adapting to task 31 on demo 0\n",
      "Speeding out DT by factor 10\n",
      "Ending Task ... \n",
      "\n",
      "Adapting to task 31 on demo 1\n",
      "Speeding out DT by factor 10\n",
      "Ending Task ... \n",
      "\n",
      "Adapting to task 31 on demo 2\n",
      "Speeding out DT by factor 10\n",
      "Ending Task ... \n",
      "\n",
      "Adapting to task 32 on demo 0\n",
      "Speeding out DT by factor 10\n",
      "Ending Task ... \n",
      "\n",
      "Adapting to task 32 on demo 1\n",
      "Speeding out DT by factor 10\n",
      "Ending Task ... \n",
      "\n",
      "Adapting to task 32 on demo 2\n",
      "Speeding out DT by factor 10\n",
      "Ending Task ... \n",
      "\n",
      "Adapting to task 33 on demo 0\n",
      "Speeding out DT by factor 10\n",
      "Ending Task ... \n",
      "\n",
      "Adapting to task 33 on demo 1\n",
      "Speeding out DT by factor 10\n",
      "Ending Task ... \n",
      "\n",
      "Adapting to task 33 on demo 2\n",
      "Speeding out DT by factor 10\n",
      "Ending Task ... \n",
      "\n",
      "Adapting to task 34 on demo 0\n",
      "Speeding out DT by factor 10\n",
      "Ending Task ... \n",
      "\n",
      "Ending Task ... \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Adapting to task 34 on demo 1\n",
      "Speeding out DT by factor 10\n",
      "Ending Task ... \n",
      "\n",
      "Ending Task ... \n",
      "\n",
      "Adapting to task 34 on demo 2\n",
      "Speeding out DT by factor 10\n",
      "Ending Task ... \n",
      "\n",
      "Ending Task ... \n",
      "\n",
      "Adapting to task 35 on demo 0\n",
      "Speeding out DT by factor 10\n",
      "Ending Task ... \n",
      "\n",
      "Ending Task ... \n",
      "\n",
      "Adapting to task 35 on demo 1\n",
      "Speeding out DT by factor 10\n",
      "Ending Task ... \n",
      "\n",
      "Ending Task ... \n",
      "\n",
      "Adapting to task 35 on demo 2\n",
      "Speeding out DT by factor 10\n",
      "Ending Task ... \n",
      "\n",
      "Ending Task ... \n",
      "\n",
      "Adapting to task 36 on demo 0\n",
      "Speeding out DT by factor 10\n",
      "Ending Task ... \n",
      "\n",
      "Ending Task ... \n",
      "\n",
      "Adapting to task 36 on demo 1\n",
      "Speeding out DT by factor 10\n",
      "Ending Task ... \n",
      "\n",
      "Ending Task ... \n",
      "\n",
      "Adapting to task 36 on demo 2\n",
      "Speeding out DT by factor 10\n",
      "Ending Task ... \n",
      "\n",
      "Ending Task ... \n",
      "\n",
      "Adapting to task 37 on demo 0\n",
      "Speeding out DT by factor 10\n",
      "Ending Task ... \n",
      "\n",
      "Ending Task ... \n",
      "\n",
      "Adapting to task 37 on demo 1\n",
      "Speeding out DT by factor 10\n",
      "Ending Task ... \n",
      "\n",
      "Ending Task ... \n",
      "\n",
      "Adapting to task 37 on demo 2\n",
      "Speeding out DT by factor 10\n",
      "Ending Task ... \n",
      "\n",
      "Ending Task ... \n",
      "\n",
      "Adapting to task 38 on demo 0\n",
      "Speeding out DT by factor 10\n",
      "Ending Task ... \n",
      "\n",
      "Ending Task ... \n",
      "\n",
      "Adapting to task 38 on demo 1\n",
      "Speeding out DT by factor 10\n",
      "Ending Task ... \n",
      "\n",
      "Ending Task ... \n",
      "\n",
      "Adapting to task 38 on demo 2\n",
      "Speeding out DT by factor 10\n",
      "Ending Task ... \n",
      "\n",
      "Ending Task ... \n",
      "\n",
      "Adapting to task 39 on demo 0\n",
      "Speeding out DT by factor 10\n",
      "Ending Task ... \n",
      "\n",
      "Ending Task ... \n",
      "\n",
      "Adapting to task 39 on demo 1\n",
      "Speeding out DT by factor 10\n",
      "Ending Task ... \n",
      "\n",
      "Ending Task ... \n",
      "\n",
      "Adapting to task 39 on demo 2\n",
      "Speeding out DT by factor 10\n",
      "Ending Task ... \n",
      "\n",
      "Ending Task ... \n",
      "\n",
      "Adapting to task 40 on demo 0\n",
      "Speeding out DT by factor 10\n",
      "Ending Task ... \n",
      "\n",
      "Ending Task ... \n",
      "\n",
      "Adapting to task 40 on demo 1\n",
      "Speeding out DT by factor 10\n",
      "Ending Task ... \n",
      "\n",
      "Ending Task ... \n",
      "\n",
      "Adapting to task 40 on demo 2\n",
      "Speeding out DT by factor 10\n",
      "Ending Task ... \n",
      "\n",
      "Ending Task ... \n",
      "\n",
      "Adapting to task 41 on demo 0\n",
      "Speeding out DT by factor 10\n",
      "Ending Task ... \n",
      "\n",
      "Ending Task ... \n",
      "\n",
      "Adapting to task 41 on demo 1\n",
      "Speeding out DT by factor 10\n",
      "Ending Task ... \n",
      "\n",
      "Ending Task ... \n",
      "\n",
      "Adapting to task 41 on demo 2\n",
      "Speeding out DT by factor 10\n",
      "Ending Task ... \n",
      "\n",
      "Ending Task ... \n",
      "\n",
      "Adapting to task 42 on demo 0\n",
      "Speeding out DT by factor 10\n",
      "Ending Task ... \n",
      "\n",
      "Ending Task ... \n",
      "\n",
      "Adapting to task 42 on demo 1\n",
      "Speeding out DT by factor 10\n",
      "Ending Task ... \n",
      "\n",
      "Ending Task ... \n",
      "\n",
      "Adapting to task 42 on demo 2\n",
      "Speeding out DT by factor 10\n",
      "Ending Task ... \n",
      "\n",
      "Ending Task ... \n",
      "\n",
      "Adapting to task 43 on demo 0\n",
      "Speeding out DT by factor 10\n",
      "Ending Task ... \n",
      "\n",
      "Ending Task ... \n",
      "\n",
      "Adapting to task 43 on demo 1\n",
      "Speeding out DT by factor 10\n",
      "Ending Task ... \n",
      "\n",
      "Ending Task ... \n",
      "\n",
      "Adapting to task 43 on demo 2\n",
      "Speeding out DT by factor 10\n",
      "Ending Task ... \n",
      "\n",
      "Ending Task ... \n",
      "\n",
      "Adapting to task 44 on demo 0\n",
      "Speeding out DT by factor 10\n",
      "Ending Task ... \n",
      "\n",
      "Ending Task ... \n",
      "\n",
      "Adapting to task 44 on demo 1\n",
      "Speeding out DT by factor 10\n",
      "Ending Task ... \n",
      "\n",
      "Ending Task ... \n",
      "\n",
      "Adapting to task 44 on demo 2\n",
      "Speeding out DT by factor 10\n",
      "Ending Task ... \n",
      "\n",
      "Ending Task ... \n",
      "\n",
      "Adapting to task 45 on demo 0\n",
      "Speeding out DT by factor 10\n",
      "Ending Task ... \n",
      "\n",
      "Ending Task ... \n",
      "\n",
      "Adapting to task 45 on demo 1\n",
      "Speeding out DT by factor 10\n",
      "Ending Task ... \n",
      "\n",
      "Ending Task ... \n",
      "\n",
      "Adapting to task 45 on demo 2\n",
      "Speeding out DT by factor 10\n",
      "Ending Task ... \n",
      "\n",
      "Ending Task ... \n",
      "\n",
      "Adapting to task 46 on demo 0\n",
      "Speeding out DT by factor 10\n",
      "Ending Task ... \n",
      "\n",
      "Ending Task ... \n",
      "\n",
      "Adapting to task 46 on demo 1\n",
      "Speeding out DT by factor 10\n",
      "Ending Task ... \n",
      "\n",
      "Ending Task ... \n",
      "\n",
      "Adapting to task 46 on demo 2\n",
      "Speeding out DT by factor 10\n",
      "Ending Task ... \n",
      "\n",
      "Ending Task ... \n",
      "\n",
      "Adapting to task 47 on demo 0\n",
      "Speeding out DT by factor 10\n",
      "Ending Task ... \n",
      "\n",
      "Ending Task ... \n",
      "\n",
      "Adapting to task 47 on demo 1\n",
      "Speeding out DT by factor 10\n",
      "Ending Task ... \n",
      "\n",
      "Ending Task ... \n",
      "\n",
      "Adapting to task 47 on demo 2\n",
      "Speeding out DT by factor 10\n",
      "Ending Task ... \n",
      "\n",
      "Ending Task ... \n",
      "\n",
      "Adapting to task 48 on demo 0\n",
      "Speeding out DT by factor 10\n",
      "Ending Task ... \n",
      "\n",
      "Ending Task ... \n",
      "\n",
      "Adapting to task 48 on demo 1\n",
      "Speeding out DT by factor 10\n",
      "Ending Task ... \n",
      "\n",
      "Ending Task ... \n",
      "\n",
      "Adapting to task 48 on demo 2\n",
      "Speeding out DT by factor 10\n",
      "Ending Task ... \n",
      "\n",
      "Ending Task ... \n",
      "\n",
      "Adapting to task 49 on demo 0\n",
      "Speeding out DT by factor 10\n",
      "Ending Task ... \n",
      "\n",
      "Ending Task ... \n",
      "\n",
      "Adapting to task 49 on demo 1\n",
      "Speeding out DT by factor 10\n",
      "Ending Task ... \n",
      "\n",
      "Ending Task ... \n",
      "\n",
      "Adapting to task 49 on demo 2\n",
      "Speeding out DT by factor 10\n",
      "Ending Task ... \n",
      "\n",
      "Ending Task ... \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"\")\n",
    "sys.path.append(\"../\")\n",
    "import os, shutil\n",
    "import os.path as osp\n",
    "import pickle\n",
    "import json\n",
    "import numpy as np\n",
    "import click\n",
    "import torch\n",
    "\n",
    "from tensorboardX import SummaryWriter\n",
    "import datetime\n",
    "\n",
    "from envs.metaENV import ENV, VisualiserWrapper\n",
    "from baselines.SAC.sac import SAC\n",
    "from envs.MetaPeg2D import WINDOW_X, WINDOW_Y, ORIGIN, PEG_DEPTH\n",
    "from backend.torch.PEARL.policies import TanhGaussianPolicy\n",
    "from backend.torch.networks import FlattenMlp, MlpEncoder, RecurrentEncoder, LatentGNNEncoder, NormalAux\n",
    "\n",
    "from backend.samplers.util import expert_rollout\n",
    "from configs.default import default_config\n",
    "from expert.expert import variant\n",
    "\n",
    "    \n",
    "def sim_policy(variant, \n",
    "               path_to_exp, \n",
    "               num_demos=1, \n",
    "               view=False, \n",
    "               visible = False\n",
    "              ):\n",
    "    \n",
    "    '''\n",
    "    simulate a trained policy adapting to a new task\n",
    "    optionally save videos of the trajectories - requires ffmpeg\n",
    "    :variant: experiment configuration dict\n",
    "    :path_to_exp: path to exp folder\n",
    "    :num_trajs: number of trajectories to simulate per task (default 1)\n",
    "    :deterministic: if the policy is deterministic (default stochastic)\n",
    "    :save_video: whether to generate and save a video (default False)\n",
    "    '''\n",
    "\n",
    "    env = ENV(expert = True) if not view else VisualiserWrapper(WINDOW_X, WINDOW_Y, \"RoboPeg2D Simulation\", \n",
    "                                                       vsync = False, resizable = False, visible = visible)\n",
    "\n",
    "    num_actions = len(env.action_space)\n",
    "    num_inputs = len(env.observation_space)\n",
    "\n",
    "    agent = SAC(num_inputs, num_actions, action_range = None, **variant['trainer_kwargs'])\n",
    "    agent.load_model(os.path.join(path_to_exp,'actor_ExpertPeg2D_'), os.path.join(path_to_exp, 'critic_ExpertPeg2D_'))\n",
    "\n",
    "    if view:\n",
    "        env.set_visible(visible = visible)\n",
    "        env.set_visibles()\n",
    "    \n",
    "    # loop through tasks collecting rollouts\n",
    "    all_rets = []\n",
    "    all_paths = []\n",
    "    tasks = [x for x in range(50)]\n",
    "    \n",
    "    for idx in tasks:\n",
    "        env.set_task_idx(idx)\n",
    "        env.reset_task(idx)\n",
    "        env.rollout_counter = 0\n",
    "\n",
    "        paths = []\n",
    "\n",
    "        for n in range(num_demos):\n",
    "            if view:\n",
    "                print(f'Adapting to task {idx} on demo {n}')\n",
    "                env.view_expert_rollout(agent, max_steps = variant['algorithm_kwargs']['max_path_length'])\n",
    "                env.reset_task(idx)\n",
    "            else:\n",
    "                print(f'Adapting to task {idx} on demo {n}')\n",
    "                path = expert_rollout(env, agent, max_path_length=variant['algorithm_kwargs']['max_path_length'],\n",
    "                                     animated = visible, eval = True)                \n",
    "                paths.append(path)\n",
    "                \n",
    "        env.all_paths.append(env.trajectories)\n",
    "            \n",
    "        all_rets.append([sum(p['rewards']) for p in paths])\n",
    "\n",
    "    if not view:\n",
    "        n = min([len(a) for a in all_rets])\n",
    "        rets = [a[:n] for a in all_rets]\n",
    "        rets = np.mean(np.stack(rets), axis=0)\n",
    "        for i, ret in enumerate(rets):\n",
    "            print('trajectory {}, avg return: {} \\n'.format(i, ret))\n",
    "\n",
    "    return env.all_paths \n",
    "\n",
    "def main(config, path, num_demos = 3, view = False, visible = False):\n",
    "    return sim_policy(variant, path, num_demos, view, visible = visible)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    config = None\n",
    "    num_demos = 3\n",
    "    path = \"expert/Peg2D/models/\"\n",
    "    all_paths = main(config, \n",
    "                     path, \n",
    "                     num_demos, \n",
    "                     view = True, \n",
    "                     visible = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[50, 50, 50],\n",
       " [50, 50, 50],\n",
       " [50, 50, 50],\n",
       " [50, 50, 50],\n",
       " [50, 50, 50],\n",
       " [50, 50, 50],\n",
       " [50, 50, 50],\n",
       " [50, 50, 50],\n",
       " [50, 50, 50],\n",
       " [50, 50, 50],\n",
       " [50, 50, 50],\n",
       " [50, 50, 50],\n",
       " [50, 50, 50],\n",
       " [50, 50, 50],\n",
       " [50, 50, 50],\n",
       " [50, 50, 50],\n",
       " [50, 50, 50],\n",
       " [50, 50, 50],\n",
       " [50, 50, 50],\n",
       " [50, 50, 50],\n",
       " [50, 50, 50],\n",
       " [50, 50, 50],\n",
       " [50, 50, 50],\n",
       " [50, 50, 50],\n",
       " [50, 50, 50],\n",
       " [50, 50, 50],\n",
       " [50, 50, 50],\n",
       " [50, 50, 50],\n",
       " [50, 50, 50],\n",
       " [50, 50, 50],\n",
       " [50, 50, 50],\n",
       " [50, 50, 50],\n",
       " [50, 50, 50],\n",
       " [50, 50, 50],\n",
       " [50, 50, 50, 50, 50, 50],\n",
       " [50, 50, 50, 50, 50, 50],\n",
       " [50, 50, 50, 50, 50, 50],\n",
       " [50, 50, 50, 50, 50, 50],\n",
       " [50, 50, 50, 50, 50, 50],\n",
       " [50, 50, 50, 50, 50, 50],\n",
       " [50, 50, 50, 50, 50, 50],\n",
       " [50, 50, 50, 50, 50, 50],\n",
       " [50, 50, 50, 50, 50, 50],\n",
       " [50, 50, 50, 50, 50, 50],\n",
       " [50, 50, 50, 50, 50, 50],\n",
       " [50, 50, 50, 50, 50, 50],\n",
       " [50, 50, 50, 50, 50, 50],\n",
       " [50, 50, 50, 50, 50, 50],\n",
       " [50, 50, 50, 50, 50, 50],\n",
       " [50, 50, 50, 50, 50, 50]]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[[x['rollout_length'] for x in all_paths[y]] for y in range(0,len(all_paths))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.4788084671483674"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(all_paths[-1][0]['rewards'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "           \n",
    "demo_paths = dict(\n",
    "            Peg2D = all_paths)\n",
    "\n",
    "import pickle\n",
    "\n",
    "with open('expert/Peg2D/ExpertPeg2DPaths.pickle', 'wb') as handle:\n",
    "    pickle.dump(demo_paths, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx = np.array([[False for x in range(10)]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([[int(x) for x in xx.flatten()]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 8, 9])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.unique([1,2,3,4,5,3,1,9,8,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1])\n",
      "torch.Size([2, 5])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "a = torch.tensor([[False], [True]]).float()\n",
    "print(a.shape)\n",
    "b = torch.ones([2,5])\n",
    "print(b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat([a,b], dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_var = torch.rand([16,6])\n",
    "z_mu = torch.rand([16,6])\n",
    "target_latent_space = torch.rand([16,256,6])\n",
    "normal = torch.distributions.Normal(z_mu, z_var)\n",
    "log_probs = normal.log_prob(target_latent_space.permute(1,0,2))\n",
    "normals_1 = [torch.distributions.Normal(mu, torch.sqrt(var)) for mu, var in zip(torch.unbind(z_mu), torch.unbind(z_var))]\n",
    "log_probs_1 = [normal.log_prob(target_latent_space[i]) for i, normal in enumerate(normals)]\n",
    "log_probs_1 = torch.stack(log_probs_1).permute(1,0,2) # log_probs = normal.log_prob(target_latent_space.permute(1,0,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-1606905.3750)"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(log_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-22348.4492)"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(log_probs_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.8665, 0.7193, 0.5797])"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.rand([3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-171-60fe12f686d4>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-171-60fe12f686d4>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    WHAT THE FUCK\u001b[0m\n\u001b[1;37m           ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "WHAT THE FUCK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 0., 0., 0.]) tensor([1., 1., 1., 1., 1., 1.])\n"
     ]
    }
   ],
   "source": [
    "mu = torch.zeros([6])\n",
    "var = torch.ones([6])\n",
    "nrm = torch.distributions.Normal(mu,var)\n",
    "print(mu,var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.1398, -1.0074, -0.9886, -0.9201, -0.9308, -1.0082])"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nrm.log_prob(torch.rand([6]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Normal(loc: torch.Size([6]), scale: torch.Size([6]))"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.distributions.Normal(mu,var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.9239, -0.9389, -1.4090, -0.9239, -0.9239, -0.9239])"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nrm.log_prob(torch.tensor([0.1, 0.2, 0.99, 0.1, 0.1, 0.1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([256, 1, 1])"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.rand([16,256,6]).permute(1,0,2).sum(dim = [1,2], keepdim = True).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "gg = dict(\n",
    "    hello = torch.tensor([8,3]),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "for v in gg.values():\n",
    "    print(isinstance(v,torch.Tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "min() received an invalid combination of arguments - got (Tensor, float), but expected one of:\n * (Tensor input)\n * (Tensor input, name dim, bool keepdim, tuple of Tensors out)\n * (Tensor input, Tensor other, Tensor out)\n * (Tensor input, int dim, bool keepdim, tuple of Tensors out)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-50610a4b0e89>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: min() received an invalid combination of arguments - got (Tensor, float), but expected one of:\n * (Tensor input)\n * (Tensor input, name dim, bool keepdim, tuple of Tensors out)\n * (Tensor input, Tensor other, Tensor out)\n * (Tensor input, int dim, bool keepdim, tuple of Tensors out)\n"
     ]
    }
   ],
   "source": [
    "torch.dot(torch.torch.Tensor([1]), 0.0),torch.Tensor([1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torch.clamp(torch.Tensor([1]), 0.0, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
